{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Federated PyTorch MNIST Tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Install dependencies if not already installed\n",
    "!pip install torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import openfl.native as fx\n",
    "from openfl.federated import FederatedModel,FederatedDataSet\n",
    "\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After importing the required packages, the next step is setting up our openfl workspace. To do this, simply run the `fx.init()` command as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup default workspace, logging, etc.\n",
    "fx.init('torch_cnn_mnist')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to define our dataset and model to perform federated learning on. The dataset should be composed of a numpy arrayWe start with a simple fully connected model that is trained on the MNIST dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(labels, classes):\n",
    "    return np.eye(classes)[labels]\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "\n",
    "train_images,train_labels = trainset.train_data, np.array(trainset.train_labels)\n",
    "train_images = torch.from_numpy(np.expand_dims(train_images, axis=1)).float()\n",
    "train_labels = one_hot(train_labels,10)\n",
    "\n",
    "validset = torchvision.datasets.MNIST(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "\n",
    "valid_images,valid_labels = validset.test_data, np.array(validset.test_labels)\n",
    "valid_images = torch.from_numpy(np.expand_dims(valid_images, axis=1)).float()\n",
    "valid_labels = one_hot(valid_labels,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_shape = train_images.shape[1]\n",
    "classes       = 10\n",
    "\n",
    "fl_data = FederatedDataSet(train_images,train_labels,valid_images,valid_labels,batch_size=32,num_classes=classes)\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, 3)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 3)\n",
    "        self.fc1 = nn.Linear(32 * 5 * 5, 32)\n",
    "        self.fc2 = nn.Linear(32, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(x.size(0),-1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "optimizer = lambda x: optim.Adam(x, lr=1e-4)\n",
    "\n",
    "def cross_entropy(output, target):\n",
    "    \"\"\"Binary cross-entropy metric\n",
    "    \"\"\"\n",
    "    return F.cross_entropy(input=output,target=torch.argmax(target, dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Create a federated model using the pytorch class, lambda optimizer function, and loss function\n",
    "fl_model = FederatedModel(build_model=Net,optimizer=optimizer,loss_fn=cross_entropy,data_loader=fl_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `FederatedModel` object is a wrapper around your Keras, Tensorflow or PyTorch model that makes it compatible with openfl. It provides built in federated training and validation functions that we will see used below. Using it's `setup` function, collaborator models and datasets can be automatically defined for the experiment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collaborator_models = fl_model.setup(num_collaborators=10)\n",
    "collaborators = {str(i): collaborator_models[i] for i in range(10)}#, 'three':collaborator_models[2]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Original MNIST dataset\n",
    "print(f'Original training data size: {len(train_images)}')\n",
    "print(f'Original validation data size: {len(valid_images)}\\n')\n",
    "\n",
    "#Collaborator one's data\n",
    "print(f'Collaborator one\\'s training data size: {len(collaborator_models[0].data_loader.X_train)}')\n",
    "print(f'Collaborator one\\'s validation data size: {len(collaborator_models[0].data_loader.X_valid)}\\n')\n",
    "\n",
    "#Collaborator two's data\n",
    "print(f'Collaborator two\\'s training data size: {len(collaborator_models[1].data_loader.X_train)}')\n",
    "print(f'Collaborator two\\'s validation data size: {len(collaborator_models[1].data_loader.X_valid)}\\n')\n",
    "\n",
    "#Collaborator three's data\n",
    "#print(f'Collaborator three\\'s training data size: {len(collaborator_models[2].data_loader.X_train)}')\n",
    "#print(f'Collaborator three\\'s validation data size: {len(collaborator_models[2].data_loader.X_valid)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the current plan values by running the `fx.get_plan()` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #Get the current values of the plan. Each of these can be overridden\n",
    "print(fx.get_plan())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openfl.interface.aggregation_functions import AggregationFunction\n",
    "import numpy as np\n",
    "\n",
    "class ExponentialSmoothingAveraging(AggregationFunction):\n",
    "    \"\"\"\n",
    "        Averaging via exponential smoothing.\n",
    "        \n",
    "        In order to use this mechanism properly you should specify `aggregator.settings.db_store_rounds` \n",
    "        in `override_config` keyword argument of `run_experiment` function. \n",
    "        It should be equal to the number of rounds you want to include in smoothing window.\n",
    "        \n",
    "        Args:\n",
    "            alpha(float): Smoothing term.\n",
    "    \"\"\"\n",
    "    def __init__(self, alpha=0.9):\n",
    "        self.alpha = alpha\n",
    "        \n",
    "    def call(self,\n",
    "             local_tensors,\n",
    "             db_iterator,\n",
    "             tensor_name,\n",
    "             fl_round,\n",
    "             tags):\n",
    "        \"\"\"Aggregate tensors.\n",
    "\n",
    "        Args:\n",
    "            local_tensors(list[openfl.utilities.LocalTensor]): List of local tensors to aggregate.\n",
    "            db_iterator: iterator over history of all tensors. Columns:\n",
    "                - 'tensor_name': name of the tensor.\n",
    "                    Examples for `torch.nn.Module`s: 'conv1.weight', 'fc2.bias'.\n",
    "                - 'round': 0-based number of round corresponding to this tensor.\n",
    "                - 'tags': tuple of tensor tags. Tags that can appear:\n",
    "                    - 'model' indicates that the tensor is a model parameter.\n",
    "                    - 'trained' indicates that tensor is a part of a training result.\n",
    "                        These tensors are passed to the aggregator node after local learning.\n",
    "                    - 'aggregated' indicates that tensor is a result of aggregation.\n",
    "                        These tensors are sent to collaborators for the next round.\n",
    "                    - 'delta' indicates that value is a difference between rounds\n",
    "                        for a specific tensor.\n",
    "                    also one of the tags is a collaborator name\n",
    "                    if it corresponds to a result of a local task.\n",
    "\n",
    "                - 'nparray': value of the tensor.\n",
    "            tensor_name: name of the tensor\n",
    "            fl_round: round number\n",
    "            tags: tuple of tags for this tensor\n",
    "        Returns:\n",
    "            np.ndarray: aggregated tensor\n",
    "        \"\"\"\n",
    "        tensors, weights = zip(*[(x.tensor, x.weight) for x in local_tensors])\n",
    "        tensors, weights = np.array(tensors), np.array(weights)\n",
    "        average = np.average(tensors, weights=weights, axis=0)\n",
    "        previous_tensor_values = []\n",
    "        for record in db_iterator:\n",
    "            if (\n",
    "                record['tensor_name'] == tensor_name\n",
    "                and 'aggregated' in record['tags']\n",
    "                and 'delta' not in record['tags']\n",
    "               ):\n",
    "                previous_tensor_values.append(record['nparray'])\n",
    "        for i, x in enumerate(previous_tensor_values):\n",
    "            previous_tensor_values[i] = x * self.alpha * (1 - self.alpha) ** i\n",
    "        smoothing_term = np.sum(previous_tensor_values, axis=0)\n",
    "        return self.alpha * average + (1 - self.alpha) * smoothing_term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openfl.interface.aggregation_functions import AggregationFunction\n",
    "import numpy as np\n",
    "\n",
    "class ClippedAveraging(AggregationFunction):\n",
    "    def __init__(self, ratio):\n",
    "        \"\"\"Average clipped tensors.\n",
    "            \n",
    "            Args:\n",
    "                ratio(float): Ratio to multiply with a tensor for clipping\n",
    "        \"\"\"\n",
    "        self.ratio = ratio\n",
    "        \n",
    "    def call(self,\n",
    "             local_tensors,\n",
    "             db_iterator,\n",
    "             tensor_name,\n",
    "             fl_round,\n",
    "             *__):\n",
    "        \"\"\"Aggregate tensors.\n",
    "\n",
    "        Args:\n",
    "            local_tensors(list[openfl.utilities.LocalTensor]): List of local tensors to aggregate.\n",
    "            db_iterator: iterator over history of all tensors. Columns:\n",
    "                - 'tensor_name': name of the tensor.\n",
    "                    Examples for `torch.nn.Module`s: 'conv1.weight', 'fc2.bias'.\n",
    "                - 'round': 0-based number of round corresponding to this tensor.\n",
    "                - 'tags': tuple of tensor tags. Tags that can appear:\n",
    "                    - 'model' indicates that the tensor is a model parameter.\n",
    "                    - 'trained' indicates that tensor is a part of a training result.\n",
    "                        These tensors are passed to the aggregator node after local learning.\n",
    "                    - 'aggregated' indicates that tensor is a result of aggregation.\n",
    "                        These tensors are sent to collaborators for the next round.\n",
    "                    - 'delta' indicates that value is a difference between rounds\n",
    "                        for a specific tensor.\n",
    "                    also one of the tags is a collaborator name\n",
    "                    if it corresponds to a result of a local task.\n",
    "\n",
    "                - 'nparray': value of the tensor.\n",
    "            tensor_name: name of the tensor\n",
    "            fl_round: round number\n",
    "            tags: tuple of tags for this tensor\n",
    "        Returns:\n",
    "            np.ndarray: aggregated tensor\n",
    "        \"\"\"\n",
    "        clipped_tensors = []\n",
    "        previous_tensor_value = None\n",
    "        for record in db_iterator:\n",
    "            if (\n",
    "                record['round'] == (fl_round - 1)\n",
    "                and record['tensor_name'] == tensor_name\n",
    "                and record['tags'] == ('trained',)\n",
    "               ):\n",
    "                previous_tensor_value = record['nparray']\n",
    "        weights = []\n",
    "        for local_tensor in local_tensors:\n",
    "            prev_tensor = previous_tensor_value if previous_tensor_value is not None else local_tensor.tensor\n",
    "            delta = local_tensor.tensor - prev_tensor\n",
    "            new_tensor = prev_tensor + delta * self.ratio\n",
    "            clipped_tensors.append(new_tensor)\n",
    "            weights.append(local_tensor.weight)\n",
    "\n",
    "        return np.average(clipped_tensors, weights=weights, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openfl.interface.aggregation_functions import AggregationFunction\n",
    "\n",
    "class ConditionalThresholdAveraging(AggregationFunction):\n",
    "    def __init__(self, threshold_fn, metric_name='acc', tags=['metric', 'validate_local']):\n",
    "        \"\"\"Average tensors by metric value on previous round.\n",
    "        If no tensors match threshold condition, a simple weighted averaging will be performed.\n",
    "           \n",
    "           Args:\n",
    "               threshold_fn(callable): function to define a threshold for each round.\n",
    "                   Has single argument `round_number`. \n",
    "                   Returns threshold value above which collaborators are allowed to participate in aggregation.\n",
    "               metric_name(str): name of the metric to trace. Can be either 'acc' or 'loss'.\n",
    "               tags(Tuple[str]): tags of the metric tensor.\n",
    "        \"\"\"\n",
    "        self.metric_name = metric_name\n",
    "        self.threshold_fn = threshold_fn\n",
    "        self.tags = tags\n",
    "        self.logged_round = -1\n",
    "        \n",
    "    def call(self,\n",
    "             local_tensors,\n",
    "             db_iterator,\n",
    "             tensor_name,\n",
    "             fl_round,\n",
    "             *__):\n",
    "        \"\"\"Aggregate tensors.\n",
    "\n",
    "        Args:\n",
    "            local_tensors(list[openfl.utilities.LocalTensor]): List of local tensors to aggregate.\n",
    "            db_iterator: iterator over history of all tensors. Columns:\n",
    "                - 'tensor_name': name of the tensor.\n",
    "                    Examples for `torch.nn.Module`s: 'conv1.weight', 'fc2.bias'.\n",
    "                - 'round': 0-based number of round corresponding to this tensor.\n",
    "                - 'tags': tuple of tensor tags. Tags that can appear:\n",
    "                    - 'model' indicates that the tensor is a model parameter.\n",
    "                    - 'trained' indicates that tensor is a part of a training result.\n",
    "                        These tensors are passed to the aggregator node after local learning.\n",
    "                    - 'aggregated' indicates that tensor is a result of aggregation.\n",
    "                        These tensors are sent to collaborators for the next round.\n",
    "                    - 'delta' indicates that value is a difference between rounds\n",
    "                        for a specific tensor.\n",
    "                    also one of the tags is a collaborator name\n",
    "                    if it corresponds to a result of a local task.\n",
    "\n",
    "                - 'nparray': value of the tensor.\n",
    "            tensor_name: name of the tensor\n",
    "            fl_round: round number\n",
    "            tags: tuple of tags for this tensor\n",
    "        Returns:\n",
    "            np.ndarray: aggregated tensor\n",
    "        \"\"\"\n",
    "        selected_tensors = []\n",
    "        selected_weights = []\n",
    "        for record in db_iterator:\n",
    "            for local_tensor in local_tensors:\n",
    "                tags = set(self.tags + [local_tensor.col_name])\n",
    "                if (\n",
    "                    tags <= set(record['tags']) \n",
    "                    and record['round'] == fl_round\n",
    "                    and record['tensor_name'] == self.metric_name\n",
    "                    and record['nparray'] >= self.threshold_fn(fl_round)\n",
    "                ):\n",
    "                    selected_tensors.append(local_tensor.tensor)\n",
    "                    selected_weights.append(local_tensor.weight)\n",
    "        if not selected_tensors:\n",
    "            if self.logged_round < fl_round:\n",
    "                fx.logger.warning('No collaborators match threshold condition. Performing simple averaging...')\n",
    "            selected_tensors = [local_tensor.tensor for local_tensor in local_tensors]\n",
    "            selected_weights = [local_tensor.weight for local_tensor in local_tensors]\n",
    "        if self.logged_round < fl_round:\n",
    "            self.logged_round += 1\n",
    "        return np.average(selected_tensors, weights=selected_weights, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Privileged Aggregation Functions\n",
    "Most of the time the `AggregationFunction` interface is sufficient to implement custom methods, but in certain scenarios users may want to store additional information inside the TensorDB Dataframe beyond the aggregated tensor. The `openfl.interface.aggregation_functions.experimental.PrivilegedAggregationFunction` interface is provided for this use, and gives the user direct access to aggregator's TensorDB dataframe (notice the `tensor_db` param in the call function replaces the `db_iterator` from the standard AggregationFunction interface). As the name suggests, this interface is called privileged because with great power comes great responsibility, and modifying the TensorDB dataframe directly can lead to unexpected behavior and experiment failures if entries are arbitrarily deleted.\n",
    "\n",
    "Note that in-place methods (`.loc`) on the tensor_db dataframe are required for write operations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openfl.interface.aggregation_functions.experimental import PrivilegedAggregationFunction\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "class PrioritizeLeastImproved(PrivilegedAggregationFunction):\n",
    "    \"\"\"\n",
    "        Give collaborator with the least improvement in validation accuracy more influence over future weights\n",
    "        \n",
    "    \"\"\"\n",
    "        \n",
    "    def call(self,\n",
    "             local_tensors,\n",
    "             tensor_db,\n",
    "             tensor_name,\n",
    "             fl_round,\n",
    "             tags):\n",
    "        \"\"\"Aggregate tensors.\n",
    "\n",
    "        Args:\n",
    "            local_tensors(list[openfl.utilities.LocalTensor]): List of local tensors to aggregate.\n",
    "            tensor_db: Aggregator's TensorDB [writable]. Columns:\n",
    "                - 'tensor_name': name of the tensor.\n",
    "                    Examples for `torch.nn.Module`s: 'conv1.weight', 'fc2.bias'.\n",
    "                - 'round': 0-based number of round corresponding to this tensor.\n",
    "                - 'tags': tuple of tensor tags. Tags that can appear:\n",
    "                    - 'model' indicates that the tensor is a model parameter.\n",
    "                    - 'trained' indicates that tensor is a part of a training result.\n",
    "                        These tensors are passed to the aggregator node after local learning.\n",
    "                    - 'aggregated' indicates that tensor is a result of aggregation.\n",
    "                        These tensors are sent to collaborators for the next round.\n",
    "                    - 'delta' indicates that value is a difference between rounds\n",
    "                        for a specific tensor.\n",
    "                    also one of the tags is a collaborator name\n",
    "                    if it corresponds to a result of a local task.\n",
    "\n",
    "                - 'nparray': value of the tensor.\n",
    "            tensor_name: name of the tensor\n",
    "            fl_round: round number\n",
    "            tags: tuple of tags for this tensor\n",
    "        Returns:\n",
    "            np.ndarray: aggregated tensor\n",
    "        \"\"\"\n",
    "        from openfl.utilities import change_tags\n",
    "\n",
    "        tensors, weights, collaborators = zip(*[(x.tensor, x.weight, x.col_name) for idx,x in enumerate(local_tensors)])\n",
    "        tensors, weights, collaborators = np.array(tensors), np.array(weights), collaborators\n",
    "\n",
    "        if fl_round > 0:\n",
    "            metric_tags = ('metric','validate_agg')\n",
    "            collaborator_accuracy = {}\n",
    "            previous_col_accuracy = {}\n",
    "            change_in_accuracy = {}\n",
    "            for col in collaborators:\n",
    "                col_metric_tag = change_tags(metric_tags,add_field=col)\n",
    "                collaborator_accuracy[col] = float(tensor_db[(tensor_db['tensor_name'] == 'acc') &\n",
    "                                                       (tensor_db['round'] == fl_round) &\n",
    "                                                       (tensor_db['tags'] == col_metric_tag)]['nparray'])\n",
    "                previous_col_accuracy[col] = float(tensor_db[(tensor_db['tensor_name'] == 'acc') &\n",
    "                                                       (tensor_db['round'] == fl_round - 1) &\n",
    "                                                       (tensor_db['tags'] == col_metric_tag)]['nparray'])\n",
    "                change_in_accuracy[col] = collaborator_accuracy[col] - previous_col_accuracy[col]\n",
    "                \n",
    "        \n",
    "            least_improved_collaborator = min(change_in_accuracy,key=change_in_accuracy.get)\n",
    "            \n",
    "            # Dont add least improved collaborator more than once\n",
    "            if len(tensor_db[(tensor_db['tags'] == ('least_improved',)) &\n",
    "                         (tensor_db['round'] == fl_round)]) == 0:\n",
    "                tensor_db.loc[tensor_db.shape[0]] = \\\n",
    "                        ['_','_',fl_round,True,('least_improved',),np.array(least_improved_collaborator)]\n",
    "            least_improved_weight_factor = 0.1 * len(tensor_db[(tensor_db['tags'] == ('least_improved',)) &\n",
    "                                                               (tensor_db['nparray'] == np.array(least_improved_collaborator))])\n",
    "            weights[collaborators.index(least_improved_collaborator)] += least_improved_weight_factor\n",
    "            weights = weights / np.sum(weights)\n",
    "            \n",
    "        return np.average(tensors, weights=weights, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make the process of writing, reading from, and searching through dataframes easier, we add three methods to the tensor_db dataframe. `store`, `retrieve`, and `search`. Power users can still use all of the built-in pandas dataframe methods, but because some prior knowledge is needed to effectively deal with dataframe column types, iterating through them, and how to store them in a consistent way that won't break other OpenFL functionality, these three methods provide a conventient way to let researchers focus on algorithms instead internal framework machinery.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FedAvgM_Selection(PrivilegedAggregationFunction):\n",
    "    \"\"\"\n",
    "        Adapted from FeTS Challenge 2021\n",
    "        Federated Brain Tumor Segmentation:Multi-Institutional Privacy-Preserving Collaborative Learning\n",
    "        Ece Isik-Polat, Gorkem Polat,Altan Kocyigit1, and Alptekin Temizel1\n",
    "        \n",
    "    \"\"\"\n",
    "        \n",
    "    def call(\n",
    "             self,\n",
    "             local_tensors,\n",
    "             tensor_db,\n",
    "             tensor_name,\n",
    "             fl_round,\n",
    "             tags):\n",
    "    \n",
    "        \"\"\"Aggregate tensors.\n",
    "\n",
    "        Args:\n",
    "            local_tensors(list[openfl.utilities.LocalTensor]): List of local tensors to aggregate.\n",
    "            tensor_db: Aggregator's TensorDB [writable]. Columns:\n",
    "                - 'tensor_name': name of the tensor.\n",
    "                    Examples for `torch.nn.Module`s: 'conv1.weight', 'fc2.bias'.\n",
    "                - 'round': 0-based number of round corresponding to this tensor.\n",
    "                - 'tags': tuple of tensor tags. Tags that can appear:\n",
    "                    - 'model' indicates that the tensor is a model parameter.\n",
    "                    - 'trained' indicates that tensor is a part of a training result.\n",
    "                        These tensors are passed to the aggregator node after local learning.\n",
    "                    - 'aggregated' indicates that tensor is a result of aggregation.\n",
    "                        These tensors are sent to collaborators for the next round.\n",
    "                    - 'delta' indicates that value is a difference between rounds\n",
    "                        for a specific tensor.\n",
    "                    also one of the tags is a collaborator name\n",
    "                    if it corresponds to a result of a local task.\n",
    "\n",
    "                - 'nparray': value of the tensor.\n",
    "            tensor_name: name of the tensor\n",
    "            fl_round: round number\n",
    "            tags: tuple of tags for this tensor\n",
    "        Returns:\n",
    "            np.ndarray: aggregated tensor\n",
    "        \"\"\"\n",
    "        #momentum\n",
    "        tensor_db.store(tensor_name='momentum',nparray=0.9,overwrite=False)\n",
    "        #aggregator_lr\n",
    "        tensor_db.store(tensor_name='aggregator_lr',nparray=1.0,overwrite=False)\n",
    "\n",
    "        if fl_round == 0:\n",
    "            # Just apply FedAvg\n",
    "\n",
    "            tensor_values = [t.tensor for t in local_tensors]\n",
    "            weight_values = [t.weight for t in local_tensors]               \n",
    "            new_tensor_weight =  np.average(tensor_values, weights=weight_values, axis=0)        \n",
    "\n",
    "            #if not (tensor_name in weight_speeds):\n",
    "            if tensor_name not in tensor_db.search(tags=('weight_speeds',))['tensor_name']:    \n",
    "                #weight_speeds[tensor_name] = np.zeros_like(local_tensors[0].tensor) # weight_speeds[tensor_name] = np.zeros(local_tensors[0].tensor.shape)\n",
    "                tensor_db.store(\n",
    "                    tensor_name=tensor_name, \n",
    "                    tags=('weight_speeds',), \n",
    "                    nparray=np.zeros_like(local_tensors[0].tensor),\n",
    "                )\n",
    "            return new_tensor_weight        \n",
    "        else:\n",
    "            if tensor_name.endswith(\"weight\") or tensor_name.endswith(\"bias\"):\n",
    "                # Calculate aggregator's last value\n",
    "                previous_tensor_value = None\n",
    "                for _, record in tensor_db.iterrows():\n",
    "                    if (record['round'] == fl_round \n",
    "                        and record[\"tensor_name\"] == tensor_name\n",
    "                        and record[\"tags\"] == (\"aggregated\",)): \n",
    "                        previous_tensor_value = record['nparray']\n",
    "                        break\n",
    "\n",
    "                if previous_tensor_value is None:\n",
    "                    logger.warning(\"Error in fedAvgM: previous_tensor_value is None\")\n",
    "                    logger.warning(\"Tensor: \" + tensor_name)\n",
    "\n",
    "                    # Just apply FedAvg       \n",
    "                    tensor_values = [t.tensor for t in local_tensors]\n",
    "                    weight_values = [t.weight for t in local_tensors]               \n",
    "                    new_tensor_weight =  np.average(tensor_values, weights=weight_values, axis=0)        \n",
    "                    \n",
    "                    if tensor_name not in tensor_db.search(tags=('weight_speeds',))['tensor_name']:    \n",
    "                        tensor_db.store(\n",
    "                            tensor_name=tensor_name, \n",
    "                            tags=('weight_speeds',), \n",
    "                            nparray=np.zeros_like(local_tensors[0].tensor),\n",
    "                        )\n",
    "\n",
    "                    return new_tensor_weight\n",
    "                else:\n",
    "                    # compute the average delta for that layer\n",
    "                    deltas = [previous_tensor_value - t.tensor for t in local_tensors]\n",
    "                    weight_values = [t.weight for t in local_tensors]\n",
    "                    average_deltas = np.average(deltas, weights=weight_values, axis=0) \n",
    "\n",
    "                    # V_(t+1) = momentum*V_t + Average_Delta_t\n",
    "                    tensor_weight_speed = tensor_db.retrieve(\n",
    "                        tensor_name=tensor_name,\n",
    "                        tags=('weight_speeds',)\n",
    "                    )\n",
    "                    \n",
    "                    momentum = float(tensor_db.retrieve(tensor_name='momentum'))\n",
    "                    aggregator_lr = float(tensor_db.retrieve(tensor_name='aggregator_lr'))\n",
    "                    \n",
    "                    new_tensor_weight_speed = momentum * tensor_weight_speed + average_deltas # fix delete (1-momentum)\n",
    "                    \n",
    "                    tensor_db.store(\n",
    "                        tensor_name=tensor_name, \n",
    "                        tags=('weight_speeds',), \n",
    "                        nparray=new_tensor_weight_speed\n",
    "                    )\n",
    "                    # W_(t+1) = W_t-lr*V_(t+1)\n",
    "                    new_tensor_weight = previous_tensor_value - aggregator_lr*new_tensor_weight_speed\n",
    "\n",
    "                    return new_tensor_weight\n",
    "            else:\n",
    "                # Just apply FedAvg       \n",
    "                tensor_values = [t.tensor for t in local_tensors]\n",
    "                weight_values = [t.weight for t in local_tensors]               \n",
    "                new_tensor_weight =  np.average(tensor_values, weights=weight_values, axis=0)\n",
    "\n",
    "                return new_tensor_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run experiment, return trained FederatedModel\n",
    "final_fl_model = fx.run_experiment(collaborators,\n",
    "                                   {\n",
    "                                       'aggregator.settings.rounds_to_train':5,\n",
    "                                       'aggregator.settings.db_store_rounds':5,\n",
    "                                       'tasks.train.aggregation_type': ClippedAveraging(ratio=0.9)\n",
    "                                   })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save final model\n",
    "final_fl_model.save_native('final_pytorch_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.7",
   "language": "python",
   "name": "py3.7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

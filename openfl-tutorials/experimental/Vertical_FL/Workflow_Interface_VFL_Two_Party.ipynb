{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b4c42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/securefederatedai/openfl.git\n",
    "!pip install -r ../workflow_interface_requirements.txt\n",
    "!pip install torch\n",
    "!pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "difficult-madrid",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "from time import time\n",
    "from torchvision import datasets, transforms\n",
    "from torch import nn, optim\n",
    "\n",
    "from openfl.experimental.interface import FLSpec, Aggregator, Collaborator\n",
    "from openfl.experimental.runtime import LocalRuntime\n",
    "from openfl.experimental.placement import aggregator, collaborator\n",
    "\n",
    "# Data preprocessing\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5,), (0.5,)),\n",
    "                                ])\n",
    "trainset = datasets.MNIST('mnist', download=True,\n",
    "                          train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    trainset, batch_size=2048, shuffle=False)\n",
    "\n",
    "testset = datasets.MNIST('mnist', download=True,\n",
    "                         train=False, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False)\n",
    "\n",
    "torch.manual_seed(0)  # Define our model segments\n",
    "input_size = 784\n",
    "hidden_sizes = [128, 640]\n",
    "output_size = 10\n",
    "\n",
    "label_model = nn.Sequential(\n",
    "    nn.Linear(hidden_sizes[1], output_size),\n",
    "    nn.LogSoftmax(dim=1)\n",
    ")\n",
    "\n",
    "label_model_optimizer = optim.SGD(label_model.parameters(), lr=0.03)\n",
    "\n",
    "data_model = nn.Sequential(\n",
    "    nn.Linear(input_size, hidden_sizes[0]),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(hidden_sizes[0], hidden_sizes[1]),\n",
    "    nn.ReLU(),\n",
    ")\n",
    "\n",
    "data_model_optimizer = optim.SGD(data_model.parameters(), lr=0.03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forward-world",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VerticalTwoPartyFlow(FLSpec):\n",
    "\n",
    "    def __init__(self, batch_num):\n",
    "        super().__init__()\n",
    "        self.batch_num = batch_num\n",
    "\n",
    "    @aggregator\n",
    "    def start(self):\n",
    "        self.collaborators = self.runtime.collaborators\n",
    "        print(f'Batch_num = {self.batch_num}')\n",
    "        # 1) Zero the gradients\n",
    "        self.label_model_optimizer.zero_grad()\n",
    "        self.next(self.data_model_forward_pass, foreach='collaborators')\n",
    "\n",
    "    @collaborator\n",
    "    def data_model_forward_pass(self):\n",
    "        self.data_model_output_local = ''\n",
    "        for idx, (images, _) in enumerate(self.trainloader):\n",
    "            if idx < self.batch_num:\n",
    "                continue\n",
    "            self.data_model_optimizer.zero_grad()\n",
    "            images = images.view(images.shape[0], -1)\n",
    "            model_output = self.data_model(images)\n",
    "            self.data_model_output_local = model_output\n",
    "            self.data_model_output = model_output.detach().requires_grad_()\n",
    "            break\n",
    "        self.next(self.label_model_forward_pass)\n",
    "                  #exclude=['data_model_output_local'])\n",
    "\n",
    "    @aggregator\n",
    "    def label_model_forward_pass(self, inputs):\n",
    "        criterion = nn.NLLLoss()\n",
    "        self.grad_to_local = []\n",
    "        total_loss = 0\n",
    "        self.data_remaining = False\n",
    "        for idx, (_, labels) in enumerate(self.trainloader):\n",
    "            if idx < self.batch_num:\n",
    "                continue\n",
    "            self.data_remaining = True\n",
    "            pred = self.label_model(inputs[0].data_model_output)\n",
    "            loss = criterion(pred, labels)\n",
    "            loss.backward()\n",
    "            self.grad_to_local = inputs[0].data_model_output.grad.clone()\n",
    "            self.label_model_optimizer.step()\n",
    "            total_loss += loss\n",
    "            break\n",
    "        print(f'Total loss = {total_loss}')  # / len(self.trainloader)}')\n",
    "        self.next(self.data_model_backprop, foreach='collaborators')\n",
    "\n",
    "    @collaborator\n",
    "    def data_model_backprop(self):\n",
    "        if self.data_remaining:\n",
    "            self.data_model_optimizer = optim.SGD(self.data_model.parameters(), lr=0.03)\n",
    "            self.data_model_optimizer.zero_grad()\n",
    "            self.data_model_output_local.backward(self.grad_to_local)\n",
    "            self.data_model_optimizer.step()\n",
    "        self.next(self.join)\n",
    "\n",
    "    @aggregator\n",
    "    def join(self, inputs):\n",
    "        print(f'Join batch_num = {self.batch_num}')\n",
    "        self.batch_num += 1\n",
    "        self.next(self.end)\n",
    "\n",
    "    @aggregator\n",
    "    def end(self):\n",
    "        print(f'This is the end of the flow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59aff1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup participants\n",
    "aggregator = Aggregator()\n",
    "\n",
    "def callable_to_initialize_aggregator_private_attributes(train_loader,label_model,label_model_optimizer):\n",
    "        return {\"trainloader\": train_loader,\n",
    "                \"label_model\" : label_model,\n",
    "                \"label_model_optimizer\":label_model_optimizer\n",
    "                }  \n",
    "\n",
    "# Setup aggregator private attributes via callable function\n",
    "aggregator = Aggregator(\n",
    "    name=\"agg\",\n",
    "    private_attributes_callable=callable_to_initialize_aggregator_private_attributes,\n",
    "    train_loader = trainloader,\n",
    "    label_model=label_model,\n",
    "    label_model_optimizer=label_model_optimizer\n",
    ")\n",
    "\n",
    "# Setup collaborators private attributes via callable function\n",
    "collaborator_names = ['Portland']\n",
    "\n",
    "def callable_to_initialize_collaborator_private_attributes(index,data_model,data_model_optimizer,train_loader):\n",
    "    return {\n",
    "        \"data_model\": data_model,\n",
    "        \"data_model_optimizer\": data_model_optimizer,\n",
    "        \"trainloader\" : deepcopy(train_loader)\n",
    "    }\n",
    "\n",
    "collaborators = []\n",
    "for idx, collaborator_name in enumerate(collaborator_names):\n",
    "        collaborators.append(\n",
    "            Collaborator(\n",
    "                name=collaborator_name,\n",
    "                private_attributes_callable=callable_to_initialize_collaborator_private_attributes,\n",
    "                index=idx,\n",
    "                data_model = data_model,\n",
    "                data_model_optimizer = data_model_optimizer,\n",
    "                train_loader = trainloader\n",
    "            )\n",
    "        )\n",
    "\n",
    "local_runtime = LocalRuntime(\n",
    "    aggregator=aggregator, collaborators=collaborators, backend='ray')\n",
    "print(f'Local runtime collaborators = {local_runtime.collaborators}')\n",
    "\n",
    "epochs = 100\n",
    "batch_num = 0\n",
    "for i in range(epochs):\n",
    "    print(f'Starting round {i}')\n",
    "    data_remaining = True\n",
    "    vflow = VerticalTwoPartyFlow(batch_num=0)\n",
    "    vflow.runtime = local_runtime\n",
    "    while data_remaining:\n",
    "        vflow.run()\n",
    "        batch_num = vflow.batch_num\n",
    "        data_remaining = vflow.data_remaining\n",
    "        print(f'Continuing training loop: batch_num = {batch_num}')\n",
    "    vflow.batch_num = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "verified-favor",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_id = vflow._run_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statutory-prime",
   "metadata": {},
   "outputs": [],
   "source": [
    "from metaflow import Metaflow, Flow, Task, Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fifty-tamil",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Metaflow()\n",
    "list(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grand-defendant",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = Flow('VerticalTwoPartyFlow').latest_run"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

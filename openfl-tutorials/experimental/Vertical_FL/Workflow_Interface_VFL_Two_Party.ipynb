{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b4c42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/intel/openfl.git\n",
    "!pip install -r ../requirements_workflow_interface.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "difficult-madrid",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "from time import time\n",
    "from torchvision import datasets, transforms\n",
    "from torch import nn, optim\n",
    "\n",
    "from openfl.experimental.interface import FLSpec, Aggregator, Collaborator\n",
    "from openfl.experimental.runtime import LocalRuntime\n",
    "from openfl.experimental.placement import aggregator, collaborator\n",
    "\n",
    "# Data preprocessing\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5,), (0.5,)),\n",
    "                                ])\n",
    "trainset = datasets.MNIST('mnist', download=True,\n",
    "                          train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    trainset, batch_size=2048, shuffle=False)\n",
    "\n",
    "testset = datasets.MNIST('mnist', download=True,\n",
    "                         train=False, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False)\n",
    "\n",
    "torch.manual_seed(0)  # Define our model segments\n",
    "input_size = 784\n",
    "hidden_sizes = [128, 640]\n",
    "output_size = 10\n",
    "\n",
    "label_model = nn.Sequential(\n",
    "    nn.Linear(hidden_sizes[1], output_size),\n",
    "    nn.LogSoftmax(dim=1)\n",
    ")\n",
    "\n",
    "label_model_optimizer = optim.SGD(label_model.parameters(), lr=0.03)\n",
    "\n",
    "data_model = nn.Sequential(\n",
    "    nn.Linear(input_size, hidden_sizes[0]),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(hidden_sizes[0], hidden_sizes[1]),\n",
    "    nn.ReLU(),\n",
    ")\n",
    "\n",
    "data_model_optimizer = optim.SGD(data_model.parameters(), lr=0.03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forward-world",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VerticalTwoPartyFlow(FLSpec):\n",
    "\n",
    "    def __init__(self, batch_num):\n",
    "        super().__init__()\n",
    "        self.batch_num = batch_num\n",
    "\n",
    "    @aggregator\n",
    "    def start(self):\n",
    "        self.collaborators = self.runtime.collaborators\n",
    "        print(f'Batch_num = {self.batch_num}')\n",
    "        # 1) Zero the gradients\n",
    "        self.label_model_optimizer.zero_grad()\n",
    "        self.next(self.data_model_forward_pass, foreach='collaborators')\n",
    "\n",
    "    @collaborator\n",
    "    def data_model_forward_pass(self):\n",
    "        self.data_model_output_local = ''\n",
    "        for idx, (images, _) in enumerate(self.trainloader):\n",
    "            if idx < self.batch_num:\n",
    "                continue\n",
    "            self.data_model_optimizer.zero_grad()\n",
    "            images = images.view(images.shape[0], -1)\n",
    "            model_output = self.data_model(images)\n",
    "            self.data_model_output_local = model_output\n",
    "            self.data_model_output = model_output.detach().requires_grad_()\n",
    "            break\n",
    "        self.next(self.label_model_forward_pass)\n",
    "                  #exclude=['data_model_output_local'])\n",
    "\n",
    "    @aggregator\n",
    "    def label_model_forward_pass(self, inputs):\n",
    "        criterion = nn.NLLLoss()\n",
    "        self.grad_to_local = []\n",
    "        total_loss = 0\n",
    "        self.data_remaining = False\n",
    "        for idx, (_, labels) in enumerate(self.trainloader):\n",
    "            if idx < self.batch_num:\n",
    "                continue\n",
    "            self.data_remaining = True\n",
    "            pred = self.label_model(inputs[0].data_model_output)\n",
    "            loss = criterion(pred, labels)\n",
    "            loss.backward()\n",
    "            self.grad_to_local = inputs[0].data_model_output.grad.clone()\n",
    "            self.label_model_optimizer.step()\n",
    "            total_loss += loss\n",
    "            break\n",
    "        print(f'Total loss = {total_loss}')  # / len(self.trainloader)}')\n",
    "        self.next(self.data_model_backprop, foreach='collaborators')\n",
    "\n",
    "    @collaborator\n",
    "    def data_model_backprop(self):\n",
    "        if self.data_remaining:\n",
    "            self.data_model_optimizer = optim.SGD(self.data_model.parameters(), lr=0.03)\n",
    "            self.data_model_optimizer.zero_grad()\n",
    "            self.data_model_output_local.backward(self.grad_to_local)\n",
    "            self.data_model_optimizer.step()\n",
    "        self.next(self.join)\n",
    "\n",
    "    @aggregator\n",
    "    def join(self, inputs):\n",
    "        print(f'Join batch_num = {self.batch_num}')\n",
    "        self.batch_num += 1\n",
    "        self.next(self.end)\n",
    "\n",
    "    @aggregator\n",
    "    def end(self):\n",
    "        print(f'This is the end of the flow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59aff1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup participants\n",
    "aggregator = Aggregator()\n",
    "aggregator.private_attributes['trainloader'] = trainloader\n",
    "aggregator.private_attributes['label_model'] = label_model\n",
    "aggregator.private_attributes['label_model_optimizer'] = label_model_optimizer\n",
    "\n",
    "# Setup collaborators with private attributes\n",
    "collaborator_names = ['Portland']\n",
    "collaborators = [Collaborator(name=name) for name in collaborator_names]\n",
    "\n",
    "for idx, collaborator in enumerate(collaborators):\n",
    "    collaborator.private_attributes['data_model'] = data_model\n",
    "    collaborator.private_attributes['data_model_optimizer'] = data_model_optimizer\n",
    "    collaborator.private_attributes['trainloader'] = deepcopy(trainloader)\n",
    "\n",
    "local_runtime = LocalRuntime(\n",
    "    aggregator=aggregator, collaborators=collaborators, backend='single_process')\n",
    "print(f'Local runtime collaborators = {local_runtime.collaborators}')\n",
    "\n",
    "epochs = 100\n",
    "batch_num = 0\n",
    "for i in range(epochs):\n",
    "    print(f'Starting round {i}')\n",
    "    data_remaining = True\n",
    "    vflow = VerticalTwoPartyFlow(batch_num=0)\n",
    "    vflow.runtime = local_runtime\n",
    "    while data_remaining:\n",
    "        vflow.run()\n",
    "        batch_num = vflow.batch_num\n",
    "        data_remaining = vflow.data_remaining\n",
    "        print(f'Continuing training loop: batch_num = {batch_num}')\n",
    "    vflow.batch_num = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "verified-favor",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_id = vflow._run_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "composed-burst",
   "metadata": {},
   "outputs": [],
   "source": [
    "import metaflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statutory-prime",
   "metadata": {},
   "outputs": [],
   "source": [
    "from metaflow import Metaflow, Flow, Task, Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fifty-tamil",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Metaflow()\n",
    "list(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grand-defendant",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = Flow('VerticalTwoPartyFlow').latest_run"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

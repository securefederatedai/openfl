{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dc13070c",
   "metadata": {},
   "source": [
    "# Workflow Interface 1001: Workspace Creation from Jupyter Notebook"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8f28c451",
   "metadata": {},
   "source": [
    "This tutorial demonstrates the methodology to convert a Federated Learning experiment developed in Jupyter Notebook into a Workspace that can be deployed using Aggregator Based Workflow\n",
    "\n",
    "OpenFL experimental Workflow Interface enables the user to simulate a Federated Learning experiment using **LocalRuntime**. Once the simulation is ready, the methodology described in this tutorial enables the user to convert this experiment into an OpenFL workspace that can be deployed using the Aggregator-Based-Workflow\n",
    "\n",
    "##### High Level Overview of Methodology\n",
    "1. User annotates the relevant cells of the Jupyter notebook with `#| export` directive\n",
    "2. We then Leverage `nbdev` functionality to export these annotated cells of Jupyter notebook into a Python script\n",
    "3. Utilize OpenFL experimental module `WorkspaceExport` to convert the Python script into a OpenFL workspace\n",
    "4. User can utilize the experimental `fx` commands to deploy and run the federation seamlessly\n",
    "\n",
    "\n",
    "The methodology is described using an existing [OpenFL Watermarking Tutorial](https://github.com/securefederatedai/openfl/blob/develop/openfl-tutorials/experimental/Workflow_Interface_301_MNIST_Watermarking.ipynb). Let's get started !\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a4394089",
   "metadata": {},
   "source": [
    "# Getting Started"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "857f9995",
   "metadata": {},
   "source": [
    "Initially, we start by specifying the module where cells marked with the `#| export` directive will be automatically exported. \n",
    "\n",
    "In the following cell, `#| default_exp experiment `indicates that the exported file will be named 'experiment'. This name can be modified based on user's requirement & preferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79eacbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62449b5f",
   "metadata": {},
   "source": [
    "Once we have specified the name of the module, subsequent cells of the notebook need to be *appended* by the `#| export` directive as shown below. User should ensure that *all* the notebook functionality required in the Federated Learning experiment is included in this directive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e19dcf2",
   "metadata": {},
   "source": [
    "We start by installing OpenFL and dependencies of the workflow interface \n",
    "> These dependencies are required to be exported and become the requirements for the Federated Learning Workspace "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7475cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "!pip install git+https://github.com/securefederatedai/openfl.git\n",
    "!pip install -r workflow_interface_requirements.txt\n",
    "\n",
    "!pip install matplotlib\n",
    "!pip install torch\n",
    "!pip install torchvision\n",
    "!pip install git+https://github.com/pyviz-topics/imagen.git@master\n",
    "!pip install holoviews==1.15.4\n",
    "\n",
    "\n",
    "# Uncomment this if running in Google Colab\n",
    "#!pip install -r https://raw.githubusercontent.com/intel/openfl/develop/openfl-tutorials/experimental/workflow_interface_requirements.txt\n",
    "#import os\n",
    "#os.environ[\"USERNAME\"] = \"colab\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6ae8e2",
   "metadata": {},
   "source": [
    "We now define our dataloaders, model, optimizer, and some helper functions like we would for any other deep learning experiment \n",
    "\n",
    "> This cell and all the subsequent cells are important ingredients of the Federated Learning experiment and therefore annotated with the `#| export` directive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd8ac2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import random\n",
    "import pathlib\n",
    "import os\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL.Image as Image\n",
    "import imagen as ig\n",
    "import numbergen as ng\n",
    "import os\n",
    "\n",
    "random_seed = 1\n",
    "torch.backends.cudnn.enabled = False\n",
    "torch.manual_seed(random_seed)\n",
    "\n",
    "# MNIST Train and Test datasets\n",
    "mnist_train = torchvision.datasets.MNIST(\n",
    "    \"./files/\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=torchvision.transforms.Compose(\n",
    "        [\n",
    "            torchvision.transforms.ToTensor(),\n",
    "            torchvision.transforms.Normalize((0.1307,), (0.3081,)),\n",
    "        ]\n",
    "    ),\n",
    ")\n",
    "\n",
    "mnist_test = torchvision.datasets.MNIST(\n",
    "    \"./files/\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=torchvision.transforms.Compose(\n",
    "        [\n",
    "            torchvision.transforms.ToTensor(),\n",
    "            torchvision.transforms.Normalize((0.1307,), (0.3081,)),\n",
    "        ]\n",
    "    ),\n",
    ")\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, dropout=0.0):\n",
    "        super(Net, self).__init__()\n",
    "        self.dropout = dropout\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 2),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, 2),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 128, 2),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.fc1 = nn.Linear(128 * 5**2, 200)\n",
    "        self.fc2 = nn.Linear(200, 10)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.dropout(x)\n",
    "        out = self.block(x)\n",
    "        out = out.view(-1, 128 * 5**2)\n",
    "        out = self.dropout(out)\n",
    "        out = self.relu(self.fc1(out))\n",
    "        out = self.dropout(out)\n",
    "        out = self.fc2(out)\n",
    "        return F.log_softmax(out, 1)\n",
    "\n",
    "\n",
    "def inference(network, test_loader):\n",
    "    network.eval()\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            output = network(data)\n",
    "            pred = output.data.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "    accuracy = float(correct / len(test_loader.dataset))\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "def train_model(model, optimizer, data_loader, entity, round_number, log=False):\n",
    "    # Helper function to train the model\n",
    "    train_loss = 0\n",
    "    log_interval = 20\n",
    "    model.train()\n",
    "    for batch_idx, (X, y) in enumerate(data_loader):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = model(X)\n",
    "        loss = F.nll_loss(output, y)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item() * len(X)\n",
    "        if batch_idx % log_interval == 0 and log:\n",
    "            print(\"{:<20} Train Epoch: {:<3} [{:<3}/{:<4} ({:<.0f}%)] Loss: {:<.6f}\".format(\n",
    "                    entity,\n",
    "                    round_number,\n",
    "                    batch_idx * len(X),\n",
    "                    len(data_loader.dataset),\n",
    "                    100.0 * batch_idx / len(data_loader),\n",
    "                    loss.item(),\n",
    "                )\n",
    "            )\n",
    "    train_loss /= len(data_loader.dataset)\n",
    "    return train_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d907d9",
   "metadata": {},
   "source": [
    "Next we define the dataset required for watermarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcad2624",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "watermark_dir = \"./files/watermark-dataset/MWAFFLE/\"\n",
    "\n",
    "\n",
    "def generate_watermark(\n",
    "    x_size=28, y_size=28, num_class=10, num_samples_per_class=10, img_dir=watermark_dir\n",
    "):\n",
    "    \"\"\"\n",
    "    Generate Watermark by superimposing a pattern on noisy background.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x_size: x dimension of the image\n",
    "    y_size: y dimension of the image\n",
    "    num_class: number of classes in the original dataset\n",
    "    num_samples_per_class: number of samples to be generated per class\n",
    "    img_dir: directory for saving watermark dataset\n",
    "\n",
    "    Reference\n",
    "    ---------\n",
    "    WAFFLE: Watermarking in Federated Learning (https://arxiv.org/abs/2008.07298)\n",
    "\n",
    "    \"\"\"\n",
    "    x_pattern = int(x_size * 2 / 3.0 - 1)\n",
    "    y_pattern = int(y_size * 2 / 3.0 - 1)\n",
    "\n",
    "    np.random.seed(0)\n",
    "    for cls in range(num_class):\n",
    "        patterns = []\n",
    "        random_seed = 10 + cls\n",
    "        patterns.append(\n",
    "            ig.Line(\n",
    "                xdensity=x_pattern,\n",
    "                ydensity=y_pattern,\n",
    "                thickness=0.001,\n",
    "                orientation=np.pi * ng.UniformRandom(seed=random_seed),\n",
    "                x=ng.UniformRandom(seed=random_seed) - 0.5,\n",
    "                y=ng.UniformRandom(seed=random_seed) - 0.5,\n",
    "                scale=0.8,\n",
    "            )\n",
    "        )\n",
    "        patterns.append(\n",
    "            ig.Arc(\n",
    "                xdensity=x_pattern,\n",
    "                ydensity=y_pattern,\n",
    "                thickness=0.001,\n",
    "                orientation=np.pi * ng.UniformRandom(seed=random_seed),\n",
    "                x=ng.UniformRandom(seed=random_seed) - 0.5,\n",
    "                y=ng.UniformRandom(seed=random_seed) - 0.5,\n",
    "                size=0.33,\n",
    "            )\n",
    "        )\n",
    "\n",
    "        pat = np.zeros((x_pattern, y_pattern))\n",
    "        for i in range(6):\n",
    "            j = np.random.randint(len(patterns))\n",
    "            pat += patterns[j]()\n",
    "        res = pat > 0.5\n",
    "        pat = res.astype(int)\n",
    "\n",
    "        x_offset = np.random.randint(x_size - x_pattern + 1)\n",
    "        y_offset = np.random.randint(y_size - y_pattern + 1)\n",
    "\n",
    "        for i in range(num_samples_per_class):\n",
    "            base = np.random.rand(x_size, y_size)\n",
    "            # base = np.zeros((x_input, y_input))\n",
    "            base[\n",
    "                x_offset : x_offset + pat.shape[0],\n",
    "                y_offset : y_offset + pat.shape[1],\n",
    "            ] += pat\n",
    "            d = np.ones((x_size, x_size))\n",
    "            img = np.minimum(base, d)\n",
    "            if not os.path.exists(img_dir + str(cls) + \"/\"):\n",
    "                os.makedirs(img_dir + str(cls) + \"/\")\n",
    "            plt.imsave(\n",
    "                img_dir + str(cls) + \"/wm_\" + str(i + 1) + \".png\",\n",
    "                img,\n",
    "                cmap=matplotlib.cm.gray,\n",
    "            )\n",
    "\n",
    "\n",
    "# If the Watermark dataset does not exist, generate and save the Watermark images\n",
    "watermark_path = pathlib.Path(watermark_dir)\n",
    "if watermark_path.exists() and watermark_path.is_dir():\n",
    "    print(\n",
    "        f\"Watermark dataset already exists at: {watermark_path}. Proceeding to next step ... \"\n",
    "    )\n",
    "    pass\n",
    "else:\n",
    "    print(f\"Generating Watermark dataset... \")\n",
    "    generate_watermark()\n",
    "\n",
    "\n",
    "class WatermarkDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, images_dir, label_dir=None, transforms=None):\n",
    "        self.images_dir = os.path.abspath(images_dir)\n",
    "        self.image_paths = [\n",
    "            os.path.join(self.images_dir, d) for d in os.listdir(self.images_dir)\n",
    "        ]\n",
    "        self.label_paths = label_dir\n",
    "        self.transform = transforms\n",
    "        temp = []\n",
    "\n",
    "        # Recursively counting total number of images in the directory\n",
    "        for image_path in self.image_paths:\n",
    "            for path in os.walk(image_path):\n",
    "                if len(path) <= 1:\n",
    "                    continue\n",
    "                path = path[2]\n",
    "                for im_n in [image_path + \"/\" + p for p in path]:\n",
    "                    temp.append(im_n)\n",
    "        self.image_paths = temp\n",
    "\n",
    "        if len(self.image_paths) == 0:\n",
    "            raise Exception(f\"No file(s) found under {images_dir}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_filepath = self.image_paths[idx]\n",
    "        image = Image.open(image_filepath)\n",
    "        image = image.convert(\"RGB\")\n",
    "        image = self.transform(image)\n",
    "        label = int(image_filepath.split(\"/\")[-2])\n",
    "\n",
    "        return image, label\n",
    "\n",
    "\n",
    "def get_watermark_transforms():\n",
    "    return torchvision.transforms.Compose(\n",
    "        [\n",
    "            torchvision.transforms.Grayscale(),\n",
    "            torchvision.transforms.Resize(28),\n",
    "            torchvision.transforms.ToTensor(),\n",
    "            torchvision.transforms.Normalize(mean=(0.5,), std=(0.5,)),  # Normalize\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "watermark_data = WatermarkDataset(\n",
    "    images_dir=watermark_dir,\n",
    "    transforms=get_watermark_transforms(),\n",
    ")\n",
    "\n",
    "# Set display_watermark to True to display the Watermark dataset\n",
    "display_watermark = False\n",
    "if display_watermark:\n",
    "    # Inspect and plot the Watermark Images\n",
    "    wm_images = np.empty((100, 28, 28))\n",
    "    wm_labels = np.empty([100, 1], dtype=int)\n",
    "\n",
    "    for i in range(len(watermark_data)):\n",
    "        img, label = watermark_data[i]\n",
    "        wm_labels[label * 10 + i % 10] = label\n",
    "        wm_images[label * 10 + i % 10, :, :] = img.numpy()\n",
    "\n",
    "    fig = plt.figure(figsize=(120, 120))\n",
    "    for i in range(100):\n",
    "        plt.subplot(10, 10, i + 1)\n",
    "        plt.imshow(wm_images[i], interpolation=\"none\")\n",
    "        plt.title(\"Label: {}\".format(wm_labels[i]), fontsize=80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0849d57",
   "metadata": {},
   "source": [
    "Next we import the `FLSpec`, `LocalRuntime`, placement decorators (`aggregator/collaborator`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89cf4866",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "from openfl.experimental.interface import FLSpec, Aggregator, Collaborator\n",
    "from openfl.experimental.runtime import LocalRuntime\n",
    "from openfl.experimental.placement import aggregator, collaborator\n",
    "\n",
    "def FedAvg(agg_model, models, weights=None):\n",
    "    state_dicts = [model.state_dict() for model in models]\n",
    "    state_dict = agg_model.state_dict()\n",
    "    for key in models[0].state_dict():\n",
    "        state_dict[key] = torch.from_numpy(np.average([state[key].numpy() for state in state_dicts],\n",
    "                                                      axis=0, \n",
    "                                                      weights=weights))\n",
    "        \n",
    "    agg_model.load_state_dict(state_dict)\n",
    "    return agg_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ed5e31",
   "metadata": {},
   "source": [
    "Let us now define the Workflow for Watermark embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c4a752",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class FederatedFlow_MNIST_Watermarking(FLSpec):\n",
    "    \"\"\"\n",
    "    This Flow demonstrates Watermarking on a Deep Learning Model in Federated Learning\n",
    "    Ref: WAFFLE: Watermarking in Federated Learning (https://arxiv.org/abs/2008.07298)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        model=None,\n",
    "        optimizer=None,\n",
    "        watermark_pretrain_optimizer=None,\n",
    "        watermark_retrain_optimizer=None,\n",
    "        round_number=0,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        if model is not None:\n",
    "            self.model = model\n",
    "            self.optimizer = optimizer\n",
    "            self.watermark_pretrain_optimizer = watermark_pretrain_optimizer\n",
    "            self.watermark_retrain_optimizer = watermark_retrain_optimizer\n",
    "        else:\n",
    "            self.model = Net()\n",
    "            self.optimizer = optim.SGD(\n",
    "                self.model.parameters(), lr=learning_rate, momentum=momentum\n",
    "            )\n",
    "            self.watermark_pretrain_optimizer = optim.SGD(\n",
    "                self.model.parameters(),\n",
    "                lr=watermark_pretrain_learning_rate,\n",
    "                momentum=watermark_pretrain_momentum,\n",
    "                weight_decay=watermark_pretrain_weight_decay,\n",
    "            )\n",
    "            self.watermark_retrain_optimizer = optim.SGD(\n",
    "                self.model.parameters(), lr=watermark_retrain_learning_rate\n",
    "            )\n",
    "        self.round_number = round_number\n",
    "        self.watermark_pretraining_completed = False\n",
    "\n",
    "    @aggregator\n",
    "    def start(self):\n",
    "        \"\"\"\n",
    "        This is the start of the Flow.\n",
    "        \"\"\"\n",
    "\n",
    "        print(f\"<Agg>: Start of flow ... \")\n",
    "        self.collaborators = self.runtime.collaborators\n",
    "\n",
    "        # Randomly select a fraction of actual collaborator every round\n",
    "        fraction = 0.5\n",
    "        if int(fraction * len(self.collaborators)) < 1:\n",
    "            raise Exception(\n",
    "                f\"Cannot run training with {fraction*100}% selected collaborators out of {len(self.collaborators)} Collaborators. Atleast one collaborator is required to run the training\"\n",
    "            )\n",
    "        self.subset_collaborators = random.sample(\n",
    "            self.collaborators, int(fraction * (len(self.collaborators)))\n",
    "        )\n",
    "\n",
    "        self.next(self.watermark_pretrain)\n",
    "\n",
    "    @aggregator\n",
    "    def watermark_pretrain(self):\n",
    "        \"\"\"\n",
    "        Pre-Train the Model before starting Federated Learning.\n",
    "        \"\"\"\n",
    "        if not self.watermark_pretraining_completed:\n",
    "\n",
    "            print(\"<Agg>: Performing Watermark Pre-training\")\n",
    "\n",
    "            for i in range(self.pretrain_epochs):\n",
    "\n",
    "                watermark_pretrain_loss = train_model(\n",
    "                    self.model,\n",
    "                    self.watermark_pretrain_optimizer,\n",
    "                    self.watermark_data_loader,\n",
    "                    \"<Agg>:\",\n",
    "                    i,\n",
    "                    log=False,\n",
    "                )\n",
    "                watermark_pretrain_validation_score = inference(\n",
    "                    self.model, self.watermark_data_loader\n",
    "                )\n",
    "\n",
    "                print(\n",
    "                    \"<Agg>: Watermark Pretraining: Round: {:<3} Loss: {:<.6f} Acc: {:<.6f}\".format(\n",
    "                        i,\n",
    "                        watermark_pretrain_loss,\n",
    "                        watermark_pretrain_validation_score,\n",
    "                    )\n",
    "                )\n",
    "\n",
    "            self.watermark_pretraining_completed = True\n",
    "\n",
    "        self.next(\n",
    "            self.aggregated_model_validation,\n",
    "            foreach=\"subset_collaborators\",\n",
    "            exclude=[\"watermark_pretrain_optimizer\", \"watermark_retrain_optimizer\"],\n",
    "        )\n",
    "\n",
    "    @collaborator\n",
    "    def aggregated_model_validation(self):\n",
    "        \"\"\"\n",
    "        Perform Aggregated Model validation on Collaborators.\n",
    "        \"\"\"\n",
    "        self.agg_validation_score = inference(self.model, self.test_loader)\n",
    "        print(\n",
    "            f\"<Collab: {self.input}> Aggregated Model validation score = {self.agg_validation_score}\"\n",
    "        )\n",
    "\n",
    "        self.next(self.train)\n",
    "\n",
    "    @collaborator\n",
    "    def train(self):\n",
    "        \"\"\"\n",
    "        Train model on Local collab dataset.\n",
    "\n",
    "        \"\"\"\n",
    "        print(\"<Collab>: Performing Model Training on Local dataset ... \")\n",
    "\n",
    "        self.optimizer = optim.SGD(\n",
    "            self.model.parameters(), lr=learning_rate, momentum=momentum\n",
    "        )\n",
    "\n",
    "        self.loss = train_model(\n",
    "            self.model,\n",
    "            self.optimizer,\n",
    "            self.train_loader,\n",
    "            \"<Collab: {:<20}\".format(self.input + \">\"),\n",
    "            self.round_number if self.round_number is not None else 0,\n",
    "            log=True,\n",
    "        )\n",
    "\n",
    "        self.next(self.local_model_validation)\n",
    "\n",
    "    @collaborator\n",
    "    def local_model_validation(self):\n",
    "        \"\"\"\n",
    "        Validate locally trained model.\n",
    "\n",
    "        \"\"\"\n",
    "        self.local_validation_score = inference(self.model, self.test_loader)\n",
    "        print(\n",
    "            f\"<Collab: {self.input}> Local model validation score = {self.local_validation_score}\"\n",
    "        )\n",
    "        self.next(self.join)\n",
    "\n",
    "    @aggregator\n",
    "    def join(self, inputs):\n",
    "        \"\"\"\n",
    "        Model aggregation step.\n",
    "        \"\"\"\n",
    "\n",
    "        self.average_loss = sum(input.loss for input in inputs) / len(inputs)\n",
    "        self.aggregated_model_accuracy = sum(\n",
    "            input.agg_validation_score for input in inputs\n",
    "        ) / len(inputs)\n",
    "        self.local_model_accuracy = sum(\n",
    "            input.local_validation_score for input in inputs\n",
    "        ) / len(inputs)\n",
    "\n",
    "        print(f\"<Agg>: Joining models from collaborators...\")\n",
    "\n",
    "        print(\n",
    "            f\"   Aggregated model validation score = {self.aggregated_model_accuracy}\"\n",
    "        )\n",
    "        print(f\"   Average training loss = {self.average_loss}\")\n",
    "        print(f\"   Average local model validation values = {self.local_model_accuracy}\")\n",
    "\n",
    "        self.model = FedAvg(self.model, [input.model for input in inputs])\n",
    "\n",
    "        self.next(self.watermark_retrain)\n",
    "\n",
    "    @aggregator\n",
    "    def watermark_retrain(self):\n",
    "        \"\"\"\n",
    "        Retrain the aggregated model.\n",
    "\n",
    "        \"\"\"\n",
    "        print(\"<Agg>: Performing Watermark Retraining ... \")\n",
    "        self.watermark_retrain_optimizer = optim.SGD(\n",
    "            self.model.parameters(), lr=watermark_retrain_learning_rate\n",
    "        )\n",
    "\n",
    "        retrain_round = 0\n",
    "\n",
    "        # Perform re-training until (accuracy >= acc_threshold) or (retrain_round > number of retrain_epochs)\n",
    "        self.watermark_retrain_validation_score = inference(\n",
    "            self.model, self.watermark_data_loader\n",
    "        )\n",
    "        while (\n",
    "            self.watermark_retrain_validation_score < self.watermark_acc_threshold\n",
    "        ) and (retrain_round < self.retrain_epochs):\n",
    "            self.watermark_retrain_train_loss = train_model(\n",
    "                self.model,\n",
    "                self.watermark_retrain_optimizer,\n",
    "                self.watermark_data_loader,\n",
    "                \"<Agg>\",\n",
    "                retrain_round,\n",
    "                log=False,\n",
    "            )\n",
    "            self.watermark_retrain_validation_score = inference(\n",
    "                self.model, self.watermark_data_loader\n",
    "            )\n",
    "\n",
    "            print(\n",
    "                \"<Agg>: Watermark Retraining: Train Epoch: {:<3} Retrain Round: {:<3} Loss: {:<.6f}, Acc: {:<.6f}\".format(\n",
    "                    self.round_number,\n",
    "                    retrain_round,\n",
    "                    self.watermark_retrain_train_loss,\n",
    "                    self.watermark_retrain_validation_score,\n",
    "                )\n",
    "            )\n",
    "\n",
    "            retrain_round += 1\n",
    "\n",
    "        self.next(self.end)\n",
    "\n",
    "    @aggregator\n",
    "    def end(self):\n",
    "        \"\"\"\n",
    "        This is the last step in the Flow.\n",
    "\n",
    "        \"\"\"\n",
    "        print(f\"This is the end of the flow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d1bba1a",
   "metadata": {},
   "source": [
    "We now initialize certain attributes of the Flow, simulation parameters (seed, batch-sizes, optimizer parameters) and create the `LocalRuntime`\n",
    "\n",
    "> NOTE: Aggregator based workflow requires a `FederatedRuntime`. In this methodology `FederatedRuntime` is created automatically and it's usage is transparent to the user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bffcc141",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "# Set random seed\n",
    "random_seed = 42\n",
    "torch.manual_seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "torch.backends.cudnn.enabled = False\n",
    "\n",
    "# Batch sizes\n",
    "batch_size_train = 64\n",
    "batch_size_test = 64\n",
    "batch_size_watermark = 50\n",
    "\n",
    "# MNIST parameters\n",
    "learning_rate = 5e-2\n",
    "momentum = 5e-1\n",
    "log_interval = 20\n",
    "\n",
    "# Watermarking parameters\n",
    "watermark_pretrain_learning_rate = 1e-1\n",
    "watermark_pretrain_momentum = 5e-1\n",
    "watermark_pretrain_weight_decay = 5e-05\n",
    "watermark_retrain_learning_rate = 5e-3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4ac3ad",
   "metadata": {},
   "source": [
    "You'll notice in the `FederatedFlow_MNIST_Watermarking` definition above that there were certain attributes that the flow was not initialized with, namely the `train_loader` and `test_loader` for each of the collaborators. These are **private_attributes** of the particular participant and (as the name suggests) are accessible ONLY to the particular participant's through its task. Additionally these private attributes are always filtered out of the current state when transferring from collaborator to aggregator, and vice versa.\n",
    "\n",
    "Users can directly specify a collaborator's private attributes via `collaborator.private_attributes` which is a dictionary where key is name of the attribute and value is the object that is made accessible to collaborator.\n",
    "\n",
    "For more detailed information on specifying these private attributes, please refer to the first quick start [notebook](https://github.com/securefederatedai/openfl/blob/develop/openfl-tutorials/experimental/Workflow_Interface_101_MNIST.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f10d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "# Setup Aggregator with private attributes\n",
    "aggregator = Aggregator()\n",
    "aggregator.private_attributes = {\n",
    "    \"watermark_data_loader\": torch.utils.data.DataLoader(\n",
    "        watermark_data, batch_size=batch_size_watermark, shuffle=True\n",
    "    ),\n",
    "    \"pretrain_epochs\": 25,\n",
    "    \"retrain_epochs\": 25,\n",
    "    \"watermark_acc_threshold\": 0.98,\n",
    "    \"watermark_pretraining_completed\": False,\n",
    "}\n",
    "\n",
    "# Setup Collaborators with private attributes\n",
    "collaborator_names = ['Portland', 'Seattle', 'Chandler','Bangalore']\n",
    "print(f\"Creating collaborators {collaborator_names}\")\n",
    "collaborators = [Collaborator(name=name) for name in collaborator_names]\n",
    "\n",
    "for idx, collaborator in enumerate(collaborators):\n",
    "    local_train = deepcopy(mnist_train)\n",
    "    local_test = deepcopy(mnist_test)\n",
    "    local_train.data = mnist_train.data[idx :: len(collaborators)]\n",
    "    local_train.targets = mnist_train.targets[idx :: len(collaborators)]\n",
    "    local_test.data = mnist_test.data[idx :: len(collaborators)]\n",
    "    local_test.targets = mnist_test.targets[idx :: len(collaborators)]\n",
    "    collaborator.private_attributes = {\n",
    "        \"train_loader\": torch.utils.data.DataLoader(\n",
    "            local_train, batch_size=batch_size_train, shuffle=True\n",
    "        ),\n",
    "        \"test_loader\": torch.utils.data.DataLoader(\n",
    "            local_test, batch_size=batch_size_train, shuffle=True\n",
    "        ),\n",
    "    }\n",
    "\n",
    "local_runtime = LocalRuntime(aggregator=aggregator, collaborators=collaborators)\n",
    "print(f\"Local runtime collaborators = {local_runtime.collaborators}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5177f137",
   "metadata": {},
   "source": [
    "### Alternate method to specify private attributes\n",
    "\n",
    "There is another way users can initialize private attributes in which private attributes need to be set using a (user defined) callback function while instantiating the participant. The callback function returns the private attributes (`train_loader` & `test_loader`) in form of a dictionary where the key is the attribute name, and the value is the object that will be made accessible to that participant's task.\n",
    "\n",
    "In the following example callback function, `callable_to_initialize_collaborator_private_attributes`, returns the private attributes `train_loader` and `test_loader` of the collaborator.\n",
    "\n",
    "Detailed information on specifying private attributes using callback function is provided in this [documentation](https://github.com/securefederatedai/openfl/blob/develop/docs/about/features_index/workflowinterface.rst). \n",
    "\n",
    ">To use this method, uncomment the following cell and comment out the previous cell which initializes private attributes directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f6e104",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #| export\n",
    "\n",
    "# def callable_to_initialize_aggregator_private_attributes(watermark_data, batch_size):\n",
    "#     return {\n",
    "#         \"watermark_data_loader\": torch.utils.data.DataLoader(\n",
    "#             watermark_data, batch_size=batch_size, shuffle=True\n",
    "#         ),\n",
    "#         \"pretrain_epochs\": 25,\n",
    "#         \"retrain_epochs\": 25,\n",
    "#         \"watermark_acc_threshold\": 0.98,\n",
    "#     }\n",
    "\n",
    "# # Setup Aggregator private attributes via callable function\n",
    "# aggregator = Aggregator(\n",
    "#         name=\"agg\",\n",
    "#         private_attributes_callable=callable_to_initialize_aggregator_private_attributes,\n",
    "#         watermark_data=watermark_data,\n",
    "#         batch_size=batch_size_watermark,\n",
    "#     )\n",
    "\n",
    "# collaborator_names = [\n",
    "#     \"Portland\",\n",
    "#     \"Seattle\",\n",
    "#     \"Chandler\",\n",
    "#     \"Bangalore\",\n",
    "#     \"New Delhi\",\n",
    "# ]\n",
    "# n_collaborators = len(collaborator_names)\n",
    "\n",
    "# def callable_to_initialize_collaborator_private_attributes(index, n_collaborators, batch_size, train_dataset, test_dataset):\n",
    "#     train = deepcopy(train_dataset)\n",
    "#     test = deepcopy(test_dataset)\n",
    "#     train.data = train_dataset.data[index::n_collaborators]\n",
    "#     train.targets = train_dataset.targets[index::n_collaborators]\n",
    "#     test.data = test_dataset.data[index::n_collaborators]\n",
    "#     test.targets = test_dataset.targets[index::n_collaborators]\n",
    "\n",
    "#     return {\n",
    "#         \"train_loader\": torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True),\n",
    "#         \"test_loader\": torch.utils.data.DataLoader(test, batch_size=batch_size, shuffle=True),\n",
    "#     }\n",
    "\n",
    "# # Setup Collaborators private attributes via callable function\n",
    "# collaborators = []\n",
    "# for idx, collaborator_name in enumerate(collaborator_names):\n",
    "#     collaborators.append(\n",
    "#         Collaborator(\n",
    "#             name=collaborator_name, num_cpus=0, num_gpus=0,\n",
    "#             private_attributes_callable=callable_to_initialize_collaborator_private_attributes,\n",
    "#             index=idx, n_collaborators=n_collaborators,\n",
    "#             train_dataset=mnist_train, test_dataset=mnist_test, batch_size=64\n",
    "#         )\n",
    "#     )\n",
    "\n",
    "# local_runtime = LocalRuntime(aggregator=aggregator, collaborators=collaborators, backend=\"ray\")\n",
    "# print(f\"Local runtime collaborators = {local_runtime.collaborators}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4ec6cc",
   "metadata": {},
   "source": [
    ">NOTE: If both methods for specifying private attributes are used, the private attributes will only be set by the latter method. Additionally, the code for both methods  will be included in your generated workspace."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61813ab",
   "metadata": {},
   "source": [
    "Now that we have our flow and runtime defined, let's run the experiment! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d19819",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "model = Net()\n",
    "optimizer = optim.SGD(\n",
    "    model.parameters(), lr=learning_rate, momentum=momentum\n",
    ")\n",
    "watermark_pretrain_optimizer = optim.SGD(\n",
    "    model.parameters(),\n",
    "    lr=watermark_pretrain_learning_rate,\n",
    "    momentum=watermark_pretrain_momentum,\n",
    "    weight_decay=watermark_pretrain_weight_decay,\n",
    ")\n",
    "watermark_retrain_optimizer = optim.SGD(\n",
    "    model.parameters(), lr=watermark_retrain_learning_rate\n",
    ")\n",
    "best_model = None\n",
    "round_number = 0\n",
    "top_model_accuracy = 0\n",
    "\n",
    "flflow = FederatedFlow_MNIST_Watermarking(\n",
    "    model,\n",
    "    optimizer,\n",
    "    watermark_pretrain_optimizer,\n",
    "    watermark_retrain_optimizer,\n",
    "    round_number,\n",
    "    checkpoint=True,\n",
    ")\n",
    "flflow.runtime = local_runtime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5371b6d",
   "metadata": {},
   "source": [
    "## Workspace creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41688326",
   "metadata": {},
   "source": [
    "The following cells convert the Jupyter notebook into a Python script and create a Template Workspace that can be utilized by Aggregator based Workflow\n",
    "> NOTE: Only Notebook cells that were marked with `#| export` directive shall be included in this Python script\n",
    "\n",
    "We first import `WorkspaceExport` module and execute `WorkspaceExport.export()` that converts the notebook and generates the template workspace. User is required to specify: \n",
    "1. `notebook_path`: path of the Jupyter notebook that is required to be converted\n",
    "2. `output_workspace`: path where the converted workspace is stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c98aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openfl.experimental.workspace_export import WorkspaceExport\n",
    "\n",
    "WorkspaceExport.export(\n",
    "    notebook_path='./Workflow_Interface_1001_Workspace_Creation_from_JupyterNotebook.ipynb',\n",
    "    output_workspace=f\"/home/{os.environ['USER']}/generated-workspace\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8639a64",
   "metadata": {},
   "source": [
    "## Workspace Usage\n",
    "\n",
    "The workspace created above can be used by the Aggregator based workflow by using the `fx` commands in the following manner"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ff55808c-c340-476b-a543-58d43451c54e",
   "metadata": {},
   "source": [
    "**Workspace Activation and Creation**\n",
    "1. Activate the experimental aggregator-based workflow:\n",
    "\n",
    "    `fx experimental activate`\n",
    "\n",
    "   This will create an 'experimental' directory under ~/.openfl/\n",
    "3. Create a workspace using the custom template:\n",
    "\n",
    "    `fx workspace create --prefix workspace_path --custom_template /home/$USER/generated-workspace`\n",
    "4. Change to the workspace directory:\n",
    "\n",
    "    `cd workspace_path`\n",
    "\n",
    "**Workspace Initialization and Certification**\n",
    "1. Initialize the FL plan and auto-populate the fully qualified domain name (FQDN) of the aggregator node:\n",
    "\n",
    "    `fx plan initialize`\n",
    "2. Certify the workspace:\n",
    "\n",
    "    `fx workspace certify`\n",
    "    \n",
    "**Aggregator Setup and Workspace Export**\n",
    "1. Run the aggregator certificate creation command:\n",
    "\n",
    "    `fx aggregator generate-cert-request`\n",
    "\n",
    "    `fx aggregator certify`\n",
    "2. Export the workspace for collaboration:\n",
    "\n",
    "    `fx workspace export`\n",
    "    \n",
    "**Collaborator Node Setup**\n",
    "\n",
    "***On the Collaborator Node:***\n",
    "\n",
    "1. Copy the workspace archive from the aggregator node to the collaborator nodes. Import the workspace archive:\n",
    "\n",
    "    `fx workspace import --archive WORKSPACE.zip`\n",
    "   \n",
    "    `cd workspace_path`\n",
    "3. Generate a collaborator certificate request:\n",
    "\n",
    "    `fx collaborator generate-cert-request -n {COL_LABEL}`\n",
    "\n",
    "***On the Aggregator Node (Certificate Authority):***\n",
    "\n",
    "3. Sign the Collaborator Certificate Signing Request (CSR) Package from collaborator nodes:\n",
    "\n",
    "    `fx collaborator certify --request-pkg /PATH/TO/col_{COL_LABEL}_to_agg_cert_request.zip`\n",
    "\n",
    "***On the Collaborator Node:***\n",
    "\n",
    "4. Import the signed certificate and certificate chain into the workspace:\n",
    "\n",
    "    `fx collaborator certify --import /PATH/TO/agg_to_col_{COL_LABEL}_signed_cert.zip`\n",
    "    \n",
    "**Final Workspace Activation**\n",
    "***On the Aggregator Node:***\n",
    "\n",
    "1. Start the Aggregator:\n",
    "\n",
    "    `fx aggregator start`\n",
    "    \n",
    "    The Aggregator is now running and waiting for Collaborators to connect.\n",
    "\n",
    "***On the Collaborator Nodes:***\n",
    "\n",
    "2. Run the Collaborator:\n",
    "\n",
    "    `fx collaborator start -n {COL_LABEL}`\n",
    "\n",
    "**Workspace Deactivation**\n",
    "1. To deactivate the experimental aggregator-based workflow and switch back to original aggregator-based workflow:\n",
    "\n",
    "    `fx experimental deactivate`\n",
    "\n",
    "   This will remove the 'experimental' directory under ~/.openfl/\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openfl-wip",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

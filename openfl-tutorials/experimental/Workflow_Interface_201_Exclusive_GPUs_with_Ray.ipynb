{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "14821d97",
   "metadata": {},
   "source": [
    "# Workflow Interface 201: Using Ray to request exclusive GPUs\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/intel/openfl/blob/develop/openfl-tutorials/experimental/Workflow_Interface_201_Exclusive_GPUs_with_Ray.ipynb)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bd059520",
   "metadata": {},
   "source": [
    "In this OpenFL Workflow Interface tutorial, we will demonstrate how to leverage multiple GPUs concurrent model training using the LocalRuntime's Ray Backend. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fc8e35da",
   "metadata": {},
   "source": [
    "# Getting Started"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4dbb89b6",
   "metadata": {},
   "source": [
    "First we start by installing the necessary dependencies for the workflow interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f98600",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/intel/openfl.git\n",
    "!pip install -r requirements_workflow_interface.txt\n",
    "!pip install torch\n",
    "!pip install torchvision\n",
    "\n",
    "# Uncomment this if running in Google Colab\n",
    "#!pip install -r https://raw.githubusercontent.com/intel/openfl/develop/openfl-tutorials/experimental/requirements_workflow_interface.txt\n",
    "#import os\n",
    "#os.environ[\"USERNAME\"] = \"colab\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7237eac4",
   "metadata": {},
   "source": [
    "We begin with the quintessential example of a small pytorch CNN model trained on the MNIST dataset. Let's start define our dataloaders, model, optimizer, and some helper functions like we would for any other deep learning experiment. Notice the `inference` functions makes consistent references to `cuda:0`. This will become important later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e85e030",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "\n",
    "n_epochs = 3\n",
    "batch_size_train = 64\n",
    "batch_size_test = 1000\n",
    "learning_rate = 0.01\n",
    "momentum = 0.5\n",
    "log_interval = 10\n",
    "\n",
    "random_seed = 1\n",
    "torch.backends.cudnn.enabled = False\n",
    "torch.manual_seed(random_seed)\n",
    "\n",
    "mnist_train = torchvision.datasets.MNIST('files/', train=True, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ]))\n",
    "\n",
    "mnist_test = torchvision.datasets.MNIST('files/', train=False, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ]))\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x)\n",
    "    \n",
    "def inference(network,test_loader):\n",
    "    if torch.cuda.is_available():\n",
    "        network = network.to('cuda:0')\n",
    "    network.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "      for data, target in test_loader:\n",
    "        if torch.cuda.is_available():\n",
    "          data = data.to('cuda:0')\n",
    "          target = target.to('cuda:0')\n",
    "        output = network(data)\n",
    "        test_loss += F.nll_loss(output, target, size_average=False).item()\n",
    "        pred = output.data.max(1, keepdim=True)[1]\n",
    "        correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('\\nTest set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "      test_loss, correct, len(test_loader.dataset),\n",
    "      100. * correct / len(test_loader.dataset)))\n",
    "    accuracy = float(correct / len(test_loader.dataset))\n",
    "    return accuracy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cd268911",
   "metadata": {},
   "source": [
    "Next we import the `FLSpec`, `LocalRuntime`, and placement decorators.\n",
    "\n",
    "- `FLSpec` – Defines the flow specification. User defined flows are subclasses of this.\n",
    "- `Runtime` – Defines where the flow runs, infrastructure for task transitions (how information gets sent). The `LocalRuntime` runs the flow on a single node.\n",
    "- `aggregator/collaborator` - placement decorators that define where the task will be assigned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "precise-studio",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "from openfl.experimental.interface import FLSpec, Aggregator, Collaborator\n",
    "from openfl.experimental.runtime import LocalRuntime\n",
    "from openfl.experimental.placement import aggregator, collaborator\n",
    "\n",
    "\n",
    "def FedAvg(models, weights=None):\n",
    "    models = [model.to('cpu') for model in models]\n",
    "    new_model = models[0]\n",
    "    state_dicts = [model.state_dict() for model in models]\n",
    "    state_dict = new_model.state_dict()\n",
    "    for key in models[1].state_dict():\n",
    "        state_dict[key] = torch.from_numpy(np.average([state[key].numpy() for state in state_dicts],\n",
    "                                                      axis=0, \n",
    "                                                      weights=weights))\n",
    "    new_model.load_state_dict(state_dict)\n",
    "    return new_model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b2e45614",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "Now we come to the updated flow definition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "difficult-madrid",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CollaboratorGPUFlow(FLSpec):\n",
    "\n",
    "    def __init__(self, model = None, optimizer = None, rounds=3, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        if model is not None:\n",
    "            self.model = model\n",
    "            self.optimizer = optimizer\n",
    "        else:\n",
    "            self.model = Net()\n",
    "            self.optimizer = optim.SGD(self.model.parameters(), lr=learning_rate,\n",
    "                                   momentum=momentum)\n",
    "        self.rounds = rounds\n",
    "\n",
    "    @aggregator\n",
    "    def start(self):\n",
    "        print(f'Performing initialization for model')\n",
    "        self.collaborators = self.runtime.collaborators\n",
    "        self.private = 10\n",
    "        self.current_round = 0\n",
    "        self.next(self.aggregated_model_validation,foreach='collaborators',exclude=['private'])\n",
    "\n",
    "    @collaborator\n",
    "    def aggregated_model_validation(self):\n",
    "        print(f'Performing aggregated model validation for collaborator {self.input}')\n",
    "        self.agg_validation_score = inference(self.model,self.test_loader)\n",
    "        print(f'{self.input} value of {self.agg_validation_score}')\n",
    "        self.next(self.train)\n",
    "\n",
    "    @collaborator\n",
    "    def train(self):\n",
    "        \"\"\"\n",
    "        Train the model.\n",
    "        \"\"\"\n",
    "        self.model.train()\n",
    "        self.optimizer = optim.SGD(self.model.parameters(), lr=learning_rate,\n",
    "                              momentum=momentum)\n",
    "        train_losses = []\n",
    "        for batch_idx, (data, target) in enumerate(self.train_loader):\n",
    "            if torch.cuda.is_available():\n",
    "                data = data.to(\"cuda:0\")\n",
    "                target = target.to(\"cuda:0\")\n",
    "            self.optimizer.zero_grad()\n",
    "            output = self.model(data)\n",
    "            loss = F.nll_loss(output, target)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            if batch_idx % log_interval == 0:\n",
    "                print('Train Epoch: 1 [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                    batch_idx * len(data), len(self.train_loader.dataset),\n",
    "                    100. * batch_idx / len(self.train_loader), loss.item()))\n",
    "                self.loss = loss.item()\n",
    "        self.next(self.local_model_validation)\n",
    "\n",
    "    @collaborator\n",
    "    def local_model_validation(self):\n",
    "        self.local_validation_score = inference(self.model,self.test_loader)\n",
    "        print(f'Doing local model validation for collaborator {self.input}: {self.local_validation_score}')\n",
    "        self.next(self.join)\n",
    "\n",
    "    @aggregator\n",
    "    def join(self,inputs):\n",
    "        self.average_loss = sum(input.loss for input in inputs)/len(inputs)\n",
    "        self.aggregated_model_accuracy = sum(input.agg_validation_score for input in inputs)/len(inputs)\n",
    "        self.local_model_accuracy = sum(input.local_validation_score for input in inputs)/len(inputs)\n",
    "        print(f'Average aggregated model validation values = {self.aggregated_model_accuracy}')\n",
    "        print(f'Average training loss = {self.average_loss}')\n",
    "        print(f'Average local model validation values = {self.local_model_accuracy}')\n",
    "        self.model = FedAvg([input.model for input in inputs])\n",
    "        self.optimizer = [input.optimizer for input in inputs][0]\n",
    "        self.current_round += 1\n",
    "        if self.current_round < self.rounds:\n",
    "            self.next(self.aggregated_model_validation, foreach='collaborators', exclude=['private'])\n",
    "        else:\n",
    "            self.next(self.end)\n",
    "        \n",
    "    @aggregator\n",
    "    def end(self):\n",
    "        print(f'This is the end of the flow')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "49c4afa8",
   "metadata": {},
   "source": [
    "In this step we define entities necessary to run the flow and create a function which returns dataset as private attributes of collaborator. As described in [quickstart](https://github.com/securefederatedai/openfl/blob/develop/openfl-tutorials/experimental/Workflow_Interface_101_MNIST.ipynb) we define entities necessary for the flow.\n",
    "\n",
    "To request GPU(s) with ray-backend, we specify `num_gpus=0.5` as the argument while instantiating Collaborator, this will reserve 0.5 GPU for each of the 2 collaborators and therefore require a dedicated GPU for the experiment. Tune this based on your use case, for example `num_gpus=0.5` for an experiment with 4 collaborators will require 2 dedicated GPUs. **NOTE:** Collaborator cannot span over multiple GPUs, for example `num_gpus=0.4` with 5 collaborators will require 3 dedicated GPUs. In this case collaborator 1 and 2 use GPU#1, collaborator 3 and 4 use GPU#2, and collaborator 5 uses GPU#3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forward-world",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Aggregator private attributes via callable function\n",
    "aggregator = Aggregator(num_gpus=0.3)\n",
    "\n",
    "collaborator_names = ['Portland', 'Seattle']\n",
    "\n",
    "def callable_to_initialize_collaborator_private_attributes(index, n_collaborators,\n",
    "        train_dataset, test_dataset, batch_size_train):\n",
    "    local_train = deepcopy(train_dataset)\n",
    "    local_test = deepcopy(test_dataset)\n",
    "    local_train.data = train_dataset.data[index::n_collaborators]\n",
    "    local_train.targets = train_dataset.targets[index::n_collaborators]\n",
    "    local_test.data = test_dataset.data[index::n_collaborators]\n",
    "    local_test.targets = test_dataset.targets[index::n_collaborators]\n",
    "\n",
    "    return {\n",
    "        'train_loader': torch.utils.data.DataLoader(local_train,batch_size=batch_size_train, shuffle=True),\n",
    "        'test_loader': torch.utils.data.DataLoader(local_test, batch_size=batch_size_train, shuffle=True)\n",
    "    }\n",
    "\n",
    "# Setup collaborators private attributes via callable function\n",
    "collaborators = []\n",
    "for idx, collaborator_name in enumerate(collaborator_names):\n",
    "    collaborators.append(\n",
    "        Collaborator(\n",
    "            name=collaborator_name, num_cpus=0, num_gpus=0.3,\n",
    "            private_attributes_callable=callable_to_initialize_collaborator_private_attributes,\n",
    "            index=idx, n_collaborators=len(collaborator_names),\n",
    "            train_dataset=mnist_train, test_dataset=mnist_test, batch_size_train=batch_size_train\n",
    "        )\n",
    "    )\n",
    "    \n",
    "# The following is equivalent to\n",
    "# local_runtime = LocalRuntime(aggregator=aggregator, collaborators=collaborators, **backend='ray'**)\n",
    "local_runtime = LocalRuntime(aggregator=aggregator, collaborators=collaborators, backend='ray')\n",
    "print(f'Local runtime collaborators = {local_runtime.collaborators}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0525eaa9",
   "metadata": {},
   "source": [
    "Now that we have our flow and runtime defined, let's run the experiment! \n",
    "\n",
    "(If you run this example on Google Colab with the GPU Runtime, you should see two tasks executing at a time.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d581d96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = None\n",
    "best_model = None\n",
    "optimizer = None\n",
    "flflow = CollaboratorGPUFlow(model, optimizer, checkpoint=True)\n",
    "flflow.runtime = local_runtime\n",
    "flflow.run()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "10616d60",
   "metadata": {},
   "source": [
    "Now that the flow has completed, let's get the final model and accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ae3cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Sample of the final model weights: {flflow.model.state_dict()[\"conv1.weight\"][0]}')\n",
    "\n",
    "print(f'\\nFinal aggregated model accuracy for {flflow.rounds} rounds of training: {flflow.aggregated_model_accuracy}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8e084b41",
   "metadata": {},
   "source": [
    "Now that the flow is complete, let's dig into some of the information captured along the way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "verified-favor",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_id = flflow._run_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statutory-prime",
   "metadata": {},
   "outputs": [],
   "source": [
    "from metaflow import Metaflow, Flow, Task, Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fifty-tamil",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Metaflow()\n",
    "list(m)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f8f7d05f",
   "metadata": {},
   "source": [
    "For existing users of Metaflow, you'll notice this is the same way you would examine a flow after completion. Let's look at the latest run that generated some results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grand-defendant",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = Flow('CollaboratorGPUFlow').latest_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incident-novelty",
   "metadata": {},
   "outputs": [],
   "source": [
    "f"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a206b36c",
   "metadata": {},
   "source": [
    "And its list of steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "increasing-dressing",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bf4ec317",
   "metadata": {},
   "source": [
    "This matches the list of steps executed in the flow, so far so good..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "olympic-latter",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = Step(f'CollaboratorGPUFlow/{run_id}/train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "awful-posting",
   "metadata": {},
   "outputs": [],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "median-double",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(s)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0c5522b7",
   "metadata": {},
   "source": [
    "Now we see **6** steps: **2** collaborators each performed **3** rounds of model training  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adult-maldives",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = Task(f'CollaboratorGPUFlow/{run_id}/train/11')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "changed-hungarian",
   "metadata": {},
   "outputs": [],
   "source": [
    "t"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "efd5da76",
   "metadata": {},
   "source": [
    "Now let's look at the data artifacts this task generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "academic-hierarchy",
   "metadata": {},
   "outputs": [],
   "source": [
    "t.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thermal-torture",
   "metadata": {},
   "outputs": [],
   "source": [
    "t.data.input"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3e92fab0",
   "metadata": {},
   "source": [
    "Now let's look at its log output (stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "auburn-working",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(t.stdout)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ced6e90e",
   "metadata": {},
   "source": [
    "And any error logs? (stderr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8a9ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(t.stderr)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8b9f8d25",
   "metadata": {},
   "source": [
    "# Congratulations!\n",
    "Now that you've completed your **workflow interface 201 tutorial**, see some of the more advanced things you can do in our [other tutorials](broken_link), including:\n",
    "\n",
    "- Vertical Federated Learning\n",
    "- Model Watermarking\n",
    "- Differential Privacy\n",
    "- And More!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "runtime-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

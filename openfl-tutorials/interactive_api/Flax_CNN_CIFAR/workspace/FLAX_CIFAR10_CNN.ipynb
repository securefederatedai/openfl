{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26fdd9ed",
   "metadata": {},
   "source": [
    "# Federated FLAX/JAX CIFAR10 Tutorial\n",
    "Using `TFDS` API as a data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1329f2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ml_collections flax -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d30942",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba06315-142b-4339-92a7-f2fa38fb79f1",
   "metadata": {},
   "source": [
    "`TF_FORCE_GPU_ALLOW_GROWTH=true` - Starts out allocating very little memory, and as the program gets run and more GPU memory is needed, the GPU memory region is extended for the TensorFlow process.\n",
    "\n",
    "`XLA_PYTHON_CLIENT_PREALLOCATE=false` - This disables the preallocation behavior. JAX will instead allocate GPU memory as needed, potentially decreasing the overall memory usage. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ce140e",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_DEVICE='cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56eae004-fce0-442e-8c0d-659c7db77f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if DEFAULT_DEVICE == 'cpu':\n",
    "    os.environ['JAX_PLATFORMS']='cpu' # Force XLA to use CPU\n",
    "    os.environ['CUDA_VISIBLE_DEVICES']='-1' # Force TF to use CPU\n",
    "elif DEFAULT_DEVICE == 'GPU':\n",
    "    os.environ['XLA_PYTHON_CLIENT_PREALLOCATE']='false'\n",
    "    os.environ['TF_FORCE_GPU_ALLOW_GROWTH']='true'\n",
    "    os.environ['TF_ENABLE_ONEDNN_OPTS']='0' # Disable oneDNN custom operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0833dfc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print('TensorFlow', tf.__version__)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60763633-919a-41c1-b755-50f3bb3baf3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flax import linen as nn\n",
    "from flax.metrics import tensorboard\n",
    "from flax.training import train_state\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import logging\n",
    "import ml_collections\n",
    "import optax\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.keras.utils import Progbar\n",
    "from dataclasses import field\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246f9c98",
   "metadata": {},
   "source": [
    "## Connect to the Federation\n",
    "\n",
    "Start `Director` and `Envoy` before proceeding with this cell. \n",
    "\n",
    "This cell connects this notebook to the Federation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d657e463",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openfl.interface.interactive_api.federation import Federation\n",
    "\n",
    "# please use the same identificator that was used in signed certificate\n",
    "client_id = 'api'\n",
    "cert_dir = 'cert'\n",
    "director_node_fqdn = 'localhost'\n",
    "director_port = 50055\n",
    "\n",
    "# Create a Federation\n",
    "federation = Federation(\n",
    "    client_id=client_id,\n",
    "    director_node_fqdn=director_node_fqdn,\n",
    "    director_port=director_port, \n",
    "    tls=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6efe22a8",
   "metadata": {},
   "source": [
    "## Query Datasets from Shard Registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47dcfab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "shard_registry = federation.get_shard_registry()\n",
    "shard_registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a6c237",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, request a dummy_shard_desc that holds information about the federated dataset \n",
    "dummy_shard_desc = federation.get_dummy_shard_descriptor(size=10)\n",
    "dummy_shard_dataset = dummy_shard_desc.get_dataset('train')\n",
    "sample, target = dummy_shard_dataset[0]\n",
    "f\"Sample shape: {sample.shape}, target shape: {target.shape}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4670d19e-b0f5-472d-9794-ddb3cefbb3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_config():\n",
    "  \"\"\"Get the default hyperparameter configuration.\"\"\"\n",
    "  config = ml_collections.ConfigDict()\n",
    "  config.learning_rate = 0.01\n",
    "  config.momentum = 0.9\n",
    "  config.batch_size = 128\n",
    "  config.num_epochs = 10\n",
    "  config.rounds_to_train = 3\n",
    "  return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3faf78-2f8a-4fc9-aca0-450d700e625c",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = get_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0dbdbd",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Describing FL experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc88700a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openfl.interface.interactive_api.experiment import TaskInterface\n",
    "from openfl.interface.interactive_api.experiment import ModelInterface\n",
    "from openfl.interface.interactive_api.experiment import FLExperiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b468ae1",
   "metadata": {},
   "source": [
    "### Register model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06545bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model\n",
    "class CNN(nn.Module):\n",
    "    \"\"\"A simple CNN model.\"\"\"\n",
    "    \n",
    "    @nn.compact\n",
    "    def __call__(self, x):\n",
    "        x = nn.Conv(features=32, kernel_size=(3, 3))(x)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.avg_pool(x, window_shape=(2, 2), strides=(2, 2))\n",
    "        x = nn.Conv(features=64, kernel_size=(3, 3))(x)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.avg_pool(x, window_shape=(2, 2), strides=(2, 2))\n",
    "        x = nn.Conv(features=128, kernel_size=(3, 3))(x)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.avg_pool(x, window_shape=(2, 2), strides=(2, 2))\n",
    "        x = x.reshape((x.shape[0], -1))  # flatten\n",
    "        x = nn.Dense(features=256)(x)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.Dense(features=10)(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3aef5d-2828-489c-b645-dacf8e1ee440",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTrainState(train_state.TrainState):\n",
    "    \"\"\" Subclass `train_state.Trainstate` and `update_state` method\n",
    "        to allow update of `model parameters` and `optimizer state` \n",
    "        during `training` loop execution\n",
    "    \"\"\"\n",
    "    opt_vars : list = field(default_factory=list)\n",
    "    \n",
    "    def update_state(self, new_state: train_state.TrainState) -> None:\n",
    "        ''' \n",
    "        Update the model states, used during evaluation/inference.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        new_state : train_state.TrainState\n",
    "            Updated state with applied gradients.\n",
    "            update the `state` variable used to initialize ModelInterface\n",
    "            with the `new_state` parameters\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        None\n",
    "        '''\n",
    "        # Update Params\n",
    "        self.params.update(new_state.params)\n",
    "        \n",
    "        # Update Optimizer States\n",
    "        for var in self.opt_vars:\n",
    "            opt_var_dict = getattr(self.opt_state[0], var)\n",
    "            new_opt_var_dict = getattr(new_state.opt_state[0], var)\n",
    "            opt_var_dict.update(new_opt_var_dict)\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2786ae49-6293-4596-bbc2-0b791905d900",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_opt_vars(x):\n",
    "    return False if x.startswith('_') or x in ['index', 'count'] else True\n",
    "\n",
    "def create_train_state(rng, config):\n",
    "    \"\"\"Creates initial `TrainState`.\"\"\"\n",
    "    cnn = CNN()\n",
    "    params = cnn.init(rng, jnp.ones([1, 32, 32, 3]))['params'].unfreeze() # Random Parameters\n",
    "    tx = optax.sgd(config.learning_rate, config.momentum) # Optimizer\n",
    "    optvars = list(filter(_get_opt_vars, dir(tx.init(params)[0])))\n",
    "    initial_model_state = CustomTrainState.create(apply_fn=cnn.apply, params=params, tx=tx, opt_vars=optvars)\n",
    "    return initial_model_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0abc9a1a-a606-4cef-ba51-c4618f924bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRNG - Pseudo Random Number Generator  Seed\n",
    "rng = jax.random.PRNGKey(0)\n",
    "rng, init_rng = jax.random.split(rng)\n",
    "\n",
    "# Initialize parameters and optimizers \n",
    "# Encapsulate within TrainState class and apply gradients in an easy way\n",
    "state = create_train_state(init_rng, config)\n",
    "\n",
    "# Create ModelInterface - Register the state\n",
    "framework_adapter = 'openfl.plugins.frameworks_adapters.flax_adapter.FrameworkAdapterPlugin'\n",
    "MI = ModelInterface(model=state, optimizer=None, framework_plugin=framework_adapter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0979470",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Register dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c9eb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openfl.interface.interactive_api.experiment import DataInterface\n",
    "\n",
    "class CIFAR10FedDataset(DataInterface):\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    @property\n",
    "    def shard_descriptor(self):\n",
    "        return self._shard_descriptor\n",
    "\n",
    "    @shard_descriptor.setter\n",
    "    def shard_descriptor(self, shard_descriptor):\n",
    "        \"\"\"\n",
    "        Describe per-collaborator procedures or sharding.\n",
    "\n",
    "        This method will be called during a collaborator initialization.\n",
    "        Local shard_descriptor will be set by Envoy.\n",
    "        \"\"\"\n",
    "        self._shard_descriptor = shard_descriptor\n",
    "        \n",
    "        # shard_descriptor.get_split(...) returns a tf.data.Dataset\n",
    "        # Check cifar10_shard_descriptor.py for details\n",
    "        self.train_set = shard_descriptor.get_split('train')\n",
    "        self.valid_set = shard_descriptor.get_split('valid')\n",
    "\n",
    "    def get_train_loader(self):\n",
    "        \"\"\"Output of this method will be provided to tasks with optimizer in contract\"\"\"\n",
    "        return self.train_set\n",
    "        # bs = self.kwargs.get('train_bs', 32)\n",
    "        # return self.train_set.batch(bs)\n",
    "\n",
    "    def get_valid_loader(self):\n",
    "        \"\"\"Output of this method will be provided to tasks without optimizer in contract\"\"\"\n",
    "        return self.valid_set\n",
    "        # bs = self.kwargs.get('valid_bs', 32)\n",
    "        # return self.valid_set.batch(bs)\n",
    "    \n",
    "    def get_train_data_size(self) -> int:\n",
    "        \"\"\"Information for aggregation\"\"\"\n",
    "        return len(self.train_set)\n",
    "\n",
    "    def get_valid_data_size(self) -> int:\n",
    "        \"\"\"Information for aggregation\"\"\"\n",
    "        return len(self.valid_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0dfb459",
   "metadata": {},
   "source": [
    "### Create CIFAR10 federated dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af5c4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fed_dataset = CIFAR10FedDataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849c165b",
   "metadata": {},
   "source": [
    "## Define and register FL tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e62caa-187e-4525-a167-a1b9d7f1435e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def apply_model(state, images, labels):\n",
    "    \"\"\"Computes gradients, loss and accuracy for a single batch.\"\"\"\n",
    "\n",
    "    def loss_fn(params):\n",
    "        logits = state.apply_fn({'params': params}, images)\n",
    "        one_hot = jax.nn.one_hot(labels, 10) # 10 - Total number of classes for a given dataset\n",
    "        loss = jnp.mean(optax.softmax_cross_entropy(logits=logits, labels=one_hot))\n",
    "        return loss, logits\n",
    "\n",
    "    grad_fn = jax.value_and_grad(loss_fn, has_aux=True)\n",
    "    (loss, logits), grads = grad_fn(state.params)\n",
    "    accuracy = jnp.mean(jnp.argmax(logits, -1) == labels)\n",
    "    return grads, loss, accuracy\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def update_model(state, grads):\n",
    "    \"\"\"Return an immutable and updated state with applied gradients\"\"\"\n",
    "    return state.apply_gradients(grads=grads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a2dac6-53d7-4711-9368-e4310e9c1f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(state, train_ds, batch_size, rng):\n",
    "    \"\"\"Train for a single epoch.\"\"\"\n",
    "    train_ds_size = len(train_ds['image'])\n",
    "    steps_per_epoch = train_ds_size // batch_size\n",
    "    pbar = Progbar(steps_per_epoch)\n",
    "    \n",
    "    # Randomize the batch selection.\n",
    "    # Permute the dataset index selection\n",
    "    perms = jax.random.permutation(rng, train_ds_size)\n",
    "    perms = perms[:steps_per_epoch * batch_size]  # skip incomplete batch\n",
    "    perms = perms.reshape((steps_per_epoch, batch_size))\n",
    "\n",
    "    epoch_loss = []\n",
    "    epoch_accuracy = []\n",
    "    step = 1\n",
    "    for perm in perms:\n",
    "        batch_images = train_ds['image'][perm, ...] # Same as [perm, :, :, :]\n",
    "        batch_labels = train_ds['label'][perm, ...]\n",
    "        # apply_model -> Forward pass through the layers with the given model `state` as a parameter\n",
    "        grads, loss, accuracy = apply_model(state, batch_images, batch_labels)\n",
    "        # Apply gradients and get the updated `state`\n",
    "        # jitted methods are statelessssssss!\n",
    "        state = update_model(state, grads)\n",
    "        epoch_loss.append(loss)\n",
    "        epoch_accuracy.append(accuracy)\n",
    "        pbar.update(step, values={'epoch loss': loss, 'epoch accuracy': accuracy}.items())\n",
    "        step = step + 1\n",
    "        \n",
    "    train_loss = jnp.array(epoch_loss).mean().item()\n",
    "    train_accuracy = jnp.array(epoch_accuracy).mean().item()\n",
    "    return state, train_loss, train_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9649385",
   "metadata": {},
   "outputs": [],
   "source": [
    "TI = TaskInterface()\n",
    "@TI.register_fl_task(model='state', data_loader='dataset', optimizer='optimizer', device='device')  \n",
    "def train(state, dataset, optimizer, device, loss_fn=None, warmup=False):\n",
    "    new_state, train_loss, train_accuracy = train_epoch(state, dataset, config.batch_size, init_rng)\n",
    "    state.update_state(new_state) # Update `model` parameters registered in ModelInterface with the `new_state` parameters.\n",
    "    return {'train_acc': train_accuracy,}\n",
    "\n",
    "@TI.register_fl_task(model='state', data_loader='dataset', device='device')\n",
    "def validate(state, dataset, device):\n",
    "    _, val_loss, val_accuracy = apply_model(state, dataset['image'], dataset['label'])\n",
    "    # print(\"Validation accuracy: %.4f\" % (float(val_accuracy),))\n",
    "    return {'validation_accuracy': val_accuracy,}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0ebf2d",
   "metadata": {},
   "source": [
    "## Start federated learning experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41b7896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an experimnet in federation\n",
    "experiment_name = 'cifar10_experiment'\n",
    "fl_experiment = FLExperiment(federation=federation, experiment_name=experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b44de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following command zips the workspace and python requirements to be transfered to collaborator nodes\n",
    "\n",
    "fl_experiment.start(model_provider=MI,\n",
    "                   task_keeper=TI,\n",
    "                   data_loader=fed_dataset,\n",
    "                   rounds_to_train=config.rounds_to_train,\n",
    "                   opt_treatment='CONTINUE_GLOBAL',\n",
    "                   device_assignment_policy='CUDA_PREFERRED')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74eeb27d-d637-4041-8281-b82ed6bb22f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fl_experiment.stream_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8573e808-13cb-4da9-bed0-f36ed7724378",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "b06d1b655d4d5fbe90b113436047673f65880809b3fc5b52db1ddd0c49488bf8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

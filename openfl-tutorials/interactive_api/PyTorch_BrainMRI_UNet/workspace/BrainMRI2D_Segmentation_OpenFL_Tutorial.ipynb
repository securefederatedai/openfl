{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "893aa064",
   "metadata": {},
   "source": [
    "## Medical Decathlon BrainMRI Segmentation OpenFL tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120c95ec",
   "metadata": {},
   "source": [
    "### Download the dataset : Medicat Decathlon BrainMRI Segmentation Dataset\n",
    "\n",
    "Download the data from : https://goo.gl/QzVZcm download the file Task01_BrainTumour.tar (into the base repository) <p>\n",
    "Then run the prepare_dataset.py file to process and create the dataset so that it is ready to use. <p>\n",
    "Usage : python prepare_dataset.py tar_file_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb3df7b",
   "metadata": {},
   "source": [
    "Directory structure of the base folder would be something like this <br>\n",
    "![Directory Structure](demo_images/directory_structure.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d4f52d",
   "metadata": {},
   "source": [
    "### Experimental Setup\n",
    "Using the latest OpenFL 1.2.1 version, the experiment will have **a director** and **two envoys** <p>\n",
    "The prepare_dataset.py script will add the dataset to the two envoy folders and also the csv files that will be used"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65b49c5",
   "metadata": {},
   "source": [
    "### Director\n",
    "\n",
    "The director has two files director.yaml and start_director.sh\n",
    "\n",
    "The director_config.yaml file looks like : \n",
    "![Director YAML](demo_images/director.yaml.PNG) <p>\n",
    "Specify the **listening host**, **listening port**, **sample_shape** of the image, and the **target_shape** in this file <p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa5e16d3",
   "metadata": {},
   "source": [
    "### Envoy\n",
    "\n",
    "The envoy_config.yaml file looks like : \n",
    "![Director YAML](demo_images/envoy_config.PNG) <p>\n",
    "\n",
    "Specify the **shard_descriptor template**, the params take in the train_data.csv and valid_data.csv <p>\n",
    "rank_worldsize --> is used to shard the dataset between the different envoys, here 1,2 means the first envoy out of 2 <p>\n",
    "crop_size --> denotes the size to which the images are cropped"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57cabd27",
   "metadata": {},
   "source": [
    "### Important Note\n",
    "\n",
    "Before moving ahead to the further steps, ensure that you have downloaded the dataset and processing is complete <p>\n",
    "Furthermore, ensure that you have started the director and both the envoys (Run the shell scripts to start the directors and the envoys) <p>\n",
    "**NOTE : Please have a look at the shell scripts, if you are using a non standard setup then change the parameters like the FQDN of director and ports accordingly**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e383696",
   "metadata": {},
   "source": [
    "#### Import statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3dece093",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openfl.interface.interactive_api.federation import Federation\n",
    "from openfl.interface.interactive_api.experiment import TaskInterface, DataInterface, ModelInterface, FLExperiment\n",
    "import os\n",
    "import PIL\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler\n",
    "from torchvision import transforms as tsf\n",
    "from copy import deepcopy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F \n",
    "import tqdm\n",
    "from openfl.component.aggregation_functions import Median\n",
    "from layers import soft_dice_coef, soft_dice_loss, DoubleConv, Down, Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2feb9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the federation\n",
    "\n",
    "client_id = 'frontend' # can the client anything you want --> going for 'frontend' right now\n",
    "director_node_fqdn = 'localhost' # Only the FQDN of director is required (change it according to your setup)\n",
    "director_port = 50050 # Again the port of the director (change it according to your setup)\n",
    "\n",
    "# Define the federation using the clien_id, director_node_fqdn / port\n",
    "federation = Federation(\n",
    "    client_id=client_id,\n",
    "    director_node_fqdn=director_node_fqdn,\n",
    "    director_port=director_port,\n",
    "    tls=False\n",
    ")\n",
    "\n",
    "# Check for the shard registry --> Ensure that the envoys are communicating with the director\n",
    "shard_registry = federation.get_shard_registry()\n",
    "print(f'shard_registry : \\n{shard_registry}')\n",
    "\n",
    "# A shard descriptor to ensure that the images are being read from the envoy's side\n",
    "dummy_shard_desc = federation.get_dummy_shard_descriptor(size=10)\n",
    "dummy_shard_dataset = dummy_shard_desc.get_dataset('train')\n",
    "sample,target = dummy_shard_dataset[0]\n",
    "print(f'Sample shape : {sample.shape}, target.shape = {target.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f81c59b4",
   "metadata": {},
   "source": [
    "### Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70fdf17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The brainMRIDataset that will be used, this is basically a wrapper on top of the shard_descriptor that are present at the\n",
    "# envoy's side\n",
    "class brainMriDataset(Dataset):\n",
    "\n",
    "    def __init__(self, dataset) -> None:\n",
    "        super().__init__()\n",
    "        self._dataset = dataset\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img, msk = self._dataset[idx]\n",
    "        img = img\n",
    "        msk = msk\n",
    "        return img, msk\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._dataset)\n",
    "\n",
    "# The wrapper over brainMriDataset, will be used to actually call and send train_loader and valid_loader for the \n",
    "class brainMRISD(DataInterface):\n",
    "\n",
    "    def __init__(self, **kwargs) -> None:\n",
    "        super().__init__(**kwargs)\n",
    "    \n",
    "    @property\n",
    "    def shard_descriptor(self):\n",
    "        return self._shard_descriptor\n",
    "    \n",
    "    @shard_descriptor.setter\n",
    "    def shard_descriptor(self, shard_descriptor):\n",
    "        self._shard_descriptor = shard_descriptor\n",
    "        self._shard_dataset_train = brainMriDataset(shard_descriptor.get_dataset('train'))\n",
    "        self._shard_dataset_valid = brainMriDataset(shard_descriptor.get_dataset('valid'))\n",
    "        self.train_indices = np.arange(len(self._shard_dataset_train))\n",
    "        self.valid_indices = np.arange(len(self._shard_dataset_valid))\n",
    "    \n",
    "    def get_train_loader(self,**kwargs):\n",
    "        return DataLoader(\n",
    "            self._shard_dataset_train,\n",
    "            num_workers=8,\n",
    "            batch_size=self.kwargs['train_bs'],\n",
    "        )\n",
    "    \n",
    "    def get_valid_loader(self,**kwargs):\n",
    "        return DataLoader(\n",
    "            self._shard_dataset_valid,\n",
    "            num_workers=8,\n",
    "            batch_size=self.kwargs['valid_bs']\n",
    "        )\n",
    "    \n",
    "    def get_train_data_size(self):\n",
    "        return len(self.train_indices)\n",
    "    \n",
    "    def get_valid_data_size(self):\n",
    "        return len(self.valid_indices)\n",
    "    \n",
    "\n",
    "# Test the dataset\n",
    "brain_dataset = brainMRISD(train_bs=4,valid_bs=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995c8eb9",
   "metadata": {},
   "source": [
    "### Describe the model and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a79680",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "UNet model definition\n",
    "\"\"\"\n",
    "# Define the model that will be used in training\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, n_channels=1, n_classes=1):\n",
    "        super().__init__()\n",
    "        self.inc = DoubleConv(n_channels, 16)\n",
    "        self.down0 = Down(16,32)\n",
    "        self.down1 = Down(32, 64)\n",
    "        self.down2 = Down(64,128)\n",
    "        self.down3 = Down(128,256)\n",
    "        self.up0 = Up(256,128)\n",
    "        self.up1 = Up(128,64)\n",
    "        self.up2 = Up(64, 32)\n",
    "        self.up3 = Up(32,16)\n",
    "        self.outc = nn.Conv2d(16, n_classes, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down0(x1)\n",
    "        x3 = self.down1(x2)\n",
    "        x4 = self.down2(x3)\n",
    "        x5 = self.down3(x4)\n",
    "        x = self.up0(x5,x4)\n",
    "        x = self.up1(x, x3)\n",
    "        x = self.up2(x, x2)\n",
    "        x = self.up3(x, x1)\n",
    "        x = self.outc(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Define the model class\n",
    "model_unet = UNet()\n",
    "\n",
    "# Define the optimizer to use\n",
    "optimizer_adam = optim.Adam(model_unet.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ea57d0",
   "metadata": {},
   "source": [
    "### Register the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541fdefa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Framework_adapter that will convert the regular PyTorch code \n",
    "framework_adapter = 'openfl.plugins.frameworks_adapters.pytorch_adapter.FrameworkAdapterPlugin'\n",
    "MI = ModelInterface(model=model_unet, optimizer=optimizer_adam, framework_plugin=framework_adapter)\n",
    "\n",
    "# Save the initial model state\n",
    "initial_model = deepcopy(model_unet)\n",
    "\n",
    "TI = TaskInterface()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ec92dc",
   "metadata": {},
   "source": [
    "### Define and register FL tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f824de35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Soft dice coefficient calculation function\n",
    "def soft_dice_coef(output, target, epsilon=1):\n",
    "    \"\"\"Calculate loss.\"\"\"\n",
    "    num = target.size(0)\n",
    "    inter = torch.dot(output.reshape(-1), target.reshape(-1))\n",
    "    sets_sum = torch.sum(output) + torch.sum(target)\n",
    "    if sets_sum.item() == 0:\n",
    "        sets_sum = 2 * inter\n",
    "    return (2 * inter + epsilon) / (sets_sum + epsilon)\n",
    "\n",
    "\n",
    "# Soft Dice Loss based on the Soft dice coefficient\n",
    "def soft_dice_loss(output, target, epsilon=1):\n",
    "    return 1 - soft_dice_coef(output, target, epsilon=epsilon)\n",
    "\n",
    "\n",
    "class Config:\n",
    "    num_workers=2\n",
    "    batch_size=8\n",
    "    n_epoches=20\n",
    "    lr = 1e-4\n",
    "\n",
    "\n",
    "#The Interactive API supports overriding of the aggregation function\n",
    "aggregation_function = Median()\n",
    "\n",
    "\n",
    "#### This is the main training engine that the envoys will use to train the model ####\n",
    "\n",
    "# Task interface currently supports only standalone functions.\n",
    "@TI.add_kwargs(**{'some_parameter': 0}) # Just to showcase how we can send additional paramters\n",
    "@TI.register_fl_task(model='unet_model', data_loader='train_loader', \\\n",
    "                     device='device', optimizer='optimizer')     \n",
    "@TI.set_aggregation_function(aggregation_function)\n",
    "def train(unet_model, train_loader, optimizer, device, loss_fn=soft_dice_loss, some_parameter=None):\n",
    "    \n",
    "    \"\"\"    \n",
    "    The following constructions, that may lead to resource race\n",
    "    is no longer needed:\n",
    "    \n",
    "    if not torch.cuda.is_available():\n",
    "        device = 'cpu'\n",
    "    else:\n",
    "        device = 'cuda'\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    print(f'\\n\\n TASK TRAIN GOT DEVICE {device}\\n\\n')\n",
    "    \n",
    "    function_defined_in_notebook(some_parameter)\n",
    "\n",
    "    train_loader = tqdm.tqdm(train_loader, desc=\"train\")\n",
    "    \n",
    "    unet_model.train()\n",
    "    unet_model.to(device)\n",
    "\n",
    "    losses = []\n",
    "\n",
    "    for data, target in train_loader:\n",
    "        data, target = torch.tensor(data).to(device, dtype=torch.float32).requires_grad_(True), torch.tensor(\n",
    "            target).to(device, dtype=torch.float32).requires_grad_(True)\n",
    "        optimizer.zero_grad()\n",
    "        output = unet_model(data)\n",
    "        loss = loss_fn(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.detach().cpu().numpy())\n",
    "        \n",
    "    return {'train_loss': np.mean(losses),}\n",
    "\n",
    "\n",
    "@TI.register_fl_task(model='unet_model', data_loader='val_loader', device='device')\n",
    "def validate(unet_model, val_loader, device, loss_fn=soft_dice_coef):\n",
    "    print(f'\\n\\n TASK VALIDATE GOT DEVICE {device}\\n\\n')\n",
    "    \n",
    "    unet_model.eval()\n",
    "    unet_model.to(device)\n",
    "    \n",
    "    val_loader = tqdm.tqdm(val_loader, desc=\"validate\")\n",
    "\n",
    "    val_losses = []\n",
    "    total_samples = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in val_loader:\n",
    "            samples = target.shape[0]\n",
    "            # print(f'number of samples in this batch : {samples}')\n",
    "            total_samples += samples\n",
    "            data, target = torch.tensor(data).to(device, dtype=torch.float32), \\\n",
    "                torch.tensor(target).to(device, dtype=torch.float32)\n",
    "            output = unet_model(data)\n",
    "            val = loss_fn(output, target)\n",
    "            val_losses.append(val.detach().cpu().numpy())\n",
    "            \n",
    "    return {'val_loss': np.mean(val_losses),}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8cdf13",
   "metadata": {},
   "source": [
    "### Start the federated learning experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361e4032",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an experimnet in federation\n",
    "experiment_name = 'brain_MRI_experiment'\n",
    "fl_experiment = FLExperiment(federation=federation, experiment_name=experiment_name)\n",
    "\n",
    "\n",
    "# Start the federation experiment\n",
    "fl_experiment.start(model_provider=MI, \n",
    "                    task_keeper=TI,\n",
    "                    data_loader=brain_dataset,\n",
    "                    rounds_to_train=50,\n",
    "                    opt_treatment='CONTINUE_GLOBAL',\n",
    "                    device_assignment_policy='CUDA_PREFERRED')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a720822f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To track the training process\n",
    "fl_experiment.stream_metrics()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

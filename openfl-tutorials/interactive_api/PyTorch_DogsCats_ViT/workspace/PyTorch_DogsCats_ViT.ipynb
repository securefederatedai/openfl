{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visual Transformer + OpenFL for Dogs & Cats classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies if not already installed\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from copy import deepcopy\n",
    "\n",
    "from linformer import Linformer\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset, SubsetRandomSampler\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "from torchvision import transforms\n",
    "\n",
    "import tqdm\n",
    "\n",
    "from vit_pytorch.efficient import ViT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connect to the Federation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a federation\n",
    "from openfl.interface.interactive_api.federation import Federation\n",
    "\n",
    "# please use the same identificator that was used in signed certificate\n",
    "client_id = 'api'\n",
    "director_node_fqdn = 'localhost'\n",
    "director_port = 50051\n",
    "\n",
    "# 1) Run with API layer - Director mTLS\n",
    "# If the user wants to enable mTLS their must provide CA root chain,\n",
    "# and signed key pair to the federation interface\n",
    "# cert_chain = 'cert/root_ca.crt'\n",
    "# API_certificate = 'cert/frontend.crt'\n",
    "# API_private_key = 'cert/frontend.key'\n",
    "\n",
    "# federation = Federation(\n",
    "#     client_id=client_id,\n",
    "#     director_node_fqdn=director_node_fqdn,\n",
    "#     director_port=director_port,\n",
    "#     tls=True,\n",
    "#     cert_chain=cert_chain,\n",
    "#     api_cert=api_certificate,\n",
    "#     api_private_key=api_private_key\n",
    "# )\n",
    "\n",
    "# --------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# 2) Run with TLS disabled (trusted environment)\n",
    "# Federation can also determine local fqdn automatically\n",
    "federation = Federation(\n",
    "    client_id=client_id,\n",
    "    director_node_fqdn=director_node_fqdn,\n",
    "    director_port=director_port,\n",
    "    tls=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shard_registry = federation.get_shard_registry()\n",
    "shard_registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "federation.target_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, request a dummy_shard_desc that holds information about the federated dataset\n",
    "dummy_shard_desc = federation.get_dummy_shard_descriptor(size=10)\n",
    "dummy_shard_dataset = dummy_shard_desc.get_dataset('train')\n",
    "sample, target = dummy_shard_dataset[0]\n",
    "f\"Sample shape: {sample.shape}, target shape: {target.shape}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a FL experiment using Interactive API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openfl.interface.interactive_api.experiment import DataInterface, FLExperiment, ModelInterface, TaskInterface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training settings\n",
    "batch_size = 64\n",
    "lr = 3e-5\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\n",
    "seed_everything(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Register dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DogsCatsShardDataset(Dataset):\n",
    "    def __init__(self, dataset, transform_type=\"train\"):\n",
    "        self._dataset = dataset\n",
    "\n",
    "        # Image Augumentation\n",
    "        if transform_type == \"train\":\n",
    "            self.transform = transforms.Compose(\n",
    "                [\n",
    "                    transforms.ToPILImage(),\n",
    "                    transforms.Resize((224, 224)),\n",
    "                    transforms.RandomResizedCrop(224),\n",
    "                    transforms.RandomHorizontalFlip(),\n",
    "                    transforms.ToTensor(),\n",
    "                ]\n",
    "            )\n",
    "        elif transform_type == \"val\":\n",
    "            self.transform = transforms.Compose(\n",
    "                [\n",
    "                    transforms.ToPILImage(),\n",
    "                    transforms.Resize(256),\n",
    "                    transforms.CenterCrop(224),\n",
    "                    transforms.ToTensor(),\n",
    "                ]\n",
    "            )\n",
    "        elif transform_type == \"test\":\n",
    "            self.transform = transforms.Compose(\n",
    "                [\n",
    "                    transforms.ToPILImage(),\n",
    "                    transforms.Resize(256),\n",
    "                    transforms.CenterCrop(224),\n",
    "                    transforms.ToTensor(),\n",
    "                ]\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(\"Invalid transform type: {}\".format(transform_type))\n",
    "\n",
    "    def __len__(self):\n",
    "        self.filelength = len(self._dataset)\n",
    "        return self.filelength\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img, label = self._dataset[idx]\n",
    "        img_transformed = self.transform(img).numpy()\n",
    "        return img_transformed, label[0]\n",
    "\n",
    "\n",
    "# Now you can implement your data loaders using dummy_shard_desc\n",
    "class DogsCatsSD(DataInterface):\n",
    "\n",
    "    def __init__(self, validation_fraction=1/5, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        self.validation_fraction = validation_fraction\n",
    "\n",
    "    @property\n",
    "    def shard_descriptor(self):\n",
    "        return self._shard_descriptor\n",
    "\n",
    "    @shard_descriptor.setter\n",
    "    def shard_descriptor(self, shard_descriptor):\n",
    "        \"\"\"\n",
    "        Describe per-collaborator procedures or sharding.\n",
    "\n",
    "        This method will be called during a collaborator initialization.\n",
    "        Local shard_descriptor  will be set by Envoy.\n",
    "        \"\"\"\n",
    "        self._shard_descriptor = shard_descriptor\n",
    "        self._shard_dataset = DogsCatsShardDataset(shard_descriptor.get_dataset('train'))\n",
    "\n",
    "        validation_size = max(1, int(len(self._shard_dataset) * self.validation_fraction))\n",
    "\n",
    "        self.train_indexes = np.arange(len(self._shard_dataset) - validation_size)\n",
    "        self.val_indexes = np.arange(len(self._shard_dataset) - validation_size, len(self._shard_dataset))\n",
    "\n",
    "    def get_train_loader(self, **kwargs):\n",
    "        \"\"\"\n",
    "        Output of this method will be provided to tasks with optimizer in contract\n",
    "        \"\"\"\n",
    "        train_sampler = SubsetRandomSampler(self.train_indexes)\n",
    "\n",
    "        return DataLoader(\n",
    "            self._shard_dataset,\n",
    "            num_workers=8,\n",
    "            batch_size=self.kwargs['train_bs'],\n",
    "            sampler=train_sampler\n",
    "        )\n",
    "\n",
    "    def get_valid_loader(self, **kwargs):\n",
    "        \"\"\"\n",
    "        Output of this method will be provided to tasks without optimizer in contract\n",
    "        \"\"\"\n",
    "        val_sampler = SubsetRandomSampler(self.val_indexes)\n",
    "        return DataLoader(\n",
    "            self._shard_dataset,\n",
    "            num_workers=8,\n",
    "            batch_size=self.kwargs['valid_bs'],\n",
    "            sampler=val_sampler\n",
    "        )\n",
    "\n",
    "    def get_train_data_size(self):\n",
    "        \"\"\"\n",
    "        Information for aggregation\n",
    "        \"\"\"\n",
    "        return len(self.train_indexes)\n",
    "\n",
    "    def get_valid_data_size(self):\n",
    "        \"\"\"\n",
    "        Information for aggregation\n",
    "        \"\"\"\n",
    "        return len(self.val_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fed_dataset = DogsCatsSD(train_bs=batch_size, valid_bs=batch_size)\n",
    "fed_dataset.shard_descriptor = dummy_shard_desc\n",
    "for i, (sample, target) in enumerate(fed_dataset.get_train_loader()):\n",
    "    print(sample.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Describe a model and optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "efficient_transformer = Linformer(\n",
    "    dim=128,\n",
    "    seq_len=49 + 1,  # 7x7 patches + 1 cls-token\n",
    "    depth=12,\n",
    "    heads=8,\n",
    "    k=64\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visual Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ViT(\n",
    "    dim=128,\n",
    "    image_size=224,\n",
    "    patch_size=32,\n",
    "    num_classes=2,\n",
    "    transformer=efficient_transformer,\n",
    "    channels=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Register model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "framework_adapter = 'openfl.plugins.frameworks_adapters.pytorch_adapter.FrameworkAdapterPlugin'\n",
    "MI = ModelInterface(model=model, optimizer=optimizer, framework_plugin=framework_adapter)\n",
    "\n",
    "# Save the initial model state\n",
    "initial_model = deepcopy(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define and register FL tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openfl.interface.aggregation_functions import Median\n",
    "\n",
    "\n",
    "TI = TaskInterface()\n",
    "\n",
    "\n",
    "# The Interactive API supports registering functions definied in main module or imported.\n",
    "def function_defined_in_notebook(some_parameter):\n",
    "    print(f'Also I accept a parameter and it is {some_parameter}')\n",
    "\n",
    "\n",
    "# The Interactive API supports overriding of the aggregation function\n",
    "aggregation_function = Median()\n",
    "\n",
    "\n",
    "# Task interface currently supports only standalone functions.\n",
    "@TI.add_kwargs(**{'some_parameter': 42})\n",
    "@TI.register_fl_task(model='model', data_loader='train_loader',\n",
    "                     device='device', optimizer='optimizer', round_num='round_num')\n",
    "@TI.set_aggregation_function(aggregation_function)\n",
    "def train(model, train_loader, optimizer, round_num, device, loss_fn=criterion, some_parameter=None):\n",
    "    function_defined_in_notebook(some_parameter)\n",
    "    epoch_loss = 0\n",
    "    epoch_accuracy = 0\n",
    "\n",
    "    # Be careful at the scheduler initialization stage makes 'step()', that's why: \n",
    "    # * if you have one epoch per round DO NOT do 'scheduler.step()' at all.\n",
    "    # * if you have several epoch per round, makes 'scheduler.step()' for all of them EXCEPT the last one.\n",
    "    scheduler = StepLR(optimizer, step_size=1, gamma=0.1, verbose=True, last_epoch=round_num-1)\n",
    "    train_loader = tqdm.tqdm(train_loader, desc=\"train\")\n",
    "    model.train()\n",
    "    model.to(device)\n",
    "\n",
    "    for data, target in train_loader:\n",
    "        data, target = torch.tensor(data).to(device), torch.tensor(target).to(device, dtype=torch.long)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = loss_fn(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        acc = (output.argmax(dim=1) == target).float().mean()\n",
    "        epoch_accuracy += acc.cpu().numpy() / len(train_loader)\n",
    "        epoch_loss += loss.detach().cpu().numpy() / len(train_loader)\n",
    "\n",
    "    return {'loss': epoch_loss, 'accuracy': epoch_accuracy}\n",
    "\n",
    "\n",
    "@TI.register_fl_task(model='model', data_loader='val_loader', device='device')\n",
    "def validate(model, val_loader, device):\n",
    "\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "\n",
    "    val_loader = tqdm.tqdm(val_loader, desc=\"validate\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        epoch_val_accuracy = 0\n",
    "        epoch_val_loss = 0\n",
    "        for data, target in val_loader:\n",
    "            data, target = torch.tensor(data).to(device), torch.tensor(target).to(device, dtype=torch.long)\n",
    "            val_output = model(data)\n",
    "            val_loss = criterion(val_output, target)\n",
    "\n",
    "            acc = (val_output.argmax(dim=1) == target).float().mean()\n",
    "            epoch_val_accuracy += acc.cpu().numpy() / len(val_loader)\n",
    "            epoch_val_loss += val_loss.detach().cpu().numpy() / len(val_loader)\n",
    "\n",
    "    return {'val_loss': epoch_val_loss, 'val_accuracy': epoch_val_accuracy}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time to start a federated learning experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an experimnet in federation\n",
    "experiment_name = 'ViT_DogsCats_experiment'\n",
    "fl_experiment = FLExperiment(federation=federation, experiment_name=experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following command zips the workspace and python requirements to be transfered to collaborator nodes\n",
    "fl_experiment.start(model_provider=MI,\n",
    "                    task_keeper=TI,\n",
    "                    data_loader=fed_dataset,\n",
    "                    rounds_to_train=5,\n",
    "                    opt_treatment='CONTINUE_GLOBAL',\n",
    "                    device_assignment_policy='CUDA_PREFERRED')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If user want to stop IPython session, then reconnect and check how experiment is going\n",
    "# fl_experiment.restore_experiment_state(MI)\n",
    "\n",
    "fl_experiment.stream_metrics()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9967838c9b78b23db9544bb47605a6e8593c36ad0f41631a68de5734b7160f0f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit ('openfl_Kvasir': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

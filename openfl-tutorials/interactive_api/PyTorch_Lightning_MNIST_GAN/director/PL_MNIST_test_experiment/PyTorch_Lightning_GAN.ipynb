{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "liquid-jacket",
   "metadata": {},
   "source": [
    "# Federated GAN tutorial with PyTorch Lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "alike-sharing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytorch-lightning>=1.3 in /home/mansisha/v_pl/lib/python3.8/site-packages (1.5.6)\n",
      "Requirement already satisfied: torch==1.9.1 in /home/mansisha/v_pl/lib/python3.8/site-packages (1.9.1)\n",
      "Requirement already satisfied: torchvision==0.10.1 in /home/mansisha/v_pl/lib/python3.8/site-packages (0.10.1)\n",
      "Requirement already satisfied: torchmetrics>=0.3 in /home/mansisha/v_pl/lib/python3.8/site-packages (0.6.2)\n",
      "Requirement already satisfied: dill==0.3.4 in /home/mansisha/v_pl/lib/python3.8/site-packages (0.3.4)\n",
      "Requirement already satisfied: typing-extensions in /home/mansisha/v_pl/lib/python3.8/site-packages (from torch==1.9.1) (3.10.0.2)\n",
      "Requirement already satisfied: pillow>=5.3.0 in /home/mansisha/v_pl/lib/python3.8/site-packages (from torchvision==0.10.1) (8.4.0)\n",
      "Requirement already satisfied: numpy in /home/mansisha/v_pl/lib/python3.8/site-packages (from torchvision==0.10.1) (1.21.4)\n",
      "Requirement already satisfied: fsspec[http]!=2021.06.0,>=2021.05.0 in /home/mansisha/v_pl/lib/python3.8/site-packages (from pytorch-lightning>=1.3) (2021.11.1)\n",
      "Requirement already satisfied: PyYAML>=5.1 in /home/mansisha/v_pl/lib/python3.8/site-packages (from pytorch-lightning>=1.3) (6.0)\n",
      "Requirement already satisfied: tensorboard>=2.2.0 in /home/mansisha/v_pl/lib/python3.8/site-packages (from pytorch-lightning>=1.3) (2.2.0)\n",
      "Requirement already satisfied: tqdm>=4.41.0 in /home/mansisha/v_pl/lib/python3.8/site-packages (from pytorch-lightning>=1.3) (4.62.3)\n",
      "Requirement already satisfied: pyDeprecate==0.3.1 in /home/mansisha/v_pl/lib/python3.8/site-packages (from pytorch-lightning>=1.3) (0.3.1)\n",
      "Requirement already satisfied: future>=0.17.1 in /home/mansisha/v_pl/lib/python3.8/site-packages (from pytorch-lightning>=1.3) (0.18.2)\n",
      "Requirement already satisfied: packaging>=17.0 in /home/mansisha/v_pl/lib/python3.8/site-packages (from pytorch-lightning>=1.3) (21.3)\n",
      "Requirement already satisfied: requests in /home/mansisha/v_pl/lib/python3.8/site-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.3) (2.26.0)\n",
      "Requirement already satisfied: aiohttp in /home/mansisha/v_pl/lib/python3.8/site-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.3) (3.8.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/mansisha/v_pl/lib/python3.8/site-packages (from packaging>=17.0->pytorch-lightning>=1.3) (3.0.6)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /home/mansisha/v_pl/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.3) (47.1.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/mansisha/v_pl/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.3) (1.8.0)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /home/mansisha/v_pl/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.3) (1.35.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/mansisha/v_pl/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.3) (3.3.6)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/mansisha/v_pl/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.3) (0.4.6)\n",
      "Requirement already satisfied: six>=1.10.0 in /home/mansisha/v_pl/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.3) (1.16.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /home/mansisha/v_pl/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.3) (0.37.0)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /home/mansisha/v_pl/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.3) (1.34.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/mansisha/v_pl/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.3) (2.0.2)\n",
      "Requirement already satisfied: absl-py>=0.4 in /home/mansisha/v_pl/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.3) (1.0.0)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /home/mansisha/v_pl/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.3) (3.19.1)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /home/mansisha/v_pl/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning>=1.3) (4.2.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/mansisha/v_pl/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning>=1.3) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/mansisha/v_pl/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning>=1.3) (4.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/mansisha/v_pl/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning>=1.3) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /home/mansisha/v_pl/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning>=1.3) (4.9.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/mansisha/v_pl/lib/python3.8/site-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.3) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/mansisha/v_pl/lib/python3.8/site-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.3) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/mansisha/v_pl/lib/python3.8/site-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.3) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/mansisha/v_pl/lib/python3.8/site-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.3) (2.0.9)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/mansisha/v_pl/lib/python3.8/site-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.3) (1.2.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/mansisha/v_pl/lib/python3.8/site-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.3) (4.0.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/mansisha/v_pl/lib/python3.8/site-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.3) (1.7.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/mansisha/v_pl/lib/python3.8/site-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.3) (1.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/mansisha/v_pl/lib/python3.8/site-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.3) (5.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/mansisha/v_pl/lib/python3.8/site-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.3) (21.2.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/mansisha/v_pl/lib/python3.8/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning>=1.3) (3.6.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/mansisha/v_pl/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning>=1.3) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/mansisha/v_pl/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning>=1.3) (3.1.1)\n"
     ]
    }
   ],
   "source": [
    "# Install dependencies if not already installed\n",
    "!pip install \"pytorch-lightning>=1.3\" \"torch==1.9.1\" \"torchvision==0.10.1\" \"torchmetrics>=0.3\" \"dill==0.3.4\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16986f22",
   "metadata": {},
   "source": [
    "# Connect to the Federation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4485ac79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a federation\n",
    "from openfl.interface.interactive_api.federation import Federation\n",
    "\n",
    "# please use the same identificator that was used in signed certificate\n",
    "client_id = 'frontend'\n",
    "director_node_fqdn = 'localhost'\n",
    "director_port = 50050\n",
    "\n",
    "# 1) Run with API layer - Director mTLS \n",
    "# If the user wants to enable mTLS their must provide CA root chain, and signed key pair to the federation interface\n",
    "# cert_chain = 'cert/root_ca.crt'\n",
    "# API_certificate = 'cert/frontend.crt'\n",
    "# API_private_key = 'cert/frontend.key'\n",
    "\n",
    "# federation = Federation(\n",
    "#     client_id=client_id,\n",
    "#     director_node_fqdn=director_node_fqdn,\n",
    "#     director_port=director_port,\n",
    "#     tls=True,\n",
    "#     cert_chain=cert_chain,\n",
    "#     api_cert=api_certificate,\n",
    "#     api_private_key=api_private_key\n",
    "# )\n",
    "\n",
    "# --------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# 2) Run with TLS disabled (trusted environment)\n",
    "# Federation can also determine local fqdn automatically\n",
    "federation = Federation(\n",
    "    client_id=client_id,\n",
    "    director_node_fqdn=director_node_fqdn,\n",
    "    director_port=director_port,\n",
    "    tls=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e35802d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'env_one': {'shard_info': node_info {\n",
       "    name: \"env_one\"\n",
       "    cuda_devices {\n",
       "    }\n",
       "    cuda_devices {\n",
       "      index: 2\n",
       "    }\n",
       "  }\n",
       "  shard_description: \"Mnist dataset, shard number 1 out of 2\"\n",
       "  sample_shape: \"28\"\n",
       "  sample_shape: \"28\"\n",
       "  target_shape: \"1\",\n",
       "  'is_online': True,\n",
       "  'is_experiment_running': False,\n",
       "  'last_updated': '2021-12-29 11:00:02',\n",
       "  'current_time': '2021-12-29 11:00:28',\n",
       "  'valid_duration': seconds: 120,\n",
       "  'experiment_name': 'ExperimentName Mock'}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import time\n",
    "# while True:\n",
    "#     shard_registry = federation.get_shard_registry()\n",
    "#     print(shard_registry)\n",
    "#     time.sleep(5)\n",
    "shard_registry = federation.get_shard_registry()\n",
    "shard_registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67ae50de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "federation.target_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "920216d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, request a dummy_shard_desc that holds information about the federated dataset \n",
    "# dummy_shard_desc = federation.get_dummy_shard_descriptor(size=10)\n",
    "# dummy_shard_dataset = dummy_shard_desc.get_dataset('train')\n",
    "# sample, target = dummy_shard_dataset[0]\n",
    "# f\"Sample shape: {sample.shape}, target shape: {target.shape}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "obvious-tyler",
   "metadata": {},
   "source": [
    "## Creating a FL experiment using Interactive API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "rubber-address",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openfl.interface.interactive_api.experiment import TaskInterface, DataInterface, ModelInterface, FLExperiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sustainable-public",
   "metadata": {},
   "source": [
    "### Register dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d9acb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import OrderedDict\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from pytorch_lightning import LightningDataModule, LightningModule, Trainer\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision.datasets import MNIST\n",
    "\n",
    "# PATH_DATASETS = os.environ.get(\"PATH_DATASETS\", \".\")\n",
    "# AVAIL_GPUS = min(1, torch.cuda.device_count())\n",
    "# BATCH_SIZE = 256 if AVAIL_GPUS else 64\n",
    "# NUM_WORKERS = int(os.cpu_count() / 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81afeb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class MNISTDataModule(LightningDataModule):\n",
    "#     def __init__(\n",
    "#         self,\n",
    "#         data_dir: str = PATH_DATASETS,\n",
    "#         batch_size: int = BATCH_SIZE,\n",
    "#         num_workers: int = NUM_WORKERS,\n",
    "#     ):\n",
    "#         super().__init__()\n",
    "#         self.data_dir = data_dir\n",
    "#         self.batch_size = batch_size\n",
    "#         self.num_workers = num_workers\n",
    "\n",
    "#         self.transform = transforms.Compose(\n",
    "#             [\n",
    "#                 transforms.ToTensor(),\n",
    "#                 transforms.Normalize((0.1307,), (0.3081,)),\n",
    "#             ]\n",
    "#         )\n",
    "\n",
    "#         # self.dims is returned when you call dm.size()\n",
    "#         # Setting default dims here because we know them.\n",
    "#         # Could optionally be assigned dynamically in dm.setup()\n",
    "#         self.dims = (1, 28, 28)\n",
    "#         self.num_classes = 10\n",
    "\n",
    "#     def prepare_data(self):\n",
    "#         # download\n",
    "#         MNIST(self.data_dir, train=True, download=True)\n",
    "#         MNIST(self.data_dir, train=False, download=True)\n",
    "\n",
    "#     def setup(self, stage=None):\n",
    "#         # Assign train/val datasets for use in dataloaders\n",
    "#         if stage == \"fit\" or stage is None:\n",
    "#             mnist_full = MNIST(self.data_dir, train=True, transform=self.transform)\n",
    "#             self.mnist_train, self.mnist_val = random_split(mnist_full, [55000, 5000])\n",
    "\n",
    "#         # Assign test dataset for use in dataloader(s)\n",
    "#         if stage == \"test\" or stage is None:\n",
    "#             self.mnist_test = MNIST(self.data_dir, train=False, transform=self.transform)\n",
    "\n",
    "#     def train_dataloader(self):\n",
    "#         return DataLoader(\n",
    "#             self.mnist_train,\n",
    "#             batch_size=self.batch_size,\n",
    "#             num_workers=self.num_workers,\n",
    "#         )\n",
    "\n",
    "#     def val_dataloader(self):\n",
    "#         return DataLoader(self.mnist_val, batch_size=self.batch_size, num_workers=self.num_workers)\n",
    "\n",
    "#     def test_dataloader(self):\n",
    "#         return DataLoader(self.mnist_test, batch_size=self.batch_size, num_workers=self.num_workers)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64f37dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import PIL\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms as tsf\n",
    "\n",
    "# Now you can implement you data loaders using dummy_shard_desc\n",
    "class MnistFedDataset(DataInterface):\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    @property\n",
    "    def shard_descriptor(self):\n",
    "        return self._shard_descriptor\n",
    "\n",
    "    @shard_descriptor.setter\n",
    "    def shard_descriptor(self, shard_descriptor):\n",
    "        \"\"\"\n",
    "        Describe per-collaborator procedures or sharding.\n",
    "\n",
    "        This method will be called during a collaborator initialization.\n",
    "        Local shard_descriptor will be set by Envoy.\n",
    "        \"\"\"\n",
    "        self._shard_descriptor = shard_descriptor\n",
    "        \n",
    "        self.train_set = shard_descriptor.get_dataset('train')\n",
    "        self.valid_set = shard_descriptor.get_dataset('val')\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.shard_descriptor[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.shard_descriptor)\n",
    "\n",
    "    def get_train_loader(self):\n",
    "        \"\"\"\n",
    "        Output of this method will be provided to tasks with optimizer in contract\n",
    "        \"\"\"\n",
    "        if self.kwargs['train_bs']:\n",
    "            batch_size = self.kwargs['train_bs']\n",
    "        else:\n",
    "            batch_size = 64\n",
    "        return DataLoader(self.train_set, batch_size=batch_size, num_workers=36)\n",
    "\n",
    "    def get_valid_loader(self):\n",
    "        \"\"\"\n",
    "        Output of this method will be provided to tasks without optimizer in contract\n",
    "        \"\"\"\n",
    "        if self.kwargs['valid_bs']:\n",
    "            batch_size = self.kwargs['valid_bs']\n",
    "        else:\n",
    "            batch_size = 64\n",
    "        \n",
    "        return DataLoader(self.valid_set, batch_size=batch_size)\n",
    "\n",
    "    def get_train_data_size(self):\n",
    "        \"\"\"\n",
    "        Information for aggregation\n",
    "        \"\"\"\n",
    "        \n",
    "        return len(self.train_set)\n",
    "\n",
    "    def get_valid_data_size(self):\n",
    "        \"\"\"\n",
    "        Information for aggregation\n",
    "        \"\"\"\n",
    "        return len(self.val_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d8df35f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fed_dataset = MnistFedDataset(train_bs=256, valid_bs=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caring-distinction",
   "metadata": {},
   "source": [
    "### Describe a model and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "visible-victor",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "foreign-gospel",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Generator and discriminator model definition\n",
    "\"\"\"\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, latent_dim, img_shape):\n",
    "        super().__init__()\n",
    "        self.img_shape = img_shape\n",
    "\n",
    "        def block(in_feat, out_feat, normalize=True):\n",
    "            layers = [nn.Linear(in_feat, out_feat)]\n",
    "            if normalize:\n",
    "                layers.append(nn.BatchNorm1d(out_feat, 0.8))\n",
    "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "            return layers\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            *block(latent_dim, 128, normalize=False),\n",
    "            *block(128, 256),\n",
    "            *block(256, 512),\n",
    "            *block(512, 1024),\n",
    "            nn.Linear(1024, int(np.prod(img_shape))),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        z = z.float()\n",
    "        img = self.model(z)\n",
    "        img = img.view(img.size(0), *self.img_shape)\n",
    "        return img\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "981b810c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, img_shape):\n",
    "        super().__init__()\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(int(np.prod(img_shape)), 512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, img):\n",
    "        img_flat = img.view(img.size(0), -1)\n",
    "        img_flat = img_flat.float()\n",
    "        validity = self.model(img_flat)\n",
    "\n",
    "        return validity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6cc92e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAN(LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        channels,\n",
    "        width,\n",
    "        height,\n",
    "#         generator,\n",
    "#         discriminator,\n",
    "        latent_dim: int = 100,\n",
    "        lr: float = 0.0002,\n",
    "        b1: float = 0.5,\n",
    "        b2: float = 0.999,\n",
    "        batch_size: int = 256,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        # networks\n",
    "        data_shape = (channels, width, height)\n",
    "#         self.generator = generator\n",
    "#         self.discriminator = discriminator\n",
    "        self.generator = Generator(latent_dim=self.hparams.latent_dim, img_shape=data_shape)\n",
    "        self.discriminator = Discriminator(img_shape=data_shape)\n",
    "\n",
    "        self.validation_z = torch.randn(8, self.hparams.latent_dim)\n",
    "#         self.validation_z = torch.randn(8, 100)\n",
    "#         self.example_input_array = torch.zeros(2, 100)\n",
    "\n",
    "        self.example_input_array = torch.zeros(2, self.hparams.latent_dim)\n",
    "\n",
    "    def forward(self, z):\n",
    "        return self.generator(z)\n",
    "\n",
    "    def adversarial_loss(self, y_hat, y):\n",
    "        return F.binary_cross_entropy(y_hat, y)\n",
    "\n",
    "    def training_step(self, batch, batch_idx, optimizer_idx):\n",
    "        imgs, _ = batch\n",
    "\n",
    "        # sample noise\n",
    "        z = torch.randn(imgs.shape[0], self.hparams.latent_dim)\n",
    "        z = z.type_as(imgs)\n",
    "\n",
    "        # train generator\n",
    "        if optimizer_idx == 0:\n",
    "\n",
    "            # generate images\n",
    "            self.generated_imgs = self(z)\n",
    "\n",
    "            # log sampled images\n",
    "            sample_imgs = self.generated_imgs[:6]\n",
    "            grid = torchvision.utils.make_grid(sample_imgs)\n",
    "            self.logger.experiment.add_image(\"generated_images\", grid, 0)\n",
    "\n",
    "            # ground truth result (ie: all fake)\n",
    "            # put on GPU because we created this tensor inside training_loop\n",
    "            valid = torch.ones(imgs.size(0), 1)\n",
    "#            valid = valid.type_as(imgs)\n",
    "            valid = valid.type_as(imgs).float()\n",
    "\n",
    "            # adversarial loss is binary cross-entropy\n",
    "            g_loss = self.adversarial_loss(self.discriminator(self(z)), valid)\n",
    "            tqdm_dict = {\"g_loss\": g_loss}\n",
    "            output = OrderedDict({\"loss\": g_loss, \"progress_bar\": tqdm_dict, \"log\": tqdm_dict})\n",
    "            return output\n",
    "\n",
    "        # train discriminator\n",
    "        if optimizer_idx == 1:\n",
    "            # Measure discriminator's ability to classify real from generated samples\n",
    "\n",
    "            # how well can it label as real?\n",
    "            valid = torch.ones(imgs.size(0), 1)\n",
    "#            valid = valid.type_as(imgs)\n",
    "            valid = valid.type_as(imgs).float()\n",
    "\n",
    "            real_loss = self.adversarial_loss(self.discriminator(imgs), valid)\n",
    "\n",
    "            # how well can it label as fake?\n",
    "            fake = torch.zeros(imgs.size(0), 1)\n",
    "#             fake = fake.type_as(imgs)\n",
    "            fake = fake.type_as(imgs).float()\n",
    "\n",
    "            fake_loss = self.adversarial_loss(self.discriminator(self(z).detach()), fake)\n",
    "\n",
    "            # discriminator loss is the average of these\n",
    "            d_loss = (real_loss + fake_loss) / 2\n",
    "            tqdm_dict = {\"d_loss\": d_loss}\n",
    "            output = OrderedDict({\"loss\": d_loss, \"progress_bar\": tqdm_dict, \"log\": tqdm_dict})\n",
    "            return output\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        print(\"Inside conf optimizers\")\n",
    "        lr = self.hparams.lr\n",
    "        b1 = self.hparams.b1\n",
    "        b2 = self.hparams.b2\n",
    "\n",
    "        opt_g = torch.optim.Adam(self.generator.parameters(), lr=lr, betas=(b1, b2))\n",
    "        opt_d = torch.optim.Adam(self.discriminator.parameters(), lr=lr, betas=(b1, b2))\n",
    "#         return [opt_g, opt_d], []\n",
    "        return [opt_g, opt_d]\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        z = self.validation_z.type_as(self.generator.model[0].weight)\n",
    "\n",
    "        # log sampled images\n",
    "        sample_imgs = self(z)\n",
    "        grid = torchvision.utils.make_grid(sample_imgs)\n",
    "        self.logger.experiment.add_image(\"generated_images\", grid, self.current_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "46692b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_shape = (1, 28, 28)\n",
    "model = GAN(1,28,28)\n",
    "# model = GAN(1,28,28,generator=Generator(latent_dim=int(100), img_shape=data_shape),\n",
    "#             discriminator=Discriminator(img_shape=data_shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "greater-activation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inside conf optimizers\n"
     ]
    }
   ],
   "source": [
    "# This optimizer is not directly used inside the module\n",
    "#optimizer = optim.Adam(model.parameters(), lr=float(0.0002), betas=(float(0.5), float(0.999)))\n",
    "optimizer = model.configure_optimizers()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caroline-passion",
   "metadata": {},
   "source": [
    "#### Register model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "handled-teens",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "framework_adapter = 'openfl.plugins.frameworks_adapters.pytorch_adapter_with_multiple_opt.FrameworkAdapterPlugin'\n",
    "MI = ModelInterface(model=model, optimizer=optimizer, framework_plugin=framework_adapter)\n",
    "\n",
    "# Save the initial model state\n",
    "initial_model = deepcopy(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "portuguese-groove",
   "metadata": {},
   "source": [
    "### Define and register FL tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "increasing-builder",
   "metadata": {},
   "outputs": [],
   "source": [
    "TI = TaskInterface()\n",
    "import torch\n",
    "\n",
    "import tqdm\n",
    "#from openfl.component.aggregation_functions import Median\n",
    "\n",
    "# The Interactive API supports registering functions definied in main module or imported.\n",
    "def function_defined_in_notebook(some_parameter):\n",
    "    print(f'Also I accept a parameter and it is {some_parameter}')\n",
    "\n",
    "# Task interface currently supports only standalone functions.\n",
    "@TI.add_kwargs(**{'some_parameter': 42})\n",
    "@TI.register_fl_task(model='model', data_loader='train_loader', \\\n",
    "                     device='device', optimizer='optimizer')     \n",
    "def train(model, train_loader, optimizer, device, some_parameter=None):\n",
    "    \n",
    "    print(f'\\n\\n TASK TRAIN GOT DEVICE {device}\\n\\n')\n",
    "    \n",
    "    function_defined_in_notebook(some_parameter)\n",
    "    \n",
    "    AVAIL_GPUS = 1 if device == 'cuda' else 0\n",
    "    \n",
    "#     train_loader = tqdm.tqdm(train_loader, desc=\"train\")\n",
    "    \n",
    "#     unet_model.train()\n",
    "#     unet_model.to(device)\n",
    "\n",
    "#     losses = []\n",
    "    trainer = Trainer(gpus=[3], max_epochs= 1, progress_bar_refresh_rate=20)\n",
    "    trainer.fit(model = model, train_dataloaders = train_loader)\n",
    "\n",
    "#     for data, target in train_loader:\n",
    "#         data, target = torch.tensor(data).to(device), torch.tensor(\n",
    "#             target).to(device, dtype=torch.float32)\n",
    "#         optimizer.zero_grad()\n",
    "#         output = unet_model(data)\n",
    "#         loss = loss_fn(output=output, target=target)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         losses.append(loss.detach().cpu().numpy())\n",
    "        \n",
    "    return {'train_loss': 0.111}\n",
    "\n",
    "\n",
    "# @TI.register_fl_task(model='unet_model', data_loader='val_loader', device='device')     \n",
    "# def validate(unet_model, val_loader, device):\n",
    "#     print(f'\\n\\n TASK VALIDATE GOT DEVICE {device}\\n\\n')\n",
    "    \n",
    "#     unet_model.eval()\n",
    "#     unet_model.to(device)\n",
    "    \n",
    "#     val_loader = tqdm.tqdm(val_loader, desc=\"validate\")\n",
    "\n",
    "#     val_score = 0\n",
    "#     total_samples = 0\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         for data, target in val_loader:\n",
    "#             samples = target.shape[0]\n",
    "#             total_samples += samples\n",
    "#             data, target = torch.tensor(data).to(device), \\\n",
    "#                 torch.tensor(target).to(device, dtype=torch.int64)\n",
    "#             output = unet_model(data)\n",
    "#             val = soft_dice_coef(output, target)\n",
    "#             val_score += val.sum().cpu().numpy()\n",
    "            \n",
    "#     return {'dice_coef': val_score / total_samples,}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "derived-bride",
   "metadata": {},
   "source": [
    "## Time to start a federated learning experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "mature-renewal",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an experimnet in federation\n",
    "experiment_name = 'PL_MNIST_test_experiment'\n",
    "serializer_plugin = 'openfl.plugins.interface_serializer.cloudpickle_serializer.CloudpickleSerializer'\n",
    "#serializer_plugin = 'openfl.plugins.interface_serializer.dill_serializer.DillSerializer'\n",
    "fl_experiment = FLExperiment(federation=federation, experiment_name=experiment_name, serializer_plugin=serializer_plugin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "lightweight-causing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">[11:00:29] </span><span style=\"color: #000080\">INFO</span>     Building <span style=\"color: #800000\">ðŸ¡†</span> Object <span style=\"color: #800000\">CloudpickleSerializer</span> from <span style=\"color: #800000\">openfl.plugins.interface_serializer.cloudpickle_serializer</span> Module.                  <a href=\"file:///home/mansisha/v_pl/lib/python3.8/site-packages/openfl/federated/plan/plan.py\"><span style=\"color: #7f7f7f\">plan.py</span></a><span style=\"color: #7f7f7f\">:170</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7ff2cb725f10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">           </span><span style=\"color: #000080\">INFO</span>     Settings <span style=\"color: #800000\">ðŸ¡†</span> <span style=\"font-weight: bold\">{}</span>                                                                                                                    <a href=\"file:///home/mansisha/v_pl/lib/python3.8/site-packages/openfl/federated/plan/plan.py\"><span style=\"color: #7f7f7f\">plan.py</span></a><span style=\"color: #7f7f7f\">:173</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7ff2cb725f10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">           </span><span style=\"color: #000080\">INFO</span>     Override <span style=\"color: #800000\">ðŸ¡†</span> <span style=\"font-weight: bold\">{}</span>                                                                                                                    <a href=\"file:///home/mansisha/v_pl/lib/python3.8/site-packages/openfl/federated/plan/plan.py\"><span style=\"color: #7f7f7f\">plan.py</span></a><span style=\"color: #7f7f7f\">:175</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7ff2cb725f10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">           </span><span style=\"color: #000080\">INFO</span>     Building <span style=\"color: #800000\">ðŸ¡†</span> Object <span style=\"color: #800000\">FrameworkAdapterPlugin</span> from <span style=\"color: #800000\">openfl.plugins.frameworks_adapters.pytorch_adapter_with_multiple_opt</span> Module.       <a href=\"file:///home/mansisha/v_pl/lib/python3.8/site-packages/openfl/federated/plan/plan.py\"><span style=\"color: #7f7f7f\">plan.py</span></a><span style=\"color: #7f7f7f\">:170</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7ff2cb6b89d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">           </span><span style=\"color: #000080\">INFO</span>     Settings <span style=\"color: #800000\">ðŸ¡†</span> <span style=\"font-weight: bold\">{}</span>                                                                                                                    <a href=\"file:///home/mansisha/v_pl/lib/python3.8/site-packages/openfl/federated/plan/plan.py\"><span style=\"color: #7f7f7f\">plan.py</span></a><span style=\"color: #7f7f7f\">:173</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7ff2cb6b8eb0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">           </span><span style=\"color: #000080\">INFO</span>     Override <span style=\"color: #800000\">ðŸ¡†</span> <span style=\"font-weight: bold\">{}</span>                                                                                                                    <a href=\"file:///home/mansisha/v_pl/lib/python3.8/site-packages/openfl/federated/plan/plan.py\"><span style=\"color: #7f7f7f\">plan.py</span></a><span style=\"color: #7f7f7f\">:175</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7ff2cb6b8ee0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">[11:00:30] </span><span style=\"color: #000080\">INFO</span>     Starting experiment!                                                                                                       <a href=\"file:///home/mansisha/v_pl/lib/python3.8/site-packages/openfl/interface/interactive_api/experiment.py\"><span style=\"color: #7f7f7f\">experiment.py</span></a><span style=\"color: #7f7f7f\">:173</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7ff2b91d8100>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">           </span><span style=\"color: #000080\">INFO</span>     FL-Plan hash is <span style=\"color: #000080\">0e149d79408cd000e7bff01518d86c8f272354e83256551964c59fa1c39bf9f23afff056321042eae2a289338745c8b1</span>                 <a href=\"file:///home/mansisha/v_pl/lib/python3.8/site-packages/openfl/federated/plan/plan.py\"><span style=\"color: #7f7f7f\">plan.py</span></a><span style=\"color: #7f7f7f\">:232</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7ff2b9862e50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">           </span><span style=\"color: #000080\">INFO</span>     FL-Plan hash is <span style=\"color: #000080\">0e149d79408cd000e7bff01518d86c8f272354e83256551964c59fa1c39bf9f23afff056321042eae2a289338745c8b1</span>                 <a href=\"file:///home/mansisha/v_pl/lib/python3.8/site-packages/openfl/federated/plan/plan.py\"><span style=\"color: #7f7f7f\">plan.py</span></a><span style=\"color: #7f7f7f\">:232</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7ff2b9862e50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">           </span><span style=\"color: #000080\">INFO</span>     Building <span style=\"color: #800000\">ðŸ¡†</span> Object <span style=\"color: #800000\">CoreTaskRunner</span> from <span style=\"color: #800000\">openfl.federated.task.task_runner</span> Module.                                                  <a href=\"file:///home/mansisha/v_pl/lib/python3.8/site-packages/openfl/federated/plan/plan.py\"><span style=\"color: #7f7f7f\">plan.py</span></a><span style=\"color: #7f7f7f\">:170</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7ff2b9862e50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">           </span><span style=\"color: #000080\">INFO</span>     Settings <span style=\"color: #800000\">ðŸ¡†</span> <span style=\"font-weight: bold\">{}</span>                                                                                                                    <a href=\"file:///home/mansisha/v_pl/lib/python3.8/site-packages/openfl/federated/plan/plan.py\"><span style=\"color: #7f7f7f\">plan.py</span></a><span style=\"color: #7f7f7f\">:173</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7ff2b9862e50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">           </span><span style=\"color: #000080\">INFO</span>     Override <span style=\"color: #800000\">ðŸ¡†</span> <span style=\"font-weight: bold\">{</span><span style=\"color: #008000\">'required_plugin_components'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000\">'framework_adapters'</span>:                                                                 <a href=\"file:///home/mansisha/v_pl/lib/python3.8/site-packages/openfl/federated/plan/plan.py\"><span style=\"color: #7f7f7f\">plan.py</span></a><span style=\"color: #7f7f7f\">:175</span>\n",
       "                    <span style=\"color: #008000\">'openfl.plugins.frameworks_adapters.pytorch_adapter_with_multiple_opt.FrameworkAdapterPlugin'</span><span style=\"font-weight: bold\">}}</span>                                             \n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7ff2b9862e50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">           </span><span style=\"color: #000080\">INFO</span>     Building <span style=\"color: #800000\">ðŸ¡†</span> Object <span style=\"color: #800000\">FrameworkAdapterPlugin</span> from <span style=\"color: #800000\">openfl.plugins.frameworks_adapters.pytorch_adapter_with_multiple_opt</span> Module.       <a href=\"file:///home/mansisha/v_pl/lib/python3.8/site-packages/openfl/federated/plan/plan.py\"><span style=\"color: #7f7f7f\">plan.py</span></a><span style=\"color: #7f7f7f\">:170</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7ff2b91d8580>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">           </span><span style=\"color: #000080\">INFO</span>     Settings <span style=\"color: #800000\">ðŸ¡†</span> <span style=\"font-weight: bold\">{}</span>                                                                                                                    <a href=\"file:///home/mansisha/v_pl/lib/python3.8/site-packages/openfl/federated/plan/plan.py\"><span style=\"color: #7f7f7f\">plan.py</span></a><span style=\"color: #7f7f7f\">:173</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7ff2b91d84c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">           </span><span style=\"color: #000080\">INFO</span>     Override <span style=\"color: #800000\">ðŸ¡†</span> <span style=\"font-weight: bold\">{}</span>                                                                                                                    <a href=\"file:///home/mansisha/v_pl/lib/python3.8/site-packages/openfl/federated/plan/plan.py\"><span style=\"color: #7f7f7f\">plan.py</span></a><span style=\"color: #7f7f7f\">:175</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7ff2b91d8970>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State is:  odict_keys(['generator.model.0.weight', 'generator.model.0.bias', 'generator.model.2.weight', 'generator.model.2.bias', 'generator.model.3.weight', 'generator.model.3.bias', 'generator.model.3.running_mean', 'generator.model.3.running_var', 'generator.model.3.num_batches_tracked', 'generator.model.5.weight', 'generator.model.5.bias', 'generator.model.6.weight', 'generator.model.6.bias', 'generator.model.6.running_mean', 'generator.model.6.running_var', 'generator.model.6.num_batches_tracked', 'generator.model.8.weight', 'generator.model.8.bias', 'generator.model.9.weight', 'generator.model.9.bias', 'generator.model.9.running_mean', 'generator.model.9.running_var', 'generator.model.9.num_batches_tracked', 'generator.model.11.weight', 'generator.model.11.bias', 'discriminator.model.0.weight', 'discriminator.model.0.bias', 'discriminator.model.2.weight', 'discriminator.model.2.bias', 'discriminator.model.4.weight', 'discriminator.model.4.bias'])\n",
      "optimizer is: None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">           </span><span style=\"color: #800000\">WARNING</span>  tried to remove tensor: __opt_state_needed not present in the tensor dict                                                       <a href=\"file:///home/mansisha/v_pl/lib/python3.8/site-packages/openfl/utilities/utils.py\"><span style=\"color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f\">:165</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7ff2b91d8460>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State is:  odict_keys(['generator.model.0.weight', 'generator.model.0.bias', 'generator.model.2.weight', 'generator.model.2.bias', 'generator.model.3.weight', 'generator.model.3.bias', 'generator.model.3.running_mean', 'generator.model.3.running_var', 'generator.model.3.num_batches_tracked', 'generator.model.5.weight', 'generator.model.5.bias', 'generator.model.6.weight', 'generator.model.6.bias', 'generator.model.6.running_mean', 'generator.model.6.running_var', 'generator.model.6.num_batches_tracked', 'generator.model.8.weight', 'generator.model.8.bias', 'generator.model.9.weight', 'generator.model.9.bias', 'generator.model.9.running_mean', 'generator.model.9.running_var', 'generator.model.9.num_batches_tracked', 'generator.model.11.weight', 'generator.model.11.bias', 'discriminator.model.0.weight', 'discriminator.model.0.bias', 'discriminator.model.2.weight', 'discriminator.model.2.bias', 'discriminator.model.4.weight', 'discriminator.model.4.bias'])\n",
      "optimizer is: None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">           </span><span style=\"color: #800000\">WARNING</span>  tried to remove tensor: __opt_state_needed not present in the tensor dict                                                       <a href=\"file:///home/mansisha/v_pl/lib/python3.8/site-packages/openfl/utilities/utils.py\"><span style=\"color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f\">:165</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7ff2b91d8250>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">           </span><span style=\"color: #000080\">INFO</span>     SetNewExperiment                                                                                                      <a href=\"file:///home/mansisha/v_pl/lib/python3.8/site-packages/openfl/transport/grpc/director_client.py\"><span style=\"color: #7f7f7f\">director_client.py</span></a><span style=\"color: #7f7f7f\">:185</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7ff2b91d82e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">           </span><span style=\"color: #000080\">INFO</span>     Experiment was accepted and launched.                                                                                      <a href=\"file:///home/mansisha/v_pl/lib/python3.8/site-packages/openfl/interface/interactive_api/experiment.py\"><span style=\"color: #7f7f7f\">experiment.py</span></a><span style=\"color: #7f7f7f\">:187</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7ff2b91d8f70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# If I use autoreload I got a pickling error\n",
    "\n",
    "# The following command zips the workspace and python requirements to be transfered to collaborator nodes\n",
    "fl_experiment.start(model_provider=MI, \n",
    "                    task_keeper=TI,\n",
    "                    data_loader=fed_dataset,\n",
    "                    rounds_to_train=5,\n",
    "                    opt_treatment='CONTINUE_GLOBAL',\n",
    "                    device_assignment_policy='CUDA_PREFERRED')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f1543a36",
   "metadata": {},
   "outputs": [
    {
     "ename": "_MultiThreadedRendezvous",
     "evalue": "<_MultiThreadedRendezvous of RPC that terminated with:\n\tstatus = StatusCode.UNAVAILABLE\n\tdetails = \"Socket closed\"\n\tdebug_error_string = \"{\"created\":\"@1640764897.519425582\",\"description\":\"Error received from peer ipv4:127.0.0.1:50050\",\"file\":\"src/core/lib/surface/call.cc\",\"file_line\":1062,\"grpc_message\":\"Socket closed\",\"grpc_status\":14}\"\n>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_MultiThreadedRendezvous\u001b[0m                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_16629/154754993.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# fl_experiment.restore_experiment_state(MI)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mfl_experiment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/mansisha/v_pl/lib/python3.8/site-packages/openfl/interface/interactive_api/experiment.py\u001b[0m in \u001b[0;36mstream_metrics\u001b[0;34m(self, tensorboard_logs)\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0;34m\"\"\"Stream metrics.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assert_experiment_accepted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mmetric_message_dict\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfederation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdir_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperiment_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m             self.logger.metric(\n\u001b[1;32m    112\u001b[0m                 \u001b[0;34mf'Round {metric_message_dict[\"round\"]}, '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mansisha/v_pl/lib/python3.8/site-packages/openfl/transport/grpc/director_client.py\u001b[0m in \u001b[0;36mstream_metrics\u001b[0;34m(self, experiment_name)\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0;34m\"\"\"Stream metrics RPC.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m         \u001b[0mrequest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdirector_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStreamMetricsRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexperiment_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexperiment_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 246\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mmetric_message\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStreamMetrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    247\u001b[0m             yield {\n\u001b[1;32m    248\u001b[0m                 \u001b[0;34m'metric_origin'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmetric_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetric_origin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mansisha/v_pl/lib/python3.8/site-packages/grpc/_channel.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    414\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mansisha/v_pl/lib/python3.8/site-packages/grpc/_channel.py\u001b[0m in \u001b[0;36m_next\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    801\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    802\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    805\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31m_MultiThreadedRendezvous\u001b[0m: <_MultiThreadedRendezvous of RPC that terminated with:\n\tstatus = StatusCode.UNAVAILABLE\n\tdetails = \"Socket closed\"\n\tdebug_error_string = \"{\"created\":\"@1640764897.519425582\",\"description\":\"Error received from peer ipv4:127.0.0.1:50050\",\"file\":\"src/core/lib/surface/call.cc\",\"file_line\":1062,\"grpc_message\":\"Socket closed\",\"grpc_status\":14}\"\n>"
     ]
    }
   ],
   "source": [
    "# If user want to stop IPython session, then reconnect and check how experiment is going \n",
    "# fl_experiment.restore_experiment_state(MI)\n",
    "\n",
    "fl_experiment.stream_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383ed45d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

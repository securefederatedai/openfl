{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "liquid-jacket",
   "metadata": {},
   "source": [
    "# Federated PatchSVDD algorithm with Director example\n",
    "## Using low-level Python API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e6aae2",
   "metadata": {},
   "source": [
    "# PatchSVDD algorithm\n",
    "Anomaly detection involves making a binary decision as to whether an input image contains an anomaly, and anomaly segmentation aims to locate the anomaly on the pixel level. The deep learning variant of Support vector data description (SVDD: a long-standing algorithm used for anomaly detection) is used to the patch-based method using self-supervised learning. This extension enables anomaly segmentation and improves detection performances which are measured in AUROC on MVTec AD dataset.\n",
    "\n",
    "* Original paper: https://arxiv.org/abs/2006.16067\n",
    "* Original Github code: https://github.com/nuclearboy95/Anomaly-Detection-PatchSVDD-PyTorch/tree/934d6238e5e0ad511e2a0e7fc4f4899010e7d892\n",
    "* MVTec ad dataset download link: https://www.mydrive.ch/shares/38536/3830184030e49fe74747669442f0f282/download/420938113-1629952094/mvtec_anomaly_detection.tar.xz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0579f8",
   "metadata": {},
   "source": [
    "# Long-Living entities update\n",
    "\n",
    "* We now may have director running on another machine.\n",
    "* We use Federation API to communicate with Director.\n",
    "* Federation object should hold a Director's client (for user service)\n",
    "* Keeping in mind that several API instances may be connected to one Director.\n",
    "\n",
    "\n",
    "* We do not think for now how we start a Director.\n",
    "* But it knows the data shape and target shape for the DataScience problem in the Federation.\n",
    "* Director holds the list of connected envoys, we do not need to specify it anymore.\n",
    "* Director and Envoys are responsible for encrypting connections, we do not need to worry about certs.\n",
    "\n",
    "\n",
    "* Yet we MUST have a cert to communicate to the Director.\n",
    "* We MUST know the FQDN of a Director.\n",
    "* Director communicates data and target shape to the Federation interface object.\n",
    "\n",
    "\n",
    "* Experiment API may use this info to construct a dummy dataset and a `shard descriptor` stub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alike-sharing",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Install dependencies if not already installed\n",
    "!pip install torchvision==0.8.1\n",
    "!pip install matplotlib\n",
    "!pip install numpy\n",
    "!pip install scikit-image\n",
    "!pip install scikit-learn\n",
    "!pip install torch\n",
    "!pip install tqdm\n",
    "!pip install Pillow\n",
    "!pip install imageio\n",
    "!pip install opencv-python\n",
    "!pip install ngt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16986f22",
   "metadata": {},
   "source": [
    "# Connect to the Federation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4485ac79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a federation\n",
    "from openfl.interface.interactive_api.federation import Federation\n",
    "\n",
    "# please use the same identificator that was used in signed certificate\n",
    "cliend_id = 'frontend'\n",
    "\n",
    "# 1) Run with API layer - Director mTLS \n",
    "# If the user wants to enable mTLS their must provide CA root chain, and signed key pair to the federation interface\n",
    "# cert_chain = 'cert/root_ca.crt'\n",
    "# API_certificate = 'cert/frontend.crt'\n",
    "# API_private_key = 'cert/frontend.key'\n",
    "\n",
    "# federation = Federation(client_id='frontend', director_node_fqdn='localhost', director_port='50051',\n",
    "#                        cert_chain=cert_chain, api_cert=API_certificate, api_private_key=API_private_key)\n",
    "\n",
    "# --------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# 2) Run with TLS disabled (trusted environment)\n",
    "# Federation can also determine local fqdn automatically\n",
    "federation = Federation(client_id='frontend', director_node_fqdn='localhost', director_port='50050', tls=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35802d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "shard_registry = federation.get_shard_registry()\n",
    "shard_registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ae50de",
   "metadata": {},
   "outputs": [],
   "source": [
    "federation.target_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920216d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# First, request a dummy_shard_desc that holds information about the federated dataset \n",
    "dummy_shard_desc = federation.get_dummy_shard_descriptor(size=10)\n",
    "sample, target = dummy_shard_desc[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "obvious-tyler",
   "metadata": {},
   "source": [
    "## Creating a FL experiment using Interactive API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rubber-address",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openfl.interface.interactive_api.experiment import TaskInterface, DataInterface, ModelInterface, FLExperiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sustainable-public",
   "metadata": {},
   "source": [
    "### Register dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unlike-texas",
   "metadata": {},
   "source": [
    "We extract User dataset class implementation.\n",
    "Is it convinient?\n",
    "What if the dataset is not a class?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2407cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#List of objects in MVTec dataset\n",
    "\n",
    "objs = ['bottle', 'cable', 'capsule', 'carpet', 'grid', 'hazelnut',\n",
    "        'leather', 'metal_nut', 'pill', 'screw', 'tile', 'toothbrush',\n",
    "        'transistor', 'wood', 'zipper']\n",
    "#Arguments\n",
    "args = {\n",
    "'obj' : 'bottle',\n",
    "'lambda_value': '1e-3',\n",
    "'D' : 64,\n",
    "'lr' : '1e-4',\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8669bc63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import torch\n",
    "from functools import reduce\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from imageio import imread\n",
    "from glob import glob\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import os, shutil\n",
    "import _pickle as p\n",
    "from contextlib import contextmanager\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f37dcf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import PIL\n",
    "from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler\n",
    "from torchvision import transforms as tsf\n",
    "from utils import *\n",
    "from data_transf import *\n",
    "from inspection import *\n",
    "from functools import reduce\n",
    "\n",
    "\n",
    "def generate_coords(H, W, K):\n",
    "    h = np.random.randint(0, H - K + 1)\n",
    "    w = np.random.randint(0, W - K + 1)\n",
    "    return h, w\n",
    "\n",
    "\n",
    "def generate_coords_position(H, W, K):\n",
    "    with task('P1'):\n",
    "        p1 = generate_coords(H, W, K)\n",
    "        h1, w1 = p1\n",
    "\n",
    "    pos = np.random.randint(8)\n",
    "\n",
    "    with task('P2'):\n",
    "        J = K // 4\n",
    "\n",
    "        K3_4 = 3 * K // 4\n",
    "        h_dir, w_dir = pos_to_diff[pos]\n",
    "        h_del, w_del = np.random.randint(J, size=2)\n",
    "\n",
    "        h_diff = h_dir * (h_del + K3_4)\n",
    "        w_diff = w_dir * (w_del + K3_4)\n",
    "\n",
    "        h2 = h1 + h_diff\n",
    "        w2 = w1 + w_diff\n",
    "\n",
    "        h2 = np.clip(h2, 0, H - K)\n",
    "        w2 = np.clip(w2, 0, W - K)\n",
    "\n",
    "        p2 = (h2, w2)\n",
    "\n",
    "    return p1, p2, pos\n",
    "\n",
    "\n",
    "def generate_coords_svdd(H, W, K):\n",
    "    with task('P1'):\n",
    "        p1 = generate_coords(H, W, K)\n",
    "        h1, w1 = p1\n",
    "\n",
    "    with task('P2'):\n",
    "        J = K // 32\n",
    "\n",
    "        h_jit, w_jit = 0, 0\n",
    "\n",
    "        while h_jit == 0 and w_jit == 0:\n",
    "            h_jit = np.random.randint(-J, J + 1)\n",
    "            w_jit = np.random.randint(-J, J + 1)\n",
    "\n",
    "        h2 = h1 + h_jit\n",
    "        w2 = w1 + w_jit\n",
    "\n",
    "        h2 = np.clip(h2, 0, H - K)\n",
    "        w2 = np.clip(w2, 0, W - K)\n",
    "\n",
    "        p2 = (h2, w2)\n",
    "\n",
    "    return p1, p2\n",
    "\n",
    "\n",
    "pos_to_diff = {\n",
    "    0: (-1, -1),\n",
    "    1: (-1, 0),\n",
    "    2: (-1, 1),\n",
    "    3: (0, -1),\n",
    "    4: (0, 1),\n",
    "    5: (1, -1),\n",
    "    6: (1, 0),\n",
    "    7: (1, 1)\n",
    "}\n",
    "##################################################################\n",
    "\n",
    "class SVDD_Dataset(Dataset):\n",
    "    def __init__(self, memmap, K=64, repeat=1):\n",
    "        super().__init__()\n",
    "        self.arr = np.asarray(memmap)\n",
    "        self.K = K\n",
    "        self.repeat = repeat\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        N = self.arr.shape[0]\n",
    "        return N * self.repeat\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        N = self.arr.shape[0]\n",
    "        K = self.K\n",
    "        n = idx % N\n",
    "\n",
    "        p1, p2 = generate_coords_svdd(256, 256, K)\n",
    "\n",
    "        image = self.arr[n]\n",
    "\n",
    "        patch1 = crop_image_chw(image, p1, K)\n",
    "        patch2 = crop_image_chw(image, p2, K)\n",
    "\n",
    "        return patch1, patch2\n",
    "\n",
    "    @staticmethod\n",
    "    def infer(enc, batch):\n",
    "        x1s, x2s, = batch\n",
    "        h1s = enc(x1s)\n",
    "        h2s = enc(x2s)\n",
    "        diff = h1s - h2s\n",
    "        l2 = diff.norm(dim=1)\n",
    "        loss = l2.mean()\n",
    "\n",
    "        return loss\n",
    "    \n",
    "\n",
    "######################################################################################\n",
    "\n",
    "class PositionDataset(Dataset):\n",
    "    def __init__(self, x, K=64, repeat=1):\n",
    "        super(PositionDataset, self).__init__()\n",
    "        self.x = np.asarray(x)\n",
    "        self.K = K\n",
    "        self.repeat = repeat\n",
    "\n",
    "    def __len__(self):\n",
    "        N = self.x.shape[0]\n",
    "        return N * self.repeat\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        N = self.x.shape[0]\n",
    "        K = self.K\n",
    "        n = idx % N\n",
    "\n",
    "        image = self.x[n]\n",
    "        p1, p2, pos = generate_coords_position(256, 256, K)\n",
    "\n",
    "        patch1 = crop_image_chw(image, p1, K).copy()\n",
    "        patch2 = crop_image_chw(image, p2, K).copy()\n",
    "\n",
    "        # perturb RGB\n",
    "        rgbshift1 = np.random.normal(scale=0.02, size=(3, 1, 1))\n",
    "        rgbshift2 = np.random.normal(scale=0.02, size=(3, 1, 1))\n",
    "\n",
    "        patch1 += rgbshift1\n",
    "        patch2 += rgbshift2\n",
    "\n",
    "        # additive noise\n",
    "        noise1 = np.random.normal(scale=0.02, size=(3, K, K))\n",
    "        noise2 = np.random.normal(scale=0.02, size=(3, K, K))\n",
    "\n",
    "        patch1 += noise1\n",
    "        patch2 += noise2\n",
    "\n",
    "        return patch1, patch2, pos\n",
    "\n",
    "############################################################################################\n",
    "\n",
    "class PatchDataset_NCHW(Dataset):\n",
    "    def __init__(self, memmap, tfs=None, K=32, S=1):\n",
    "        super().__init__()\n",
    "        self.arr = memmap\n",
    "        self.tfs = tfs\n",
    "        self.S = S\n",
    "        self.K = K\n",
    "        self.N = self.arr.shape[0]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.N * self.row_num * self.col_num\n",
    "\n",
    "    @property\n",
    "    def row_num(self):\n",
    "        N, C, H, W = self.arr.shape\n",
    "        K = self.K\n",
    "        S = self.S\n",
    "        I = cnn_output_size(H, k=K, s=S)\n",
    "        return I\n",
    "\n",
    "    @property\n",
    "    def col_num(self):\n",
    "        N, C, H, W = self.arr.shape\n",
    "        K = self.K\n",
    "        S = self.S\n",
    "        J = cnn_output_size(W, k=K, s=S)\n",
    "        return J\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        N = self.N\n",
    "        n, i, j = np.unravel_index(idx, (N, self.row_num, self.col_num))\n",
    "        K = self.K\n",
    "        S = self.S\n",
    "        image = self.arr[n]\n",
    "        patch = crop_chw(image, i, j, K, S)\n",
    "\n",
    "        if self.tfs:\n",
    "            patch = self.tfs(patch)\n",
    "\n",
    "        return patch, n, i, j\n",
    "\n",
    "\n",
    "############################################################################################\n",
    "\n",
    "# Now you can implement you data loaders using dummy_shard_desc\n",
    "class MVTecSD(DataInterface):\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "    \n",
    "    @property\n",
    "    def shard_descriptor(self):\n",
    "        return self._shard_descriptor\n",
    "        \n",
    "    @shard_descriptor.setter\n",
    "    def shard_descriptor(self, shard_descriptor):\n",
    "        \"\"\"\n",
    "        Describe per-collaborator procedures or sharding.\n",
    "\n",
    "        This method will be called during a collaborator initialization.\n",
    "        Local shard_descriptor  will be set by Envoy.\n",
    "        \"\"\"\n",
    "        self._shard_descriptor = shard_descriptor\n",
    "        \n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img, mask, label = self.shard_descriptor[index]\n",
    "        return img, mask, label\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.shard_descriptor)\n",
    "    \n",
    "    \n",
    "    def get_train_loader(self, **kwargs):\n",
    "        \"\"\"\n",
    "        Output of this method will be provided to tasks with optimizer in contract\n",
    "        \"\"\"\n",
    "        self.shard_descriptor.set_mode('train')\n",
    "        train_x = np.stack([image for image, mask, label in self]).astype(np.float32)\n",
    "        mean = train_x.astype(np.float32).mean(axis=0)\n",
    "        train_x = (train_x.astype(np.float32) - mean) / 255\n",
    "        train_x = np.transpose(train_x, [0, 3, 1, 2])\n",
    "    \n",
    "        if self.kwargs['train_bs']:\n",
    "            batch_size = self.kwargs['train_bs']\n",
    "        else:\n",
    "            batch_size = 64\n",
    "            \n",
    "        loader = DataLoader(self.get_train_dataset_dict(train_x), batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
    "        return loader\n",
    "\n",
    "    def get_valid_loader(self, **kwargs):\n",
    "        \"\"\"\n",
    "        Output of this method will be provided to tasks without optimizer in contract\n",
    "        \"\"\"\n",
    "        # We need both train and test data for obtaining embeddings\n",
    "        self.shard_descriptor.set_mode('train')\n",
    "        train_x = np.stack([image for image, mask, label in self]).astype(np.float32)\n",
    "        mean = train_x.astype(np.float32).mean(axis=0)\n",
    "        train_x = (train_x.astype(np.float32) - mean) / 255\n",
    "        train_x = np.transpose(train_x, [0, 3, 1, 2])\n",
    "        \n",
    "        #getting val loader\n",
    "        self.shard_descriptor.set_mode('test')\n",
    "        test_x = np.stack([image for image, mask, label in self]).astype(np.float32)\n",
    "        mean = test_x.astype(np.float32).mean(axis=0)\n",
    "        test_x = (test_x.astype(np.float32) - mean) / 255\n",
    "        test_x = np.transpose(test_x, [0, 3, 1, 2])\n",
    "        \n",
    "        masks = np.stack([mask for image, mask, label in self]).astype(np.int32)\n",
    "        masks[masks <= 128] = 0\n",
    "        masks[masks > 128] = 255\n",
    "        labels = np.stack([label for image, mask, label in self]).astype(np.int32)\n",
    "\n",
    "        return (train_x, test_x, masks, labels)\n",
    "\n",
    "\n",
    "    def get_train_data_size(self):\n",
    "        \"\"\"\n",
    "        Information for aggregation\n",
    "        \"\"\"\n",
    "        self.shard_descriptor.set_mode('train')\n",
    "        return len(self.shard_descriptor)\n",
    "        \n",
    "\n",
    "    def get_valid_data_size(self):\n",
    "        \"\"\"\n",
    "        Information for aggregation\n",
    "        \"\"\"\n",
    "        self.shard_descriptor.set_mode('test')\n",
    "        return len(self.shard_descriptor)\n",
    "    \n",
    "    def get_train_dataset_dict(self,inp_x):\n",
    "        rep = 100\n",
    "        datasets = dict()\n",
    "        datasets[f'pos_64'] = PositionDataset(inp_x, K=64, repeat=rep)\n",
    "        datasets[f'pos_32'] = PositionDataset(inp_x, K=32, repeat=rep)\n",
    "\n",
    "        datasets[f'svdd_64'] = SVDD_Dataset(inp_x, K=64, repeat=rep)\n",
    "        datasets[f'svdd_32'] = SVDD_Dataset(inp_x, K=32, repeat=rep)\n",
    "        dataset = DictionaryConcatDataset(datasets)\n",
    "        return dataset\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8df35f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fed_dataset = MVTecSD(train_bs=64, val_bs=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f786b8b",
   "metadata": {},
   "source": [
    "### Describe a model and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visible-victor",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "from utils import makedirpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "foreign-gospel",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Model definition\n",
    "\"\"\"\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, K, D=64, bias=True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 64, 5, 2, 0, bias=bias)\n",
    "        self.conv2 = nn.Conv2d(64, 64, 5, 2, 0, bias=bias)\n",
    "        self.conv3 = nn.Conv2d(64, 128, 5, 2, 0, bias=bias)\n",
    "        self.conv4 = nn.Conv2d(128, D, 5, 1, 0, bias=bias)\n",
    "\n",
    "        self.K = K\n",
    "        self.D = D\n",
    "        self.bias = bias\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.conv1(x)\n",
    "        h = F.leaky_relu(h, 0.1)\n",
    "\n",
    "        h = self.conv2(h)\n",
    "        h = F.leaky_relu(h, 0.1)\n",
    "\n",
    "        h = self.conv3(h)\n",
    "\n",
    "        if self.K == 64:\n",
    "            h = F.leaky_relu(h, 0.1)\n",
    "            h = self.conv4(h)\n",
    "\n",
    "        h = torch.tanh(h)\n",
    "\n",
    "        return h\n",
    "\n",
    "    def save(self, name):\n",
    "        fpath = self.fpath_from_name(name)\n",
    "        makedirpath(fpath)\n",
    "        torch.save(self.state_dict(), fpath)\n",
    "\n",
    "    def load(self, name):\n",
    "        fpath = self.fpath_from_name(name)\n",
    "        self.load_state_dict(torch.load(fpath))\n",
    "\n",
    "    @staticmethod\n",
    "    def fpath_from_name(name):\n",
    "        return f'ckpts/{name}/encoder_nohier.pkl'\n",
    "\n",
    "\n",
    "def forward_hier(x, emb_small, K):\n",
    "    K_2 = K // 2\n",
    "    n = x.size(0)\n",
    "    x1 = x[..., :K_2, :K_2]\n",
    "    x2 = x[..., :K_2, K_2:]\n",
    "    x3 = x[..., K_2:, :K_2]\n",
    "    x4 = x[..., K_2:, K_2:]\n",
    "    xx = torch.cat([x1, x2, x3, x4], dim=0)\n",
    "    hh = emb_small(xx)\n",
    "\n",
    "    h1 = hh[:n]\n",
    "    h2 = hh[n: 2 * n]\n",
    "    h3 = hh[2 * n: 3 * n]\n",
    "    h4 = hh[3 * n:]\n",
    "\n",
    "    h12 = torch.cat([h1, h2], dim=3)\n",
    "    h34 = torch.cat([h3, h4], dim=3)\n",
    "    h = torch.cat([h12, h34], dim=2)\n",
    "    return h\n",
    "\n",
    "\n",
    "class EncoderDeep(nn.Module):\n",
    "    def __init__(self, K, D=64, bias=True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, 2, 0, bias=bias)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1, 0, bias=bias)\n",
    "        self.conv3 = nn.Conv2d(64, 128, 3, 1, 0, bias=bias)\n",
    "        self.conv4 = nn.Conv2d(128, 128, 3, 1, 0, bias=bias)\n",
    "        self.conv5 = nn.Conv2d(128, 64, 3, 1, 0, bias=bias)\n",
    "        self.conv6 = nn.Conv2d(64, 32, 3, 1, 0, bias=bias)\n",
    "        self.conv7 = nn.Conv2d(32, 32, 3, 1, 0, bias=bias)\n",
    "        self.conv8 = nn.Conv2d(32, D, 3, 1, 0, bias=bias)\n",
    "\n",
    "        self.K = K\n",
    "        self.D = D\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.conv1(x)\n",
    "        h = F.leaky_relu(h, 0.1)\n",
    "\n",
    "        h = self.conv2(h)\n",
    "        h = F.leaky_relu(h, 0.1)\n",
    "\n",
    "        h = self.conv3(h)\n",
    "        h = F.leaky_relu(h, 0.1)\n",
    "\n",
    "        h = self.conv4(h)\n",
    "        h = F.leaky_relu(h, 0.1)\n",
    "\n",
    "        h = self.conv5(h)\n",
    "        h = F.leaky_relu(h, 0.1)\n",
    "\n",
    "        h = self.conv6(h)\n",
    "        h = F.leaky_relu(h, 0.1)\n",
    "\n",
    "        h = self.conv7(h)\n",
    "        h = F.leaky_relu(h, 0.1)\n",
    "\n",
    "        h = self.conv8(h)\n",
    "        h = torch.tanh(h)\n",
    "\n",
    "        return h\n",
    "\n",
    "    def save(self, name):\n",
    "        fpath = self.fpath_from_name(name)\n",
    "        makedirpath(fpath)\n",
    "        torch.save(self.state_dict(), fpath)\n",
    "\n",
    "    def load(self, name):\n",
    "        fpath = self.fpath_from_name(name)\n",
    "        self.load_state_dict(torch.load(fpath))\n",
    "\n",
    "    @staticmethod\n",
    "    def fpath_from_name(name):\n",
    "        return f'ckpts/{name}/encdeep.pkl'\n",
    "\n",
    "\n",
    "class EncoderHier(nn.Module):\n",
    "    def __init__(self, K, D=64, bias=True):\n",
    "        super().__init__()\n",
    "\n",
    "        if K > 64:\n",
    "            self.enc = EncoderHier(K // 2, D, bias=bias)\n",
    "\n",
    "        elif K == 64:\n",
    "            self.enc = EncoderDeep(K // 2, D, bias=bias)\n",
    "\n",
    "        else:\n",
    "            raise ValueError()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(D, 128, 2, 1, 0, bias=bias)\n",
    "        self.conv2 = nn.Conv2d(128, D, 1, 1, 0, bias=bias)\n",
    "\n",
    "        self.K = K\n",
    "        self.D = D\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = forward_hier(x, self.enc, K=self.K)\n",
    "\n",
    "        h = self.conv1(h)\n",
    "        h = F.leaky_relu(h, 0.1)\n",
    "\n",
    "        h = self.conv2(h)\n",
    "        h = torch.tanh(h)\n",
    "\n",
    "        return h\n",
    "\n",
    "    def save(self, name):\n",
    "        fpath = self.fpath_from_name(name)\n",
    "        print('fpath is: ',fpath)\n",
    "        makedirpath(fpath)\n",
    "        torch.save(self.state_dict(), fpath)\n",
    "\n",
    "    def load(self, name):\n",
    "        fpath = self.fpath_from_name(name)\n",
    "        self.load_state_dict(torch.load(fpath))\n",
    "\n",
    "    @staticmethod\n",
    "    def fpath_from_name(name):\n",
    "        return f'ckpts/{name}/enchier.pkl'\n",
    "\n",
    "\n",
    "################\n",
    "\n",
    "\n",
    "xent = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "class NormalizedLinear(nn.Module):\n",
    "    __constants__ = ['bias', 'in_features', 'out_features']\n",
    "\n",
    "    def __init__(self, in_features, out_features, bias=True):\n",
    "        super(NormalizedLinear, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.weight = nn.Parameter(torch.Tensor(out_features, in_features))\n",
    "        if bias:\n",
    "            self.bias = nn.Parameter(torch.Tensor(out_features))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n",
    "        if self.bias is not None:\n",
    "            fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.weight)\n",
    "            bound = 1 / math.sqrt(fan_in)\n",
    "            nn.init.uniform_(self.bias, -bound, bound)\n",
    "\n",
    "    def forward(self, x):\n",
    "        with torch.no_grad():\n",
    "            w = self.weight / self.weight.data.norm(keepdim=True, dim=0)\n",
    "        return F.linear(x, w, self.bias)\n",
    "\n",
    "    def extra_repr(self):\n",
    "        return 'in_features={}, out_features={}, bias={}'.format(\n",
    "            self.in_features, self.out_features, self.bias is not None\n",
    "        )\n",
    "\n",
    "\n",
    "class PositionClassifier(nn.Module):\n",
    "    def __init__(self, K, D, class_num=8):\n",
    "        super().__init__()\n",
    "        self.D = D\n",
    "\n",
    "        self.fc1 = nn.Linear(D, 128)\n",
    "        self.act1 = nn.LeakyReLU(0.1)\n",
    "\n",
    "        self.fc2 = nn.Linear(128, 128)\n",
    "        self.act2 = nn.LeakyReLU(0.1)\n",
    "\n",
    "        self.fc3 = NormalizedLinear(128, class_num)\n",
    "\n",
    "        self.K = K\n",
    "\n",
    "    def save(self, name):\n",
    "        fpath = self.fpath_from_name(name)\n",
    "        makedirpath(fpath)\n",
    "        torch.save(self.state_dict(), fpath)\n",
    "\n",
    "    def load(self, name):\n",
    "        fpath = self.fpath_from_name(name)\n",
    "        self.load_state_dict(torch.load(fpath))\n",
    "\n",
    "    def fpath_from_name(self, name):\n",
    "        return f'ckpts/{name}/position_classifier_K{self.K}.pkl'\n",
    "\n",
    "    @staticmethod\n",
    "    def infer(c, enc, batch):\n",
    "        x1s, x2s, ys = batch\n",
    "\n",
    "        h1 = enc(x1s)\n",
    "        h2 = enc(x2s)\n",
    "\n",
    "        logits = c(h1, h2)\n",
    "        loss = xent(logits, ys)\n",
    "        return loss\n",
    "\n",
    "    def forward(self, h1, h2):\n",
    "        h1 = h1.view(-1, self.D)\n",
    "        h2 = h2.view(-1, self.D)\n",
    "\n",
    "        h = h1 - h2\n",
    "\n",
    "        h = self.fc1(h)\n",
    "        h = self.act1(h)\n",
    "\n",
    "        h = self.fc2(h)\n",
    "        h = self.act2(h)\n",
    "\n",
    "        h = self.fc3(h)\n",
    "        return h\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db853fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyEnsembledModel(nn.Module):\n",
    "    def __init__(self, modelA, modelB, modelC):\n",
    "        super().__init__()\n",
    "        self.modelA = modelA\n",
    "        self.modelB = modelB\n",
    "        self.modelC = modelC\n",
    "        \n",
    "    def forward(self, x1, x2,x3):\n",
    "        x1 = self.modelA(x1)\n",
    "        x2 = self.modelB(x2)\n",
    "        x3 = self.modelC(x3)\n",
    "        x = torch.cat((x1, x2,x3), dim=1)\n",
    "        return x\n",
    "\n",
    "D = args['D']\n",
    "lr = float(args['lr'])\n",
    "enc = EncoderHier(64, D).cuda()\n",
    "cls_64 = PositionClassifier(64, D).cuda()\n",
    "cls_32 = PositionClassifier(32, D).cuda()\n",
    "\n",
    "\n",
    "model = MyEnsembledModel(enc, cls_64, cls_32)\n",
    "modules = [enc, cls_64, cls_32]\n",
    "params = [list(module.parameters()) for module in modules]\n",
    "params = reduce(lambda x, y: x + y, params)\n",
    "optimizer_adam = torch.optim.Adam(params=params, lr=lr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caroline-passion",
   "metadata": {},
   "source": [
    "#### Register model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handled-teens",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "framework_adapter = 'openfl.plugins.frameworks_adapters.pytorch_adapter.FrameworkAdapterPlugin'\n",
    "MI = ModelInterface(model=model, optimizer=optimizer_adam, framework_plugin=framework_adapter)\n",
    "\n",
    "# Save the initial model state\n",
    "initial_model = deepcopy(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "portuguese-groove",
   "metadata": {},
   "source": [
    "### Define and register FL tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "increasing-builder",
   "metadata": {},
   "outputs": [],
   "source": [
    "TI = TaskInterface()\n",
    "import torch\n",
    "import tqdm\n",
    "from utils import cnn_output_size\n",
    "\n",
    "# The Interactive API supports registering functions definied in main module or imported.\n",
    "def function_defined_in_notebook(some_parameter):\n",
    "    print(f'Also I accept a parameter and it is {some_parameter}')\n",
    "\n",
    "# Task interface currently supports only standalone functions.\n",
    "@TI.add_kwargs(**{'some_parameter': 42})\n",
    "@TI.register_fl_task(model='model', data_loader='train_loader', \\\n",
    "                     device='device', optimizer='optimizer')     \n",
    "\n",
    "def train(model, train_loader, optimizer, device, some_parameter=None):\n",
    "    if not torch.cuda.is_available():\n",
    "        device = 'cpu'\n",
    "    else:\n",
    "        device = 'cuda'\n",
    "    \n",
    "    function_defined_in_notebook(some_parameter)\n",
    "    \n",
    "    train_loader = tqdm.tqdm(train_loader, desc=\"train\")\n",
    "    model.modelA = enc\n",
    "    model.modelB = cls_64\n",
    "    model.modelC = cls_32\n",
    "    model_list = [enc, cls_64, cls_32]\n",
    "    losses = []\n",
    "    \n",
    "    for module in model_list:\n",
    "        module.train()\n",
    "\n",
    "    for d in train_loader:\n",
    "        d = to_device(d, 'cuda', non_blocking=True)\n",
    "        optimizer.zero_grad()\n",
    "        loss_pos_64 = PositionClassifier.infer(cls_64, enc, d['pos_64'])\n",
    "        loss_pos_32 = PositionClassifier.infer(cls_32, enc.enc, d['pos_32'])\n",
    "        loss_svdd_64 = SVDD_Dataset.infer(enc, d['svdd_64'])\n",
    "        loss_svdd_32 = SVDD_Dataset.infer(enc.enc, d['svdd_32'])\n",
    "\n",
    "        loss = loss_pos_64 + loss_pos_32 + float(args['lambda_value']) * (loss_svdd_64 + loss_svdd_32)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.detach().cpu().clone().numpy())\n",
    "    return {'train_loss': np.mean(losses),}\n",
    "    \n",
    "\n",
    "@TI.register_fl_task(model='model', data_loader='val_loader', device='device')     \n",
    "def validate(model, val_loader, device):\n",
    "    if not torch.cuda.is_available():\n",
    "        device = 'cpu'\n",
    "    else:\n",
    "        device = 'cuda'\n",
    "    \n",
    "    model.modelA = enc\n",
    "    enc.eval()\n",
    "    enc.to(device)\n",
    "    \n",
    "    x_tr, x_te, masks, labels = val_loader\n",
    "\n",
    "    embs64_tr = infer_(x_tr, enc, K=64, S=16)\n",
    "    embs64_te = infer_(x_te, enc, K=64, S=16)\n",
    "    embs32_tr = infer_(x_tr, enc.enc, K=32, S=4)\n",
    "    embs32_te = infer_(x_te, enc.enc, K=32, S=4)\n",
    "\n",
    "    embs64 = embs64_tr, embs64_te\n",
    "    embs32 = embs32_tr, embs32_te\n",
    "\n",
    "    results = eval_embeddings_nn_multik(args['obj'], embs64, embs32, masks, labels)\n",
    "\n",
    "    det_64 = results['det_64']\n",
    "    seg_64 = results['seg_64']\n",
    "    bal_acc_64 = results['bal_acc_64']\n",
    "    \n",
    "    det_32 = results['det_32']\n",
    "    seg_32 = results['seg_32']\n",
    "    bal_acc_32 = results['bal_acc_32']\n",
    "    \n",
    "    det_sum = results['det_sum']\n",
    "    seg_sum = results['seg_sum']\n",
    "\n",
    "    det_mult = results['det_mult']\n",
    "    seg_mult = results['seg_mult']\n",
    "    \n",
    "    maps = results['maps_mult']\n",
    "    obj = args['obj']\n",
    "    save_maps(obj, maps, x_te, masks)\n",
    "    print(\n",
    "        f'| K64 | Det: {det_64:.3f} Seg:{seg_64:.3f} BA: {bal_acc_64:.3f} | K32 | Det: {det_32:.3f} Seg:{seg_32:.3f} BA: {bal_acc_32:.3f} | sum | Det: {det_sum:.3f} Seg:{seg_sum:.3f} | mult | Det: {det_mult:.3f} Seg:{seg_mult:.3f} ({obj})')\n",
    "\n",
    "    return {'detection_score': det_sum, 'segmentation_score': seg_sum, 'balanced_accuracy_score': bal_acc_64}\n",
    "\n",
    "\n",
    "def infer_(x, enc, K, S):\n",
    "    dataset = PatchDataset_NCHW(x, K=K, S=S)\n",
    "    loader = DataLoader(dataset, batch_size=64, shuffle=False, pin_memory=True)\n",
    "    embs = np.empty((dataset.N, dataset.row_num, dataset.col_num, args['D']), dtype=np.float32)  # [-1, I, J, D]\n",
    "    enc = enc.eval()\n",
    "    with torch.no_grad():\n",
    "        for xs, ns, iis, js in loader:\n",
    "            xs = xs.cuda()\n",
    "            embedding = enc(xs)\n",
    "            embedding = embedding.detach().cpu().numpy()\n",
    "\n",
    "            for embed, n, i, j in zip(embedding, ns, iis, js):\n",
    "                embs[n, i, j] = np.squeeze(embed)\n",
    "    return embs\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "derived-bride",
   "metadata": {},
   "source": [
    "## Time to start a federated learning experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mature-renewal",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an experimnet in federation\n",
    "experiment_name = 'MVTec_test_experiment'\n",
    "fl_experiment = FLExperiment(federation=federation, experiment_name=experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lightweight-causing",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# If I use autoreload I got a pickling error\n",
    "\n",
    "# The following command zips the workspace and python requirements to be transfered to collaborator nodes\n",
    "fl_experiment.start(model_provider=MI, \n",
    "                    task_keeper=TI,\n",
    "                    data_loader=fed_dataset,\n",
    "                    rounds_to_train=5,\n",
    "                    opt_treatment='CONTINUE_GLOBAL')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1543a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If user wants to stop IPython session, then reconnect and check how experiment is going \n",
    "# fl_experiment.restore_experiment_state(MI)\n",
    "\n",
    "fl_experiment.stream_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c30b301",
   "metadata": {},
   "source": [
    "## Now we validate the best model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55acff59",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#last_model = fl_experiment.get_last_model()\n",
    "#updated_enc = last_model.modelA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9479fb7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We remove experiment_data from director\n",
    "#fl_experiment.remove_experiment_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2acb7e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Validating trained model\n",
    "#validate(last_model, fed_dataset.get_valid_loader(), 'cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ba543f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from shard_descriptor import MVTecShardDescriptor\n",
    "from inspection import save_maps\n",
    "\n",
    "fed_dataset = MVTecSD(train_bs=64, val_bs=64)\n",
    "fed_dataset.shard_descriptor = MVTecShardDescriptor(obj=args[obj], mode='test')\n",
    "\n",
    "last_model = fl_experiment.get_last_model()\n",
    "validate(last_model, fed_dataset.get_valid_loader(), 'cuda')\n",
    "save_maps(obj, maps, x_te, masks)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Vanilla PyTorch training on TinyImageNet dataset"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "This notebook is intended to show that fixing random seeds leads to the same result in both federated and non-federated cases."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "!pip install -r requirements.txt"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import shutil\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "import torchvision\n",
    "import glob\n",
    "import tqdm\n",
    "from PIL import Image\n",
    "import numpy as np"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Download data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "common_data_folder = Path.cwd() / 'data'\n",
    "zip_file_path = common_data_folder / 'tiny-imagenet-200.zip'\n",
    "os.makedirs(common_data_folder, exist_ok=True)\n",
    "os.system(f'wget --no-clobber http://cs231n.stanford.edu/tiny-imagenet-200.zip'\n",
    "          f' -O {zip_file_path}')\n",
    "shutil.unpack_archive(str(zip_file_path), str(common_data_folder))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class TinyImageNetDataset(Dataset):\n",
    "    \"\"\"TinyImageNet shard dataset class.\"\"\"\n",
    "\n",
    "    NUM_IMAGES_PER_CLASS = 500\n",
    "\n",
    "    def __init__(self, data_folder: Path, data_type='train', transform=None):\n",
    "        \"\"\"Initialize TinyImageNetDataset.\"\"\"\n",
    "        self.data_type = data_type\n",
    "        self._common_data_folder = data_folder\n",
    "        self._data_folder = os.path.join(data_folder, data_type)\n",
    "        self.labels = {}  # fname - label number mapping\n",
    "        self.image_paths = sorted(\n",
    "            glob.iglob(\n",
    "                os.path.join(self._data_folder, '**', '*.JPEG'),\n",
    "                recursive=True\n",
    "            )\n",
    "        )\n",
    "        with open(os.path.join(self._common_data_folder, 'wnids.txt'), 'r') as fp:\n",
    "            self.label_texts = sorted([text.strip() for text in fp.readlines()])\n",
    "        self.label_text_to_number = {text: i for i, text in enumerate(self.label_texts)}\n",
    "        self.fill_labels()\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        \"\"\"Return the len of the shard dataset.\"\"\"\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "        \"\"\"Return an item by the index.\"\"\"\n",
    "        file_path = self.image_paths[index]\n",
    "        sample = self.read_image(file_path)\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        label = self.labels[os.path.basename(file_path)]\n",
    "        return sample, label\n",
    "\n",
    "    def read_image(self, path: Path):\n",
    "        \"\"\"Read the image.\"\"\"\n",
    "        img = Image.open(path)\n",
    "        return img\n",
    "\n",
    "    def fill_labels(self) -> None:\n",
    "        \"\"\"Fill labels.\"\"\"\n",
    "        if self.data_type == 'train':\n",
    "            for label_text, i in self.label_text_to_number.items():\n",
    "                for cnt in range(self.NUM_IMAGES_PER_CLASS):\n",
    "                    self.labels[f'{label_text}_{cnt}.JPEG'] = i\n",
    "        elif self.data_type == 'val':\n",
    "            with open(os.path.join(self._data_folder, 'val_annotations.txt'), 'r') as fp:\n",
    "                for line in fp.readlines():\n",
    "                    terms = line.split('\\t')\n",
    "                    file_name, label_text = terms[0], terms[1]\n",
    "                    self.labels[file_name] = self.label_text_to_number[label_text]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "normalize = T.Normalize(\n",
    "    mean=[0.485, 0.456, 0.406],\n",
    "    std=[0.229, 0.224, 0.225]\n",
    ")\n",
    "\n",
    "augmentation = T.RandomApply(\n",
    "    [T.RandomHorizontalFlip(),\n",
    "     T.RandomRotation(10),\n",
    "     T.RandomResizedCrop(64)], \n",
    "    p=.8\n",
    ")\n",
    "\n",
    "training_transform = T.Compose(\n",
    "    [T.Lambda(lambda x: x.convert(\"RGB\")),\n",
    "     T.ToTensor(),\n",
    "     augmentation,\n",
    "     normalize]\n",
    ")\n",
    "\n",
    "valid_transform = T.Compose(\n",
    "    [T.Lambda(lambda x: x.convert(\"RGB\")),\n",
    "     T.ToTensor(),\n",
    "     normalize]\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dense-commerce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_loader():\n",
    "    generator=torch.Generator()\n",
    "    generator.manual_seed(0)\n",
    "    train_set = TinyImageNetDataset(common_data_folder / 'tiny-imagenet-200', transform=training_transform)\n",
    "    return DataLoader(train_set, batch_size=64, shuffle=True, generator=generator)\n",
    "\n",
    "def get_valid_loader():\n",
    "    valid_set = TinyImageNetDataset(common_data_folder / 'tiny-imagenet-200', data_type='val', transform=valid_transform)\n",
    "    return DataLoader(valid_set, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Describe the model and optimizer"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        torch.manual_seed(0)\n",
    "        super(Net, self).__init__()\n",
    "        self.model = torchvision.models.mobilenet_v2(pretrained=True)\n",
    "        self.model.requires_grad_(False)\n",
    "        self.model.classifier[1] = torch.nn.Linear(in_features=1280, \\\n",
    "                        out_features=200, bias=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model.forward(x)\n",
    "        return x\n",
    "\n",
    "model = Net()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "optimizer = optim.Adam([x for x in model.parameters() if x.requires_grad], lr=1e-4)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "loss_fn = F.cross_entropy"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def train():\n",
    "    torch.manual_seed(0)\n",
    "    device='cpu'\n",
    "    \n",
    "    data_loader = tqdm.tqdm(get_train_loader(), desc=\"train\")\n",
    "    model.train()\n",
    "    model.to(device)\n",
    "\n",
    "    losses = []\n",
    "\n",
    "    for data, target in data_loader:\n",
    "        data, target = torch.tensor(data).to(device), torch.tensor(\n",
    "            target).to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = loss_fn(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.detach().cpu().numpy())\n",
    "        \n",
    "    return {'train_loss': np.mean(losses),}\n",
    "\n",
    "def validate():\n",
    "    torch.manual_seed(0)\n",
    "    device = torch.device('cpu')\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    \n",
    "    data_loader = tqdm.tqdm(get_valid_loader(), desc=\"validate\")\n",
    "    val_score = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in data_loader:\n",
    "            samples = target.shape[0]\n",
    "            total_samples += samples\n",
    "            data, target = torch.tensor(data).to(device), \\\n",
    "                torch.tensor(target).to(device, dtype=torch.int64)\n",
    "            output = model(data)\n",
    "            pred = output.argmax(dim=1,keepdim=True)\n",
    "            val_score += pred.eq(target).sum().cpu().numpy()\n",
    "            \n",
    "    return {'acc': val_score / total_samples,}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for i in range(5):\n",
    "    if i == 0:\n",
    "        name, value = next(iter(validate().items()))\n",
    "        print(f'{name}: {value:f}')\n",
    "    \n",
    "    name, value = next(iter(train().items()))\n",
    "    print(f'{name}: {value:f}')\n",
    "    \n",
    "    name, value = next(iter(validate().items()))\n",
    "    print(f'{name}: {value:f}')"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

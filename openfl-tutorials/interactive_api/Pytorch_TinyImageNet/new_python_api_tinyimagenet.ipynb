{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26fdd9ed",
   "metadata": {},
   "source": [
    "# Federated PyTorch TinyImageNet Tutorial\n",
    "## Using low-level Python API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895288d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torchvision==0.8.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246f9c98",
   "metadata": {},
   "source": [
    "### Describe the model and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d657e463",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0523f0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "MobileNetV2 model\n",
    "\"\"\"\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.model = torchvision.models.mobilenet_v2(pretrained=True)\n",
    "        self.model.requires_grad_(False)\n",
    "        self.model.classifier[1] = torch.nn.Linear(in_features=1280, \\\n",
    "                        out_features=200, bias=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model.forward(x)\n",
    "        return x\n",
    "\n",
    "model_net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9002c72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_to_update = []\n",
    "for param in model_net.parameters():\n",
    "    if param.requires_grad == True:\n",
    "        params_to_update.append(param)\n",
    "        \n",
    "optimizer_adam = optim.Adam(params_to_update, lr=1e-4)\n",
    "\n",
    "def cross_entropy(output, target):\n",
    "    \"\"\"Binary cross-entropy metric\n",
    "    \"\"\"\n",
    "    return F.cross_entropy(input=output,target=target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0080f54",
   "metadata": {},
   "source": [
    "### Prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79dfa84b",
   "metadata": {},
   "source": [
    "We ask user to keep all the test data in `data/` folder under the workspace as it will not be sent to collaborators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69618928",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('data', exist_ok=True)\n",
    "!wget --no-clobber http://cs231n.stanford.edu/tiny-imagenet-200.zip -O ./data/tiny-imagenet-200.zip\n",
    "!unzip -n ./data/tiny-imagenet-200.zip -d ./data\n",
    "DATA_PATH = './data/tiny-imagenet-200/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506282fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TinyImageNetDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Contains 200 classes for training. Each class has 500 images. \n",
    "    Parameters\n",
    "    ----------\n",
    "    data: string\n",
    "        Data directory including `train` and `val` subdirectories.\n",
    "    split: string\n",
    "        Indicating which split to return as a data set.\n",
    "        Valid option: [`train`, `val`]\n",
    "    transform: torchvision.transforms\n",
    "        A (series) of valid transformation(s).\n",
    "    collabs: int\n",
    "        How many dataset shards will be needed, minimum 1\n",
    "    shard_num: int\n",
    "        Current shard number, starting from 0\n",
    "    \"\"\"\n",
    "    def __init__(self, data='./data/tiny-imagenet-200/', is_validation=False, transform=None, target_transform=None):\n",
    "        NUM_IMAGES_PER_CLASS = 500\n",
    "        self.data = os.path.expanduser(data)\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        split = 'train'\n",
    "        if is_validation:\n",
    "            split = 'val'\n",
    "\n",
    "        self.split_dir = os.path.join(self.data, split)\n",
    "        self.image_paths = sorted(glob.iglob(os.path.join(self.split_dir, '**', '*.JPEG'), recursive=True))\n",
    "        \n",
    "        self.labels = {}  # fname - label number mapping\n",
    "\n",
    "        # build class label - number mapping\n",
    "        with open(os.path.join(self.data, 'wnids.txt'), 'r') as fp:\n",
    "            self.label_texts = sorted([text.strip() for text in fp.readlines()])\n",
    "        self.label_text_to_number = {text: i for i, text in enumerate(self.label_texts)}\n",
    "\n",
    "        if split == 'train':\n",
    "            for label_text, i in self.label_text_to_number.items():\n",
    "                for cnt in range(NUM_IMAGES_PER_CLASS):\n",
    "                    self.labels[f'{label_text}_{cnt}.JPEG'] = i\n",
    "        elif split == 'val':\n",
    "            with open(os.path.join(self.split_dir, 'val_annotations.txt'), 'r') as fp:\n",
    "                for line in fp.readlines():\n",
    "                    terms = line.split('\\t')\n",
    "                    file_name, label_text = terms[0], terms[1]\n",
    "                    self.labels[file_name] = self.label_text_to_number[label_text]\n",
    "                    \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        file_path = self.image_paths[index]\n",
    "        label = self.labels[os.path.basename(file_path)]\n",
    "        label = self.target_transform(label) if self.target_transform else label\n",
    "        return self.read_image(file_path), label\n",
    "\n",
    "    def read_image(self, path):\n",
    "        img = Image.open(path)\n",
    "        return self.transform(img) if self.transform else img\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec1f1ca",
   "metadata": {},
   "source": [
    "### Define Federated Learning tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d9ec24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net_model, train_loader, optimizer, device, loss_fn=cross_entropy):\n",
    "    \n",
    "    function_defined_in_notebook()\n",
    "    \n",
    "    net_model.train()\n",
    "    net_model.to(device)\n",
    "\n",
    "    losses = []\n",
    "\n",
    "    for data, target in train_loader:\n",
    "        data, target = torch.tensor(data).to(device), torch.tensor(\n",
    "            target).to(device, dtype=torch.float32)\n",
    "        optimizer.zero_grad()\n",
    "        output = net_model(data)\n",
    "        loss = loss_fn(output=output, target=target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.detach().cpu().numpy())\n",
    "        \n",
    "    return {'train_loss': np.mean(losses),}\n",
    "\n",
    "\n",
    "def validate(net_model, val_loader, device):\n",
    "    net_model.eval()\n",
    "    net_model.to(device)\n",
    "\n",
    "    val_score = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in val_loader:\n",
    "            samples = target.shape[0]\n",
    "            total_samples += samples\n",
    "            data, target = torch.tensor(data).to(device), \\\n",
    "                torch.tensor(target).to(device, dtype=torch.int64)\n",
    "            output = net_model(data)\n",
    "            pred = output.argmax(dim=1,keepdim=True)\n",
    "            val_score += pred.eq(target).sum().cpu().numpy()\n",
    "            \n",
    "    return {'acc': val_score / total_samples,}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a9dd23c",
   "metadata": {},
   "source": [
    "## Describing FL experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457cea67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openfl.interface.interactive_api.experiment import TaskInterface, DataInterface, ModelInterface, FLExperiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7a3e78",
   "metadata": {},
   "source": [
    "### Register model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2c5e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "framework_adapter = 'openfl.plugins.frameworks_adapters.pytorch_adapter.FrameworkAdapterPlugin'\n",
    "MI = ModelInterface(model=model_net, optimizer=optimizer_adam, framework_plugin=framework_adapter)\n",
    "\n",
    "# Save the initial model state\n",
    "initial_model = deepcopy(model_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497f3656",
   "metadata": {},
   "source": [
    "### Register dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a518318",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserDataset:\n",
    "    def __init__(self, path_to_local_data):\n",
    "        print(f'User Dataset initialized with {path_to_local_data}')\n",
    "        \n",
    "        \n",
    "class OpenflMixin:   \n",
    "    def _delayed_init(self):\n",
    "        raise NotImplementedError\n",
    "        \n",
    "        \n",
    "class FedDataset(OpenflMixin):\n",
    "    def __init__(self, UserDataset):\n",
    "        self.user_dataset_class = UserDataset\n",
    "        print('We implement all abstract methods from mixin in this class')\n",
    "        \n",
    "    def _delayed_init(self, data_path):\n",
    "        print('This method is called on the collaborator node')\n",
    "        dataset_obj = self.user_dataset_class(data_path)\n",
    "        \n",
    "        \n",
    "fed_dataset = FedDataset(UserDataset)\n",
    "fed_dataset._delayed_init('data path on the collaborator node')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44fc5b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = T.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "\n",
    "augmentation = T.RandomApply([\n",
    "    T.RandomHorizontalFlip(),\n",
    "    T.RandomRotation(10),\n",
    "    T.RandomResizedCrop(64)], p=.8)\n",
    "\n",
    "training_transform = T.Compose([\n",
    "    T.Lambda(lambda x: x.convert(\"RGB\")),\n",
    "    augmentation,\n",
    "    T.ToTensor(),\n",
    "    normalize])\n",
    "\n",
    "valid_transform = T.Compose([\n",
    "    T.Lambda(lambda x: x.convert(\"RGB\")),\n",
    "    T.ToTensor(),\n",
    "    normalize])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd77dc3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FedDataset(DataInterface):\n",
    "    def __init__(self, UserDatasetClass, **kwargs):\n",
    "        self.UserDatasetClass = UserDatasetClass\n",
    "        self.kwargs = kwargs\n",
    "    \n",
    "    def _delayed_init(self, data_path='1,1'):\n",
    "        # With the next command the local dataset will be loaded on the collaborator node\n",
    "        # For this example we have the same dataset on the same path, and we will shard it\n",
    "        # So we use `data_path` information for this purpose.\n",
    "        self.rank, self.world_size = [int(part) for part in data_path.split(',')]\n",
    "        \n",
    "        self.train_set = self.UserDatasetClass(is_validation=False, \n",
    "                                               transform=training_transform)\n",
    "        self.valid_set = self.UserDatasetClass(is_validation=True, \n",
    "                                               transform=valid_transform)\n",
    "        \n",
    "        # Do the actual sharding\n",
    "        self._do_sharding( self.rank, self.world_size)\n",
    "        \n",
    "    def _do_sharding(self, rank, world_size):\n",
    "        # This method relies on the dataset's implementation\n",
    "        # i.e. coupled in a bad way\n",
    "        self.train_set.image_paths = self.train_set.image_paths[ rank-1 :: world_size ]\n",
    "\n",
    "    def get_train_loader(self, **kwargs):\n",
    "        \"\"\"\n",
    "        Output of this method will be provided to tasks with optimizer in contract\n",
    "        \"\"\"\n",
    "        return DataLoader(\n",
    "            self.train_set, num_workers=8, batch_size=self.kwargs['train_bs'], shuffle=True\n",
    "            )\n",
    "\n",
    "    def get_valid_loader(self, **kwargs):\n",
    "        \"\"\"\n",
    "        Output of this method will be provided to tasks without optimizer in contract\n",
    "        \"\"\"\n",
    "        return DataLoader(self.valid_set, num_workers=8, batch_size=self.kwargs['valid_bs'])\n",
    "\n",
    "    def get_train_data_size(self):\n",
    "        \"\"\"\n",
    "        Information for aggregation\n",
    "        \"\"\"\n",
    "        return len(self.train_set)\n",
    "\n",
    "    def get_valid_data_size(self):\n",
    "        \"\"\"\n",
    "        Information for aggregation\n",
    "        \"\"\"\n",
    "        return len(self.valid_set)\n",
    "    \n",
    "fed_dataset = FedDataset(TinyImageNetDataset, train_bs=8, valid_bs=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f4dc8c",
   "metadata": {},
   "source": [
    "### Register tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84718e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "TI = TaskInterface()\n",
    "import torch\n",
    "\n",
    "import tqdm\n",
    "\n",
    "# The Interactive API supports registering functions definied in main module or imported.\n",
    "def function_defined_in_notebook(some_parameter):\n",
    "    print(f'Also I accept a parameter and it is {some_parameter}')\n",
    "\n",
    "# Task interface currently supports only standalone functions.\n",
    "@TI.add_kwargs(**{'some_parameter': 42})\n",
    "@TI.register_fl_task(model='net_model', data_loader='train_loader', \\\n",
    "                     device='device', optimizer='optimizer')     \n",
    "def train(net_model, train_loader, optimizer, device, loss_fn=cross_entropy, some_parameter=None):\n",
    "    if not torch.cuda.is_available():\n",
    "        device = 'cpu'\n",
    "    \n",
    "    function_defined_in_notebook(some_parameter)\n",
    "    \n",
    "    train_loader = tqdm.tqdm(train_loader, desc=\"train\")\n",
    "    net_model.train()\n",
    "    net_model.to(device)\n",
    "\n",
    "    losses = []\n",
    "\n",
    "    for data, target in train_loader:\n",
    "        data, target = torch.tensor(data).to(device), torch.tensor(\n",
    "            target).to(device) \n",
    "        optimizer.zero_grad()\n",
    "        output = net_model(data)\n",
    "        loss = loss_fn(output=output, target=target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.detach().cpu().numpy())\n",
    "        \n",
    "    return {'train_loss': np.mean(losses),}\n",
    "\n",
    "\n",
    "@TI.register_fl_task(model='net_model', data_loader='val_loader', device='device')     \n",
    "def validate(net_model, val_loader, device):\n",
    "    net_model.eval()\n",
    "    net_model.to(device)\n",
    "    \n",
    "    val_loader = tqdm.tqdm(val_loader, desc=\"validate\")\n",
    "    val_score = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in val_loader:\n",
    "            samples = target.shape[0]\n",
    "            total_samples += samples\n",
    "            data, target = torch.tensor(data).to(device), \\\n",
    "                torch.tensor(target).to(device, dtype=torch.int64)\n",
    "            output = net_model(data)\n",
    "            pred = output.argmax(dim=1,keepdim=True)\n",
    "            val_score += pred.eq(target).sum().cpu().numpy()\n",
    "            \n",
    "    return {'acc': val_score / total_samples,}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07bbbc69",
   "metadata": {},
   "source": [
    "## Time to start a federated learning experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8736ecfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create a federation\n",
    "from openfl.interface.interactive_api.federation import Federation\n",
    "\n",
    "# 1) Run with aggregator-collaborator mTLS \n",
    "# If the user wants to enable mTLS their must provide CA root chain, and signed key pair to the federation interface\n",
    "cert_chain = 'cert/cert_chain.crt'\n",
    "agg_certificate = 'cert/agg_certificate.crt'\n",
    "agg_private_key = 'cert/agg_private.key'\n",
    "\n",
    "federation = Federation(central_node_fqdn='some.fqdn',\n",
    "                       cert_chain=cert_chain, agg_certificate=agg_certificate, agg_private_key=agg_private_key)\n",
    "col_data_paths = {'one': '1,1',}\n",
    "federation.register_collaborators(col_data_paths=col_data_paths)\n",
    "\n",
    "# --------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# 2) Run with TLS disabled (trusted environment)\n",
    "# Federation can also determine local fqdn automatically\n",
    "federation = Federation(central_node_fqdn='localhost', tls=False)\n",
    "# First number which is a collaborators rank may also be passed as a cuda device identifier\n",
    "col_data_paths = {'one': '1,2',\n",
    "                'two': '2,2'}\n",
    "federation.register_collaborators(col_data_paths=col_data_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f56355e",
   "metadata": {},
   "source": [
    "#### Certification of an aggregator\n",
    "* fx workspace certify: creates cert folder and CA as well as cert_chain\n",
    "* fx aggregator generate-cert-request --fqdn `FQDN`: you can pass a specific aggregator FQDN if you want\n",
    "* fx aggregator certify --fqdn `FQDN` --silent: signes aggregators cert\n",
    "<br> After that just pass the paths to required certs to the Federation API\n",
    "\n",
    "#### Certification of a collaborator\n",
    "just follow the usual procedure: <br>\n",
    "fx collaborator generate-cert-request -d {DATA_PATH} -n {COL} \n",
    "\n",
    "fx collaborator certify --request-pkg {COL_DIRECTORY}/{FED_WORKSPACE}/col_{COL}_to_agg_cert_request.zip\n",
    "\n",
    "fx collaborator certify --import {FED_DIRECTORY}/agg_to_col_{COL}_signed_cert.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070adad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an experimnet in federation\n",
    "fl_experiment = FLExperiment(federation=federation,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9a50b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If I use autoreload I got a pickling error\n",
    "\n",
    "# The following command zips the workspace and python requirements to be transfered to collaborator nodes\n",
    "fl_experiment.prepare_workspace_distribution(model_provider=MI, task_keeper=TI, data_loader=fed_dataset, rounds_to_train=2, \\\n",
    "                              opt_treatment='CONTINUE_GLOBAL')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "guided-celtic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This command starts the aggregator server\n",
    "fl_experiment.start_experiment(model_provider=MI)\n",
    "\n",
    "# When the aggregator server blocks the notebook one can start collaborators\n",
    "# For the test run just type console command from the workspace directory:\n",
    "# `fx collaborator start -d data.yaml -n {col_name}` for all collaborators\n",
    "# For the distributed experiment transfer zipped workspace to the collaborator nodes and run\n",
    "# `fx workspace import --archive {workspace_name}.zip` cd to the workspace and start collaborators"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac21bdf5",
   "metadata": {},
   "source": [
    "## Now we validate the best model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13eaa1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = fl_experiment.get_best_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4de2ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fed_dataset._delayed_init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5def62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validating initial model\n",
    "validate(initial_model, fed_dataset.get_valid_loader(), 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf17304",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validating trained model\n",
    "validate(best_model, fed_dataset.get_valid_loader(), 'cpu')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
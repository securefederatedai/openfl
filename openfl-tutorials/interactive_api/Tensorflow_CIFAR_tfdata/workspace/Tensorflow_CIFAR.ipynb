{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26fdd9ed",
   "metadata": {},
   "source": [
    "# Federated Tensorflow CIFAR10 Tutorial\n",
    "Using `tf.data` API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1329f2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install TF if not already. We recommend TF2.13 or greater.\n",
    "# !pip install tensorflow==2.13"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d30942",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0833dfc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print('TensorFlow', tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246f9c98",
   "metadata": {},
   "source": [
    "## Connect to the Federation\n",
    "\n",
    "Start `Director` and `Envoy` before proceeding with this cell. \n",
    "\n",
    "This cell connects this notebook to the Federation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d657e463",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openfl.interface.interactive_api.federation import Federation\n",
    "\n",
    "# please use the same identificator that was used in signed certificate\n",
    "client_id = 'api'\n",
    "cert_dir = 'cert'\n",
    "director_node_fqdn = 'localhost'\n",
    "director_port = 50051\n",
    "\n",
    "# Create a Federation\n",
    "federation = Federation(\n",
    "    client_id=client_id,\n",
    "    director_node_fqdn=director_node_fqdn,\n",
    "    director_port=director_port, \n",
    "    tls=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6efe22a8",
   "metadata": {},
   "source": [
    "## Query Datasets from Shard Registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47dcfab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "shard_registry = federation.get_shard_registry()\n",
    "shard_registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a6c237",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, request a dummy_shard_desc that holds information about the federated dataset \n",
    "dummy_shard_desc = federation.get_dummy_shard_descriptor(size=10)\n",
    "dummy_shard_dataset = dummy_shard_desc.get_dataset('train')\n",
    "sample, target = dummy_shard_dataset[0]\n",
    "f\"Sample shape: {sample.shape}, target shape: {target.shape}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0dbdbd",
   "metadata": {},
   "source": [
    "## Describing FL experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc88700a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openfl.interface.interactive_api.experiment import TaskInterface\n",
    "from openfl.interface.interactive_api.experiment import ModelInterface\n",
    "from openfl.interface.interactive_api.experiment import FLExperiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b468ae1",
   "metadata": {},
   "source": [
    "### Register model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06545bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(10, activation=None),\n",
    "], name='simplecnn')\n",
    "model.summary()\n",
    "\n",
    "# Define optimizer\n",
    "optimizer = tf.keras.optimizers.legacy.Adam(learning_rate=1e-4)\n",
    "\n",
    "# Loss and metrics. These will be used later.\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "train_acc_metric = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "val_acc_metric = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "\n",
    "# Create ModelInterface\n",
    "framework_adapter = 'openfl.plugins.frameworks_adapters.keras_adapter.FrameworkAdapterPlugin'\n",
    "MI = ModelInterface(model=model, optimizer=optimizer, framework_plugin=framework_adapter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0979470",
   "metadata": {},
   "source": [
    "### Register dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c9eb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openfl.interface.interactive_api.experiment import DataInterface\n",
    "\n",
    "class CIFAR10FedDataset(DataInterface):\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    @property\n",
    "    def shard_descriptor(self):\n",
    "        return self._shard_descriptor\n",
    "\n",
    "    @shard_descriptor.setter\n",
    "    def shard_descriptor(self, shard_descriptor):\n",
    "        \"\"\"\n",
    "        Describe per-collaborator procedures or sharding.\n",
    "\n",
    "        This method will be called during a collaborator initialization.\n",
    "        Local shard_descriptor will be set by Envoy.\n",
    "        \"\"\"\n",
    "        self._shard_descriptor = shard_descriptor\n",
    "        \n",
    "        # shard_descriptor.get_split(...) returns a tf.data.Dataset\n",
    "        # Check cifar10_shard_descriptor.py for details\n",
    "        self.train_set = shard_descriptor.get_split('train')\n",
    "        self.valid_set = shard_descriptor.get_split('valid')\n",
    "\n",
    "    def get_train_loader(self):\n",
    "        \"\"\"Output of this method will be provided to tasks with optimizer in contract\"\"\"\n",
    "        bs = self.kwargs.get('train_bs', 32)\n",
    "        return self.train_set.batch(bs)\n",
    "\n",
    "    def get_valid_loader(self):\n",
    "        \"\"\"Output of this method will be provided to tasks without optimizer in contract\"\"\"\n",
    "        bs = self.kwargs.get('valid_bs', 32)\n",
    "        return self.valid_set.batch(bs)\n",
    "    \n",
    "    def get_train_data_size(self) -> int:\n",
    "        \"\"\"Information for aggregation\"\"\"\n",
    "        return len(self.train_set)\n",
    "\n",
    "    def get_valid_data_size(self) -> int:\n",
    "        \"\"\"Information for aggregation\"\"\"\n",
    "        return len(self.valid_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0dfb459",
   "metadata": {},
   "source": [
    "### Create CIFAR10 federated dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af5c4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fed_dataset = CIFAR10FedDataset(train_bs=64, valid_bs=512)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849c165b",
   "metadata": {},
   "source": [
    "## Define and register FL tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9649385",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import Progbar\n",
    "\n",
    "TI = TaskInterface()\n",
    "\n",
    "@TI.register_fl_task(model='model', data_loader='dataset', optimizer='optimizer', device='device')     \n",
    "def train(model, dataset, optimizer, device, loss_fn=loss_fn, warmup=False):\n",
    "\n",
    "    # Iterate over the batches of the dataset.\n",
    "    pbar = Progbar(len(dataset))\n",
    "    \n",
    "    for step, (x, y) in enumerate(dataset):\n",
    "        \n",
    "        # Gradient\n",
    "        with tf.GradientTape() as tape:\n",
    "            logits = model(x, training=True)\n",
    "            loss_value = loss_fn(y, logits)\n",
    "        grads = tape.gradient(loss_value, model.trainable_weights)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "\n",
    "        # Update training metric.\n",
    "        train_acc_metric.update_state(y, logits)\n",
    "        pbar.update(step+1, \n",
    "                    values={'loss': loss_value, 'acc': train_acc_metric.result()}.items())\n",
    "        if warmup: break\n",
    "    \n",
    "    # Display metrics at the end of each epoch.\n",
    "    train_acc = train_acc_metric.result()\n",
    "    print(\"Training acc over epoch: %.4f\" % (float(train_acc),))\n",
    "\n",
    "    # Reset training metrics at the end of each epoch\n",
    "    train_acc_metric.reset_states()\n",
    "    return {'train_acc': train_acc,}\n",
    "\n",
    "\n",
    "@TI.register_fl_task(model='model', data_loader='dataset', device='device')     \n",
    "def validate(model, dataset, device):\n",
    "    # Run a validation loop at the end of each epoch.\n",
    "    for x, y in dataset:\n",
    "        logits = model(x, training=False)\n",
    "        # Update val metrics\n",
    "        val_acc_metric.update_state(y, logits)\n",
    "    val_acc = val_acc_metric.result()\n",
    "    val_acc_metric.reset_states()\n",
    "    print(\"Validation acc: %.4f\" % (float(val_acc),))\n",
    "            \n",
    "    return {'validation_accuracy': val_acc,}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0ebf2d",
   "metadata": {},
   "source": [
    "## Time to start a federated learning experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41b7896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an experimnet in federation\n",
    "experiment_name = 'cifar10_experiment'\n",
    "fl_experiment = FLExperiment(federation=federation, experiment_name=experiment_name,serializer_plugin='openfl.plugins.interface_serializer.keras_serializer.KerasSerializer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b44de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following command zips the workspace and python requirements to be transfered to collaborator nodes\n",
    "ROUNDS_TO_TRAIN = 10\n",
    "fl_experiment.start(model_provider=MI, \n",
    "                   task_keeper=TI,\n",
    "                   data_loader=fed_dataset,\n",
    "                   rounds_to_train=ROUNDS_TO_TRAIN,\n",
    "                   opt_treatment='CONTINUE_GLOBAL')\n",
    "fl_experiment.stream_metrics()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f82a63373a71051274245dbf52f7a790e1979bab025fdff4da684b10eb9978bd"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

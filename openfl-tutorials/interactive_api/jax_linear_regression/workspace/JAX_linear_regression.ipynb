{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6705776d-d264-493d-9696-7623231e558a",
   "metadata": {},
   "source": [
    "# JAX Regression Example - Interactive API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0fb48a-e902-4c5a-a7b7-39728f845707",
   "metadata": {},
   "source": [
    "Run this jupyter notebook on a virtual environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd66b4cd-03c2-4dc6-9113-0c3fc309e5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install jax==0.3.13 jaxlib==0.3.10 -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b95eeb4-9a6b-401d-9d35-2deaa4b51860",
   "metadata": {},
   "source": [
    "GPU version of JAX. Pick the jax version compatible with the CUDA and cuDNN pre-installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0e9cff-71f9-4710-87ae-cc5c37925008",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade pip # Careful with the pip upgrade, it may cause a package dependency related problems during OpenFL workflow execution.\n",
    "\n",
    "# Installs the wheel compatible with CUDA 11 and cuDNN 8.2 or newer.\n",
    "# Note: wheels only available on linux.\n",
    "# !pip install --upgrade \"jax[cuda]\" -f https://storage.googleapis.com/jax-releases/jax_releases.html\n",
    "\n",
    "# Installs the wheel compatible with Cuda >= 11.4 and cudnn >= 8.2\n",
    "# !pip install \"jax[cuda11_cudnn82]\" -f https://storage.googleapis.com/jax-releases/jax_releases.html\n",
    "\n",
    "# Installs the wheel compatible with Cuda >= 11.1 and cudnn >= 8.0.5\n",
    "# !pip install \"jax[cuda11_cudnn805]\" -f https://storage.googleapis.com/jax-releases/jax_releases.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3fcc5b-ee99-4ea8-95e8-6ce08db00809",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Without either of the below flags, JAX XLA raised CUDA_OUT_OF_MEMORY exception.\n",
    "# JAX XLA pre-allocates 90% of the GPU at start\n",
    "\n",
    "# Below flag to restrict max GPU allocation to 50%\n",
    "%env XLA_PYTHON_CLIENT_MEM_FRACTION=.5\n",
    "\n",
    "# OR\n",
    "\n",
    "# set XLA_PYTHON_CLIENT_PREALLOCATE to false to incrementally allocate GPU memory as and when required. But can take entire GPU by the end.\n",
    "# %env XLA_PYTHON_CLIENT_PREALLOCATE=false\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9008000e-fe07-4ff5-91cf-facb2decc560",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mandatory imports for Federation\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d292230e-bc1d-423d-836d-b4630a1c4042",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Both the MSE function are optimal and accurate in terms of correctness.\n",
    "\n",
    "# Calculate MSE approach 1\n",
    "def mse_loss_function1(W, X, y):\n",
    "    y_pred = jnp.dot(X, W)\n",
    "    mse_error = y_pred - y\n",
    "    return jnp.mean(jnp.square(mse_error))\n",
    "\n",
    "# Calculate MSE approach 2\n",
    "def mse_loss_function2(W, X, Y):\n",
    "    def squared_error(x, y):\n",
    "        y_pred = jnp.dot(x, W)\n",
    "        return jnp.inner(y-y_pred, y-y_pred)\n",
    "    vectorized_square_error = jax.vmap(squared_error)\n",
    "    return jnp.mean(vectorized_square_error(X, Y), axis=0)\n",
    "\n",
    "# Weight update, JAX compiled function. Consequent executions are way faster!!!.\n",
    "def update(W, x, y, lr):\n",
    "    W = W - lr * jax.grad(mse_loss_function1)(W, x, y)\n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cdf9a57-29c4-4787-bbd4-97553187b354",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression:\n",
    "    def __init__(self, n_feat: int) -> None:\n",
    "        self.weights = jnp.ones(n_feat)\n",
    "    \n",
    "    def mse(self, X, y) -> float:\n",
    "        return mse_loss_function1(self.weights, X, y)\n",
    " \n",
    "    def predict(self, X):\n",
    "        return jnp.dot(X, self.weights)\n",
    "    \n",
    "    def fit(self, X, Y, n_epochs : int, learning_rate : int, silent : bool) -> None:\n",
    "        \n",
    "        # Speed up weight updates with consecutive calls to jitted `update` function.\n",
    "        update_weights = jax.jit(update)\n",
    "        \n",
    "        start_time = time.time()\n",
    "        print('Training Loss at start: ', self.mse(X, Y))\n",
    "        for i in range(n_epochs):\n",
    "            self.weights = update_weights(self.weights, X, Y, learning_rate)\n",
    "            if i % int(n_epochs/10) == 0 and not silent:\n",
    "                print(str(i), 'Training Loss: ', self.mse(X, Y))\n",
    "\n",
    "        print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd4d2d7-5537-496a-88c1-301da87d979c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# JAX Linear Regression with federation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09cf7090-da51-4f4e-9d28-2a5c6e3bca02",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Connect to a Federation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3c0039-e1f7-4047-b98b-a2d4bd42f015",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a federation\n",
    "from openfl.interface.interactive_api.federation import Federation\n",
    "\n",
    "# please use the same identificator that was used in signed certificate\n",
    "client_id = 'frontend'\n",
    "director_node_fqdn = 'localhost'\n",
    "director_port = 50050\n",
    "\n",
    "federation = Federation(\n",
    "    client_id=client_id,\n",
    "    director_node_fqdn=director_node_fqdn,\n",
    "    director_port=director_port,\n",
    "    tls=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7815120e-b704-4a7d-a65a-3c7542023ead",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "shard_registry = federation.get_shard_registry()\n",
    "shard_registry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b011dd95-64a7-4a8b-91ec-e61cdf885bbb",
   "metadata": {},
   "source": [
    "### Initialize Data Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1985ac9-a2b1-4561-a962-6adfe35c3b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openfl.interface.interactive_api.experiment import TaskInterface, DataInterface, ModelInterface, FLExperiment\n",
    "\n",
    "class LinearRegressionDataSet(DataInterface):\n",
    "    def __init__(self, **kwargs):\n",
    "        \"\"\"Initialize DataLoader.\"\"\"\n",
    "        self.kwargs = kwargs\n",
    "\n",
    "    @property\n",
    "    def shard_descriptor(self):\n",
    "        \"\"\"Return shard descriptor.\"\"\"\n",
    "        return self._shard_descriptor\n",
    "    \n",
    "    @shard_descriptor.setter\n",
    "    def shard_descriptor(self, shard_descriptor):\n",
    "        \"\"\"\n",
    "        Describe per-collaborator procedures or sharding.\n",
    "        \n",
    "        This method will be called during a collaborator initialization.\n",
    "        Local shard_descriptor  will be set by Envoy.\n",
    "        \"\"\"\n",
    "        self._shard_descriptor = shard_descriptor\n",
    "        self.train_set = shard_descriptor.get_dataset('train')\n",
    "        self.val_set = shard_descriptor.get_dataset('val')\n",
    "        \n",
    "    def get_train_loader(self, **kwargs):\n",
    "        \"\"\"Output of this method will be provided to tasks with optimizer in contract.\"\"\"\n",
    "        return self.train_set\n",
    "\n",
    "    def get_valid_loader(self, **kwargs):\n",
    "        \"\"\"Output of this method will be provided to tasks without optimizer in contract.\"\"\"\n",
    "        return self.val_set\n",
    "\n",
    "    def get_train_data_size(self):\n",
    "        \"\"\"Information for aggregation.\"\"\"\n",
    "        return len(self.train_set)\n",
    "\n",
    "    def get_valid_data_size(self):\n",
    "        \"\"\"Information for aggregation.\"\"\"\n",
    "        return len(self.val_set)\n",
    "    \n",
    "lin_reg_dataset = LinearRegressionDataSet()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8909127-99d1-4dba-86fe-01a1b86585e7",
   "metadata": {},
   "source": [
    "### Define Model Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9523c9a2-a259-461f-937f-1fb054bd2886",
   "metadata": {},
   "outputs": [],
   "source": [
    "framework_adapter = 'custom_adapter.CustomFrameworkAdapter'\n",
    "\n",
    "# LinearRegression class accepts a parameter n_features. Should be same as `sample_shape` from `director_config.yaml`\n",
    "fed_model = LinearRegression(1)\n",
    "MI = ModelInterface(model=fed_model, optimizer=None, framework_plugin=framework_adapter)\n",
    "\n",
    "# Save the initial model state\n",
    "initial_model = LinearRegression(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3558bb-b21b-48ac-b07e-43cf75e6907b",
   "metadata": {},
   "source": [
    "### Register Tasks\n",
    "We need to employ a trick reporting metrics. OpenFL decides which model is the best based on an *increasing* metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73e1ff9-d54a-49b5-9ce8-8bc72c6a2c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "TI = TaskInterface()\n",
    "\n",
    "@TI.add_kwargs(**{'lr': 0.01,\n",
    "                   'epochs': 101})\n",
    "@TI.register_fl_task(model='my_model', data_loader='train_data', \\\n",
    "                     device='device', optimizer='optimizer')     \n",
    "def train(my_model, train_data, optimizer, device, lr, epochs):\n",
    "    X, Y = train_data[:,:-1], train_data[:,-1]\n",
    "    my_model.fit(X, Y, epochs, lr, silent=False)\n",
    "    return {'train_MSE': my_model.mse(X, Y),}\n",
    "\n",
    "@TI.register_fl_task(model='my_model', data_loader='val_data', device='device')\n",
    "def validate(my_model, val_data, device):\n",
    "    X, Y = val_data[:,:-1], val_data[:,-1] \n",
    "    return {'validation_MSE': my_model.mse(X, Y),}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7659cc-6e03-43f5-9078-95707fa0e4d5",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Run the federation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749100e8-05ce-418c-a980-545e3beb900b",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = 'jax_linear_regression_experiment'\n",
    "fl_experiment = FLExperiment(federation=federation, experiment_name=experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16bf1df7-8ca8-4a5e-a833-47c265c11e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "fl_experiment.start(model_provider=MI,\n",
    "                    task_keeper=TI,\n",
    "                    data_loader=lin_reg_dataset,\n",
    "                    rounds_to_train=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1178d1ea-05e6-46be-ac07-21620bd6ec76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fl_experiment.stream_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f23cac5-caec-4161-b4b2-dddceb3eab80",
   "metadata": {
    "tags": []
   },
   "source": [
    "# JAX Linear Regression without federation (Optional Simulation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94be17d7-90c9-4e5f-aeb1-102271826370",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install matplotlib scikit-learn -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5ced27-a808-4eca-be6e-d8b62929f32b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Imports for running JAX Linear Regression example without OpenFL.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize'] = 7, 5\n",
    "\n",
    "from jax import make_jaxpr\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58128c30-7865-4412-b4fd-86b0fe53f1a7",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Simple Linear Regression\n",
    "<img src=\"https://www.analyticsvidhya.com/wp-content/uploads/2016/01/eq5-1.png\" width=\"500\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140705fc-4af3-4668-a26b-2ebe2d42575e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create a dataset with n_features\n",
    "X, y = make_regression(n_samples=100, n_features=1, noise=10, random_state=42)\n",
    "\n",
    "# Train test split - Default 0.75/0.25\n",
    "X, X_test, y, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2665d0b-78ce-4caf-a4ca-a9decffaa96f",
   "metadata": {},
   "source": [
    "Visualize data distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f5afbf-e010-4d4a-bb92-46de06d39866",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "_ = plt.scatter(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe555dd-9e8d-4e80-bfde-87e3cafac14c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "_ = plt.scatter(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a7ddb3-166e-447f-a8f1-881511cfbd9f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# JAX logical execution plan\n",
    "print(jax.make_jaxpr(update)(jnp.ones(X.shape[1]), X, y, 0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574bac29-b5c2-4f41-8655-e98450fdef8d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# X.shape -> (n_samples, n_features)\n",
    "\n",
    "lr_model = LinearRegression(X.shape[1])\n",
    "lr = 0.01\n",
    "epochs = 101\n",
    "\n",
    "print(f\"Initial Test MSE: {lr_model.mse(X_test,y_test)}\")\n",
    "\n",
    "# silent: logging verbosity\n",
    "lr_model.fit(X,y, epochs, lr, silent=False)\n",
    "\n",
    "print(f\"Final Test MSE: {lr_model.mse(X_test,y_test)}\")\n",
    "\n",
    "print(f\"Final parameters: {lr_model.weights}\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

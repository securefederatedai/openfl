{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26fdd9ed",
   "metadata": {},
   "source": [
    "# Federated MedMNIST3D "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0570122",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies if not already installed\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms as T\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import medmnist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246f9c98",
   "metadata": {},
   "source": [
    "## Connect to the Federation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d657e463",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a federation\n",
    "from openfl.interface.interactive_api.federation import Federation\n",
    "\n",
    "# please use the same identificator that was used in signed certificate\n",
    "client_id = 'api'\n",
    "cert_dir = 'cert'\n",
    "director_node_fqdn = 'localhost'\n",
    "director_port=50051\n",
    "# 1) Run with API layer - Director mTLS \n",
    "# If the user wants to enable mTLS their must provide CA root chain, and signed key pair to the federation interface\n",
    "# cert_chain = f'{cert_dir}/root_ca.crt'\n",
    "# api_certificate = f'{cert_dir}/{client_id}.crt'\n",
    "# api_private_key = f'{cert_dir}/{client_id}.key'\n",
    "\n",
    "# federation = Federation(\n",
    "#     client_id=client_id,\n",
    "#     director_node_fqdn=director_node_fqdn,\n",
    "#     director_port=director_port,\n",
    "#     cert_chain=cert_chain,\n",
    "#     api_cert=api_certificate,\n",
    "#     api_private_key=api_private_key\n",
    "# )\n",
    "\n",
    "# --------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# 2) Run with TLS disabled (trusted environment)\n",
    "# Federation can also determine local fqdn automatically\n",
    "federation = Federation(\n",
    "    client_id=client_id,\n",
    "    director_node_fqdn=director_node_fqdn,\n",
    "    director_port=director_port, \n",
    "    tls=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47dcfab3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'one': {'shard_info': node_info {\n",
       "    name: \"one\"\n",
       "  }\n",
       "  shard_description: \"MedMNIST dataset, shard number 1 out of 1\"\n",
       "  sample_shape: \"28\"\n",
       "  sample_shape: \"28\"\n",
       "  sample_shape: \"28\"\n",
       "  target_shape: \"1\"\n",
       "  target_shape: \"1\",\n",
       "  'is_online': True,\n",
       "  'is_experiment_running': False,\n",
       "  'last_updated': '2022-05-25 22:50:19',\n",
       "  'current_time': '2022-05-25 22:50:26',\n",
       "  'valid_duration': seconds: 120,\n",
       "  'experiment_name': 'ExperimentName Mock'}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shard_registry = federation.get_shard_registry()\n",
    "shard_registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2a6c237",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sample shape: (28, 28, 28), target shape: (1, 1)'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First, request a dummy_shard_desc that holds information about the federated dataset \n",
    "dummy_shard_desc = federation.get_dummy_shard_descriptor(size=10)\n",
    "dummy_shard_dataset = dummy_shard_desc.get_dataset('train')\n",
    "sample, target = dummy_shard_dataset[0]\n",
    "f\"Sample shape: {sample.shape}, target shape: {target.shape}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0dbdbd",
   "metadata": {},
   "source": [
    "## Describing FL experimen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc88700a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openfl.interface.interactive_api.experiment import TaskInterface, DataInterface, ModelInterface, FLExperiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3081a6",
   "metadata": {},
   "source": [
    "## Load MedMNIST INFO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0377d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from medmnist import INFO, Evaluator\n",
    "\n",
    "data_flag = 'synapsemnist3d'\n",
    "#data_flag = 'bloodmnist'\n",
    "download = True\n",
    "\n",
    "num_epochs = 3\n",
    "batch_size = 128\n",
    "\n",
    "lr = 0.001\n",
    "gamma=0.1\n",
    "milestones = [0.5 * num_epochs, 0.75 * num_epochs]\n",
    "\n",
    "info = INFO[data_flag]\n",
    "task = info['task']\n",
    "n_channels = info['n_channels']\n",
    "n_classes = len(info['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9bd05eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46ab2b97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'python_class': 'SynapseMNIST3D',\n",
       " 'description': 'The SynapseMNIST3D is a new 3D volume dataset to classify whether a synapse is excitatory or inhibitory. It uses a 3D image volume of an adult rat acquired by a multi-beam scanning electron microscope. The original data is of the size 100×100×100um^3 and the resolution 8×8×30nm^3, where a (30um)^3 sub-volume was used in the MitoEM dataset with dense 3D mitochondria instance segmentation labels. Three neuroscience experts segment a pyramidal neuron within the whole volume and proofread all the synapses on this neuron with excitatory/inhibitory labels. For each labeled synaptic location, we crop a 3D volume of 1024×1024×1024nm^3 and resize it into 28×28×28 voxels. Finally, the dataset is randomly split with a ratio of 7:1:2 into training, validation and test set.',\n",
       " 'url': 'https://zenodo.org/record/5208230/files/synapsemnist3d.npz?download=1',\n",
       " 'MD5': '1235b78a3cd6280881dd7850a78eadb6',\n",
       " 'task': 'binary-class',\n",
       " 'label': {'0': 'inhibitory synapse', '1': 'excitatory synapse'},\n",
       " 'n_channels': 1,\n",
       " 'n_samples': {'train': 1230, 'val': 177, 'test': 352},\n",
       " 'license': 'CC BY 4.0'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0979470",
   "metadata": {},
   "source": [
    "### Register dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f0dc457e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wspace_utils.utils import Transform3D, model_to_syncbn\n",
    "\n",
    "shape_transform = False\n",
    "\n",
    "train_transform = Transform3D(mul='random') if shape_transform else Transform3D()\n",
    "eval_transform = Transform3D(mul='0.5') if shape_transform else Transform3D()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "09ba2f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "class TransformedDataset(Dataset):\n",
    "    \"\"\"Image Person ReID Dataset.\"\"\"\n",
    "\n",
    "\n",
    "    def __init__(self, dataset, transform=None, target_transform=None, as_rgb=False):\n",
    "        \"\"\"Initialize Dataset.\"\"\"\n",
    "        self.dataset = dataset\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.as_rgb = as_rgb\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Length of dataset.\"\"\"\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "                \n",
    "        img, label = self.dataset[index]\n",
    "        \n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)  \n",
    "        else:\n",
    "            label = label.astype(int)\n",
    "        \n",
    "        # Change between 2D and 3D\n",
    "        img = np.stack([img/255.]*(3 if self.as_rgb else 1), axis=0)\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        #print(f\"ECCOMI dtype = {img.dtype}, type = {type(img)}\")\n",
    "\n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "        \n",
    "        #img = np.array(img) \n",
    "        \n",
    "        return img, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "db2d563e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MedMnistFedDataset(DataInterface):\n",
    "    def __init__(self, **kwargs):\n",
    "        self.kwargs = kwargs\n",
    "        \n",
    "    @property\n",
    "    def shard_descriptor(self):\n",
    "        return self._shard_descriptor\n",
    "        \n",
    "    @shard_descriptor.setter\n",
    "    def shard_descriptor(self, shard_descriptor):\n",
    "        \"\"\"\n",
    "        Describe per-collaborator procedures or sharding.\n",
    "\n",
    "        This method will be called during a collaborator initialization.\n",
    "        Local shard_descriptor  will be set by Envoy.\n",
    "        \"\"\"\n",
    "        self._shard_descriptor = shard_descriptor\n",
    "\n",
    "        self.train_set = TransformedDataset(\n",
    "            self._shard_descriptor.get_dataset('train'),\n",
    "            transform=train_transform, as_rgb=False\n",
    "        )       \n",
    "        \n",
    "        self.valid_set = TransformedDataset(\n",
    "            self._shard_descriptor.get_dataset('val'),\n",
    "            transform=eval_transform, as_rgb=False\n",
    "        )\n",
    "        \n",
    "    def get_train_loader(self, **kwargs):\n",
    "        \"\"\"\n",
    "        Output of this method will be provided to tasks with optimizer in contract\n",
    "        \"\"\"\n",
    "        return DataLoader(\n",
    "            self.train_set, num_workers=8, batch_size=self.kwargs['train_bs'], shuffle=True)\n",
    "\n",
    "    def get_valid_loader(self, **kwargs):\n",
    "        \"\"\"\n",
    "        Output of this method will be provided to tasks without optimizer in contract\n",
    "        \"\"\"\n",
    "        return DataLoader(self.valid_set, num_workers=8, batch_size=self.kwargs['valid_bs'])\n",
    "\n",
    "    def get_train_data_size(self):\n",
    "        \"\"\"\n",
    "        Information for aggregation\n",
    "        \"\"\"\n",
    "        return len(self.train_set)\n",
    "\n",
    "    def get_valid_data_size(self):\n",
    "        \"\"\"\n",
    "        Information for aggregation\n",
    "        \"\"\"\n",
    "        return len(self.valid_set)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0dfb459",
   "metadata": {},
   "source": [
    "### Create Mnist federated dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4af5c4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fed_dataset = MedMnistFedDataset(train_bs=64, valid_bs=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7f63908e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 1, 28, 28, 28) torch.Size([10, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "fed_dataset.shard_descriptor = dummy_shard_desc\n",
    "for i, (sample, target) in enumerate(fed_dataset.get_train_loader()):\n",
    "    sample = (np.array(sample))\n",
    "    print(sample.shape, target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "479a5b31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dtype = float32, type = <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(f\"dtype = {sample.dtype}, type = {type(sample)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f005760c",
   "metadata": {},
   "source": [
    "## Describe the model and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d47f74d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        # self.bn1 = nn.GroupNorm(num_groups=2, num_channels=planes)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        # self.bn2 = nn.GroupNorm(num_groups=2, num_channels=planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "                # nn.GroupNorm(num_groups=2, num_channels=self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        # self.bn1 = nn.GroupNorm(num_groups=2, num_channels=planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
    "                               stride=stride, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        # self.bn2 = nn.GroupNorm(num_groups=2, num_channels=planes)\n",
    "        self.conv3 = nn.Conv2d(planes, self.expansion *\n",
    "                               planes, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n",
    "        # self.bn3 = nn.GroupNorm(num_groups=2, num_channels=self.expansion*planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "                # nn.GroupNorm(num_groups=2, num_channels=self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = F.relu(self.bn2(self.conv2(out)))\n",
    "        out = self.bn3(self.conv3(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, in_channels=1, num_classes=2):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 64\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels, 64, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        # self.bn1 = nn.GroupNorm(num_groups=2, num_channels=64)\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.linear = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        # out = F.avg_pool2d(out, 4)\n",
    "        # out = F.adaptive_avg_pool3d(out, output_size=4)\n",
    "        out = self.avgpool(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "def ResNet18(in_channels, num_classes):\n",
    "    return ResNet(BasicBlock, [2, 2, 2, 2], in_channels=in_channels, num_classes=num_classes)\n",
    "\n",
    "\n",
    "def ResNet50(in_channels, num_classes):\n",
    "    return ResNet(Bottleneck, [3, 4, 6, 3], in_channels=in_channels, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "15e0294b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ``converters`` are currently experimental. It may not support operations including (but not limited to) Functions in ``torch.nn.functional`` that involved data dimension\n"
     ]
    }
   ],
   "source": [
    "from acsconv.converters import ACSConverter, Conv3dConverter, Conv2_5dConverter\n",
    "\n",
    "model = ResNet18(in_channels=n_channels, num_classes=n_classes)\n",
    "model = model_to_syncbn(Conv3dConverter(model, i3d_repeat_axis=None))\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f2154486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv3dConverter(\n",
      "ResNet(\n",
      "  (conv1): Conv3d(1, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "  (bn1): SynchronizedBatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      (bn1): SynchronizedBatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      (bn2): SynchronizedBatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      (bn1): SynchronizedBatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      (bn2): SynchronizedBatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
      "      (bn1): SynchronizedBatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      (bn2): SynchronizedBatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
      "        (1): SynchronizedBatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      (bn1): SynchronizedBatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      (bn2): SynchronizedBatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
      "      (bn1): SynchronizedBatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      (bn2): SynchronizedBatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
      "        (1): SynchronizedBatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      (bn1): SynchronizedBatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      (bn2): SynchronizedBatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv3d(256, 512, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
      "      (bn1): SynchronizedBatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      (bn2): SynchronizedBatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
      "        (1): SynchronizedBatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      (bn1): SynchronizedBatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      (bn2): SynchronizedBatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool3d(output_size=(1, 1, 1))\n",
      "  (linear): Linear(in_features=512, out_features=2, bias=True)\n",
      ")\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from torchvision import models\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1c78ee",
   "metadata": {},
   "source": [
    "### Register model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "59831bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "framework_adapter = 'openfl.plugins.frameworks_adapters.pytorch_adapter.FrameworkAdapterPlugin'\n",
    "MI = ModelInterface(model=model.model, optimizer=optimizer, framework_plugin=framework_adapter)\n",
    "\n",
    "# Save the initial model state\n",
    "initial_model = deepcopy(model.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "602d8674",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "acsconv.converters.conv3d_converter.Conv3dConverter"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849c165b",
   "metadata": {},
   "source": [
    "## Define and register FL tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4ff463bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "TI = TaskInterface()\n",
    "\n",
    "from logging import getLogger\n",
    "\n",
    "import torch\n",
    "import tqdm\n",
    "\n",
    "logger = getLogger(__name__)\n",
    "\n",
    "train_custom_params={'criterion':criterion,'task':task}\n",
    "\n",
    "# Task interface currently supports only standalone functions.\n",
    "@TI.add_kwargs(**train_custom_params)\n",
    "@TI.register_fl_task(model='model', data_loader='train_loader',\n",
    "                     device='device', optimizer='optimizer')\n",
    "def train(model, train_loader, device, optimizer, criterion, task):\n",
    "    total_loss = []\n",
    "    \n",
    "    print(f\"CREATING TQDM\")\n",
    "    train_loader = tqdm.tqdm(train_loader, desc=\"train\")\n",
    "    print(f\"ENTERING TRAIN\")\n",
    "    model.train()\n",
    "    print(f\"MODEL TO DEVICE\")\n",
    "    model.to(device)\n",
    "    \n",
    "    print(f\"ENTERING THE LOOP\")\n",
    "    for inputs, targets in train_loader:\n",
    "        \n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        print(f\"TO DEVICES DONE\")\n",
    "    \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs.to(device))\n",
    "        \n",
    "        if task == 'multi-label, binary-class':\n",
    "            targets = targets.to(torch.float32).to(device)\n",
    "            loss = criterion(outputs, targets)\n",
    "        else:\n",
    "            targets = torch.squeeze(targets, 1).long().to(device)\n",
    "            loss = criterion(outputs, targets)\n",
    "        \n",
    "        total_loss.append(loss.item())\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    return {'train_loss': np.mean(total_loss),}\n",
    "\n",
    "\n",
    "\n",
    "val_evaluator = medmnist.Evaluator(data_flag, 'val')\n",
    "val_custom_params={'criterion':criterion, 'evaluator':val_evaluator}\n",
    "\n",
    "@TI.add_kwargs(**val_custom_params)\n",
    "@TI.register_fl_task(model='model', data_loader='val_loader', device='device')\n",
    "def validate(model, val_loader, device, criterion, evaluator):\n",
    "\n",
    "    val_loader = tqdm.tqdm(val_loader, desc=\"validate\")\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "\n",
    "    val_score = 0\n",
    "    total_samples = 0\n",
    "    total_loss = []\n",
    "    y_score = torch.tensor([]).to(device)\n",
    "\n",
    "    print(f\"ENTERING THE LOOP\")\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in val_loader:\n",
    "            outputs = model(inputs.to(device))\n",
    "            print(f\"OUTPUT DONE\")\n",
    "            \n",
    "            #targets = torch.squeeze(targets, 1).long().to(device)\n",
    "            #loss = criterion(outputs, targets)\n",
    "            #m = nn.Softmax(dim=1)\n",
    "            #outputs = m(outputs).to(device)\n",
    "            #targets = targets.float().resize_(len(targets), 1)\n",
    "\n",
    "            #total_loss.append(loss.item())\n",
    "            #y_score = torch.cat((y_score, outputs), 0)\n",
    "            #------------\n",
    "            #total_samples += targets.shape[0]\n",
    "            #pred = outputs.argmax(dim=1)\n",
    "            #val_score += pred.eq(targets).sum().cpu().numpy()\n",
    "            \n",
    "        #y_score = y_score.detach().cpu().numpy()\n",
    "        #auc, acc = evaluator.evaluate(y_score)\n",
    "        \n",
    "        #acc = val_score / total_samples        \n",
    "        #test_loss = sum(total_loss) / len(total_loss)\n",
    "        acc = 1.0\n",
    "        test_loss = 1.0\n",
    "\n",
    "        return {'acc': acc,\n",
    "                'test_loss': test_loss,\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "19681029",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(arr.flags['WRITEABLE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0ebf2d",
   "metadata": {},
   "source": [
    "## Time to start a federated learning experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d41b7896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an experimnet in federation\n",
    "experiment_name = 'medmnist_exp'\n",
    "fl_experiment = FLExperiment(federation=federation, experiment_name=experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "41b44de9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">[22:50:45] </span><span style=\"color: #000080\">INFO</span>     Building <span style=\"color: #800000\">🡆</span> Object <span style=\"color: #800000\">CloudpickleSerializer</span> from <span style=\"color: #800000\">openfl.plugins.interface_serializer.cloudpickle_serializer</span> Module.                  <a href=\"file:///home/nuc1/Documenti/tools/openfl/lib/python3.8/site-packages/openfl/federated/plan/plan.py\"><span style=\"color: #7f7f7f\">plan.py</span></a><span style=\"color: #7f7f7f\">:171</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7f368dff6e50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">           </span><span style=\"color: #000080\">INFO</span>     Building <span style=\"color: #800000\">🡆</span> Object <span style=\"color: #800000\">FrameworkAdapterPlugin</span> from <span style=\"color: #800000\">openfl.plugins.frameworks_adapters.pytorch_adapter</span> Module.                         <a href=\"file:///home/nuc1/Documenti/tools/openfl/lib/python3.8/site-packages/openfl/federated/plan/plan.py\"><span style=\"color: #7f7f7f\">plan.py</span></a><span style=\"color: #7f7f7f\">:171</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7f368c235d30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">[22:50:52] </span><span style=\"color: #000080\">INFO</span>     Starting experiment!                                                                                                       <a href=\"file:///home/nuc1/Documenti/tools/openfl/lib/python3.8/site-packages/openfl/interface/interactive_api/experiment.py\"><span style=\"color: #7f7f7f\">experiment.py</span></a><span style=\"color: #7f7f7f\">:213</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7f36abc35e20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">           </span><span style=\"color: #000080\">INFO</span>     FL-Plan hash is <span style=\"color: #000080\">a8df908801a7935bd51687e3ff1f6164b300339a0b3c6bf315b41ea3805878707d79f27fa44ebb7615bdbef57d19d078</span>                 <a href=\"file:///home/nuc1/Documenti/tools/openfl/lib/python3.8/site-packages/openfl/federated/plan/plan.py\"><span style=\"color: #7f7f7f\">plan.py</span></a><span style=\"color: #7f7f7f\">:233</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7f36abc20cd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">           </span><span style=\"color: #000080\">INFO</span>     FL-Plan hash is <span style=\"color: #000080\">a8df908801a7935bd51687e3ff1f6164b300339a0b3c6bf315b41ea3805878707d79f27fa44ebb7615bdbef57d19d078</span>                 <a href=\"file:///home/nuc1/Documenti/tools/openfl/lib/python3.8/site-packages/openfl/federated/plan/plan.py\"><span style=\"color: #7f7f7f\">plan.py</span></a><span style=\"color: #7f7f7f\">:233</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7f37284e2430>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">           </span><span style=\"color: #000080\">INFO</span>     Building <span style=\"color: #800000\">🡆</span> Object <span style=\"color: #800000\">CoreTaskRunner</span> from <span style=\"color: #800000\">openfl.federated.task.task_runner</span> Module.                                                  <a href=\"file:///home/nuc1/Documenti/tools/openfl/lib/python3.8/site-packages/openfl/federated/plan/plan.py\"><span style=\"color: #7f7f7f\">plan.py</span></a><span style=\"color: #7f7f7f\">:171</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7f372a0f8dc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">           </span><span style=\"color: #000080\">INFO</span>     Building <span style=\"color: #800000\">🡆</span> Object <span style=\"color: #800000\">FrameworkAdapterPlugin</span> from <span style=\"color: #800000\">openfl.plugins.frameworks_adapters.pytorch_adapter</span> Module.                         <a href=\"file:///home/nuc1/Documenti/tools/openfl/lib/python3.8/site-packages/openfl/federated/plan/plan.py\"><span style=\"color: #7f7f7f\">plan.py</span></a><span style=\"color: #7f7f7f\">:171</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7f36abc35430>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">           </span><span style=\"color: #800000\">WARNING</span>  tried to remove tensor: __opt_state_needed not present in the tensor dict                                                       <a href=\"file:///home/nuc1/Documenti/tools/openfl/lib/python3.8/site-packages/openfl/utilities/utils.py\"><span style=\"color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f\">:170</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7f36abc20220>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">           </span><span style=\"color: #800000\">WARNING</span>  tried to remove tensor: __opt_state_needed not present in the tensor dict                                                       <a href=\"file:///home/nuc1/Documenti/tools/openfl/lib/python3.8/site-packages/openfl/utilities/utils.py\"><span style=\"color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f\">:170</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7f37284e2430>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">           </span><span style=\"color: #000080\">INFO</span>     SetNewExperiment                                                                                                      <a href=\"file:///home/nuc1/Documenti/tools/openfl/lib/python3.8/site-packages/openfl/transport/grpc/director_client.py\"><span style=\"color: #7f7f7f\">director_client.py</span></a><span style=\"color: #7f7f7f\">:203</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7f36abc35940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">[22:51:02] </span><span style=\"color: #000080\">INFO</span>     Experiment was accepted and launched.                                                                                      <a href=\"file:///home/nuc1/Documenti/tools/openfl/lib/python3.8/site-packages/openfl/interface/interactive_api/experiment.py\"><span style=\"color: #7f7f7f\">experiment.py</span></a><span style=\"color: #7f7f7f\">:227</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7f36abc35a00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# If I use autoreload I got a pickling error\n",
    "# The following command zips the workspace and python requirements to be transfered to collaborator nodes\n",
    "fl_experiment.start(model_provider=MI, \n",
    "                    task_keeper=TI,\n",
    "                    data_loader=fed_dataset,\n",
    "                    rounds_to_train=3,\n",
    "                    opt_treatment='RESET',\n",
    "                    device_assignment_policy='CUDA_PREFERRED')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fa7cea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">[22:59:23] </span>METRIC   Round <span style=\"color: #000080; font-weight: bold\">0</span>, collaborator trained train result train_loss:  <span style=\"color: #000080; font-weight: bold\">0.664845</span>                                                           <a href=\"file:///home/nuc1/Documenti/tools/openfl/lib/python3.8/site-packages/openfl/interface/interactive_api/experiment.py\"><span style=\"color: #7f7f7f\">experiment.py</span></a><span style=\"color: #7f7f7f\">:115</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7f36abc35340>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# If user want to stop IPython session, then reconnect and check how experiment is going\n",
    "# fl_experiment.restore_experiment_state(model_interface)\n",
    "\n",
    "fl_experiment.stream_metrics(tensorboard_logs=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef600100",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1690ea49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openfl",
   "language": "python",
   "name": "openfl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4dd5da0c-1ae1-43e6-8ad9-360c8974476c",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/intel/openfl/blob/develop/openfl-tutorials/interactive_api/numpy_linear_regression/workspace/SingleNotebook.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1637381d-84d0-4132-92c3-bf1a1e9c7f7a",
   "metadata": {},
   "source": [
    "# Linear Regression with Numpy and OpenFL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee73e205-d273-4b6c-878a-5ea958bfe267",
   "metadata": {},
   "source": [
    "### Preparations in colab:\n",
    "1. Install OpenFL \n",
    "2. Clone the OpenFL repository, it contains infrastructure configs for this example.\n",
    "3. Change working directory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6fafe9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openfl\n",
    "!git clone https://github.com/securefederatedai/openfl.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2698f1da-fa69-4543-bb15-c7c0dcb776b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "\n",
    "# Logging fix for Google Colab\n",
    "log = logging.getLogger()\n",
    "log.setLevel(logging.INFO)\n",
    "\n",
    "os.chdir('./openfl/openfl-tutorials/interactive_api/numpy_linear_regression/workspace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde856d8-da4e-4d2f-bee2-85e673050623",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Union\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize'] = 7, 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e76f9d",
   "metadata": {},
   "source": [
    "# Define a linear model and train it locally\n",
    "We start with training a linear model locally on a synthetic dataset so we have a baseline solution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e06d979-c582-4f44-b092-e5d60cce88bf",
   "metadata": {
    "tags": []
   },
   "source": [
    "## We will use MSE as loss function and Ridge weights regularization\n",
    "![image.png](https://www.analyticsvidhya.com/wp-content/uploads/2016/01/eq5-1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a860ab-91a5-410e-9d1e-4b9bd5a33d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinRegLasso:\n",
    "    def __init__(self, n_feat: int) -> None:\n",
    "        self.weights = np.ones((n_feat + 1)) # (n_feat + 1,) weights + bias\n",
    "        \n",
    "    def predict(self, feature_vector: Union[np.ndarray, List[int]]) -> float:\n",
    "        '''\n",
    "        feature_vector may be a list or have shape (n_feat,)\n",
    "        or it may be a bunch of vectors (n_vec, nfeat)\n",
    "        '''\n",
    "        feature_vector = np.array(feature_vector)\n",
    "        if len(feature_vector.shape) == 1:\n",
    "            feature_vector = feature_vector[:,np.newaxis]\n",
    "        assert feature_vector.shape[-1] == self.weights.shape[0] - 1, \\\n",
    "            f\"sample shape is {feature_vector.shape} and weights shape is f{self.weights}\"\n",
    "        \n",
    "        return self.weights @ np.concatenate((feature_vector.T, [[1]*feature_vector.shape[0]]))\n",
    "    \n",
    "    def mse(self, X: np.ndarray, Y: np.ndarray) -> float:\n",
    "        Y_hat = self.predict(X)\n",
    "        return np.sum((Y - Y_hat)**2) / Y.shape[0]\n",
    "\n",
    "    def _update_weights(self, X: np.ndarray, Y: np.ndarray, lr: float, wd: float) -> None:\n",
    "        '''\n",
    "        X: (n_samples, n_features)\n",
    "        Y: (n_samples,)\n",
    "        self.weights: (n_features + 1)\n",
    "        \n",
    "        Cost function is MSE: (y - W*X - b)**2;\n",
    "        its derivative with resp to any x is -2*X*(y - W*X - b),\n",
    "        and with resp to b is -2*(y - W*X - b).\n",
    "        \n",
    "        Regularisation function is L1 |W|;\n",
    "        its derivative is SIGN(w)\n",
    "        '''\n",
    "        predictions = self.predict(X)\n",
    "        error = Y - predictions # (n_samples,)\n",
    "        X_with_bias = np.concatenate((X.T, [[1]*X.shape[0]])).T\n",
    "        updates = -2 * X_with_bias.T @ error / Y.shape[0]\n",
    "        regression_term = np.sign(self.weights)\n",
    "        \n",
    "        self.weights = self.weights - lr * updates + wd * regression_term\n",
    "    \n",
    "    def fit(self, X: np.ndarray, Y: np.ndarray,\n",
    "            n_epochs: int, lr: float, wd: float,\n",
    "            silent: bool=False) -> None:\n",
    "        for i in range(n_epochs):\n",
    "            self._update_weights(X, Y, lr, wd)\n",
    "            mse = self.mse(X, Y)\n",
    "            if not silent:\n",
    "                print(f'epoch: {i}, \\t MSE: {mse}')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796b0de6-cb80-4ca6-91e9-503011d6851f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input array with angles from 60deg to 300deg converted to radians\n",
    "noise=0.2\n",
    "\n",
    "x = np.array([i*np.pi/180 for i in range(60,300,4)])\n",
    "np.random.seed(10)  # Setting seed for reproducibility\n",
    "y = np.sin(x) + np.random.normal(0, noise, len(x))\n",
    "# plt.plot(x,y,'.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033a74b4-3bc2-4a19-b734-007ad8a4c037",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lr_model = LinRegLasso(1)\n",
    "wd = 0.0001\n",
    "lr = 0.08\n",
    "epochs = 100\n",
    "\n",
    "print(f\"Initila MSE: {lr_model.mse(x,y)}\")\n",
    "lr_model.fit(x[:,np.newaxis],y, epochs, lr, wd, silent=True)\n",
    "print(f\"Final MSE: {lr_model.mse(x,y)}\")\n",
    "print(f\"Final parameters: {lr_model.weights}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25873a87-7564-4e4a-8ef5-79a9415b209f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also solve this 1D problem using Numpy\n",
    "numpy_solution = np.polyfit(x,y,1)\n",
    "predictor_np = np.poly1d(numpy_solution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5b7a9b-4d4b-4222-8eef-4ef4ba63434a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = lr_model.predict(x)\n",
    "y_np = predictor_np(x)\n",
    "plt.plot(x,y,'.')\n",
    "plt.plot(x,y_hat,'.')\n",
    "plt.plot(x,y_np,'--')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd2e26a5-9f4e-4011-a999-e428246aa8c1",
   "metadata": {},
   "source": [
    "# Now we run the same training on federated data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83378ece-9cd5-4d40-a134-24cf68bdb79a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1. Start the Director service and several envoys with generated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d105a0-04c4-4c26-81c7-a350e14393c2",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Here are the main parameters for our Federation\n",
    "n_cols=10 # Number of Envoys / Collaborators\n",
    "n_samples_per_col=10\n",
    "noise=0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c3e78b-6e9d-4efc-9b30-3ddc413c0423",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from time import sleep\n",
    "from typing import Dict, List, Union\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "463a2821-b657-4e12-90ac-33b7810c5ff4",
   "metadata": {},
   "source": [
    "### Start the Director service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e736d33f-5df2-4a2f-8210-f1feba9fd367",
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = Path.cwd()\n",
    "director_workspace_path = Path('../director/').absolute()\n",
    "director_config_file = director_workspace_path / 'director_config.yaml'\n",
    "director_logfile = director_workspace_path / 'director.log'\n",
    "if director_logfile.is_file(): director_logfile.unlink()\n",
    "\n",
    "os.environ['main_folder'] = str(cwd)\n",
    "os.environ['director_workspace_path'] = str(director_workspace_path)\n",
    "os.environ['director_logfile'] = str(director_logfile)\n",
    "os.environ['director_config_file'] = str(director_config_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb950328-c1e6-4062-8b36-b42486d60241",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script /bin/bash --bg\n",
    "cd $director_workspace_path\n",
    "fx director start --disable-tls -c $director_config_file > $director_logfile &\n",
    "cd $main_folder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223f0037-c87e-440d-b8df-8fe9211c34dc",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Start Envoys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6deeee4-5dc8-433d-a4ea-c464c74b1b2b",
   "metadata": {},
   "source": [
    "#### First, we create several envoy config files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e65a39-15f7-4cca-90bb-a2970b7be9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the original envoy config file content\n",
    "with open(Path('../envoy/envoy_config.yaml'), \"r\") as stream:\n",
    "    orig_config = yaml.safe_load(stream)\n",
    "\n",
    "def generate_envoy_configs(config: Dict,\n",
    "                           save_path: Union[str, Path] = '../envoy/',\n",
    "                           n_cols: int = 10,\n",
    "                           n_samples_per_col: int = 10,\n",
    "                           noise: float = 0.15) -> List[Path]:\n",
    "    # Prevent installing requirements by Envoys as they will run in the same environment\n",
    "    config['params']['install_requirements'] = False\n",
    "\n",
    "    # Pass parameters for Shard Descriptors so they can generate relevant datasets\n",
    "    config['shard_descriptor']['params']['n_samples'] = n_samples_per_col\n",
    "    config['shard_descriptor']['params']['noise'] = noise\n",
    "    \n",
    "    config_paths = [(Path(save_path) / f'{i}_envoy_config.yaml').absolute()\n",
    "                for i in range(1, n_cols + 1)]\n",
    "\n",
    "    for i, path in enumerate(config_paths):\n",
    "        config['shard_descriptor']['params']['rank'] = i\n",
    "        with open(path, \"w\") as stream:\n",
    "            yaml.safe_dump(config, stream)\n",
    "            \n",
    "    return config_paths\n",
    "            \n",
    "def remove_configs(config_paths):\n",
    "    for path in config_paths:\n",
    "        path.unlink()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90109c5b-c785-4af7-ace9-dcd913018dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_paths = generate_envoy_configs(orig_config,\n",
    "                                      n_cols=n_cols,\n",
    "                                      n_samples_per_col=n_samples_per_col,\n",
    "                                      noise=noise)\n",
    "# remove_configs(config_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c3078a-7beb-47c5-bcee-2de264ef3266",
   "metadata": {},
   "source": [
    "#### Now start Envoy processes in a loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843f698e-5582-4918-828c-cf095988da92",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# envoy_workspace_path = Path('../envoy/').absolute()\n",
    "def start_envoys(config_paths: List[Path]) -> None:\n",
    "    envoy_workspace_path = config_paths[0].parent\n",
    "    cwd = Path.cwd()\n",
    "    os.chdir(envoy_workspace_path)\n",
    "    for i, path in enumerate(config_paths):\n",
    "        os.system(f'fx envoy start -n env_{i + 1} --disable-tls '\n",
    "                  f'--envoy-config-path {path} -dh localhost -dp 50049 '\n",
    "                  f'>env_{i + 1}.log &')\n",
    "    os.chdir(cwd)\n",
    "\n",
    "sleep(5)\n",
    "\n",
    "start_envoys(config_paths)\n",
    "\n",
    "sleep(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6216f14c-78d8-444c-9144-ee8316d1487b",
   "metadata": {},
   "source": [
    "## 2. Connect to the Director service of out Federation as Data scientist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d3b764-cb86-4eec-ba8e-df119da7a27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a federation\n",
    "from openfl.interface.interactive_api.federation import Federation\n",
    "\n",
    "# please use the same identificator that was used in signed certificate\n",
    "client_id = 'frontend'\n",
    "director_node_fqdn = 'localhost'\n",
    "director_port = 50049\n",
    "\n",
    "federation = Federation(\n",
    "    client_id=client_id,\n",
    "    director_node_fqdn=director_node_fqdn,\n",
    "    director_port=director_port,\n",
    "    tls=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bed370b-d0c0-46bc-8114-ea8255b2478b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Data scientist may request a list of connected envoys\n",
    "shard_registry = federation.get_shard_registry()\n",
    "\n",
    "# WARNING!\n",
    "\n",
    "# Make sure shard registry contains all the envoys you started!\n",
    "# In other case try to run this cell again or reconnect to the Director (the cell above).\n",
    "shard_registry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6401026-795f-491e-90cb-dd59b451df5f",
   "metadata": {},
   "source": [
    "### Now we will prepare an FL experimnet using OpenFL Python API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8166c689-9dde-4500-b05c-5b1ddf968978",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55fb1a98-b44f-47ff-950d-5a40a1cca0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openfl.interface.interactive_api.experiment import TaskInterface, DataInterface, ModelInterface, FLExperiment\n",
    "\n",
    "class LinRegDataSet(DataInterface):\n",
    "    def __init__(self, **kwargs):\n",
    "        \"\"\"Initialize DataLoader.\"\"\"\n",
    "        self.kwargs = kwargs\n",
    "        pass\n",
    "\n",
    "    @property\n",
    "    def shard_descriptor(self):\n",
    "        \"\"\"Return shard descriptor.\"\"\"\n",
    "        return self._shard_descriptor\n",
    "    \n",
    "    @shard_descriptor.setter\n",
    "    def shard_descriptor(self, shard_descriptor):\n",
    "        \"\"\"\n",
    "        Describe per-collaborator procedures or sharding.\n",
    "\n",
    "        This method will be called during a collaborator initialization.\n",
    "        Local shard_descriptor  will be set by Envoy.\n",
    "        \"\"\"\n",
    "        self._shard_descriptor = shard_descriptor\n",
    "        self.train_set = shard_descriptor.get_dataset(\"train\")\n",
    "        self.val_set = shard_descriptor.get_dataset(\"val\")\n",
    "\n",
    "    def get_train_loader(self, **kwargs):\n",
    "        \"\"\"Output of this method will be provided to tasks with optimizer in contract.\"\"\"\n",
    "        return self.train_set\n",
    "\n",
    "    def get_valid_loader(self, **kwargs):\n",
    "        \"\"\"Output of this method will be provided to tasks without optimizer in contract.\"\"\"\n",
    "        return self.val_set\n",
    "\n",
    "    def get_train_data_size(self):\n",
    "        \"\"\"Information for aggregation.\"\"\"\n",
    "        return len(self.train_set)\n",
    "\n",
    "    def get_valid_data_size(self):\n",
    "        \"\"\"Information for aggregation.\"\"\"\n",
    "        return len(self.val_set)\n",
    "    \n",
    "lin_reg_dataset = LinRegDataSet()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6233e1ed-a2f2-456f-9417-f35a2c27b236",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885a8530-6248-4060-a30a-45cdc79bc41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can inspect the framework adapter used in this example.\n",
    "# It is a plug-in component allowing OpenFL to manage model parameters.\n",
    "framework_adapter = 'custom_adapter.CustomFrameworkAdapter'\n",
    "fed_model = LinRegLasso(1)\n",
    "MI = ModelInterface(model=fed_model, optimizer=None, framework_plugin=framework_adapter)\n",
    "\n",
    "# Save the initial model state\n",
    "initial_model = LinRegLasso(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9da235-02a8-4e7a-9455-5fe2462aa317",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Tasks\n",
    "Using an Optimizer does not make sense for this experiment. Yet it is a required part of a training task contract in the current version of OpenFL, so we just pass None.\n",
    "We need to employ a trick reporting metrics. OpenFL decides which model is the best based on an *increasing* metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e101689-8a63-4562-98ff-09443b1ab9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "TI = TaskInterface()\n",
    "\n",
    "@TI.add_kwargs(**{'lr': 0.001,\n",
    "                   'wd': 0.0001,\n",
    "                   'epoches': 1})\n",
    "@TI.register_fl_task(model='my_model', data_loader='train_data', \\\n",
    "                     device='device', optimizer='optimizer')     \n",
    "def train(my_model, train_data, optimizer, device, lr, wd, epoches):\n",
    "    X, Y = train_data[:,:-1], train_data[:,-1]\n",
    "    my_model.fit(X, Y, epochs, lr, wd, silent=True)\n",
    "    return {'train_MSE': my_model.mse(X, Y),}\n",
    "\n",
    "@TI.register_fl_task(model='my_model', data_loader='val_data', device='device')     \n",
    "def validate(my_model, val_data, device):\n",
    "    X, Y = val_data[:,:-1], val_data[:,-1]        \n",
    "    return {'validation_MSE': my_model.mse(X, Y),}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a4623e-6559-4d4c-b199-f9afe16c0bbd",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb357a88-7098-45b2-85f4-71fe2f2e0f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = 'linear_regression_experiment'\n",
    "fl_experiment = FLExperiment(federation=federation, experiment_name=experiment_name,\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db20124a-949d-4218-abfd-aaf4d0758284",
   "metadata": {},
   "outputs": [],
   "source": [
    "fl_experiment.start(model_provider=MI, \n",
    "                    task_keeper=TI,\n",
    "                    data_loader=lin_reg_dataset,\n",
    "                    rounds_to_train=10,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4909be2b-d23b-4356-b2af-10a212382d52",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This method not only prints messages recieved from the director, \n",
    "# but also saves logs in the tensorboard format (by default)\n",
    "fl_experiment.stream_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd479019-1579-42c4-a446-f7d0a12596df",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Optional: start tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6faaaea",
   "metadata": {},
   "source": [
    "Running on your own machine locally, start tensorboard in background and open localhost:6006 in your browser:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f4b673-e6b1-4bbe-8294-d2b61a65d40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script /bin/bash --bg\n",
    "tensorboard --host $(hostname --all-fqdns | awk '{print $1}') --logdir logs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68867a02",
   "metadata": {},
   "source": [
    "In Google Colab you may use the inline extension "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3684b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d27834-ec5b-4290-8c9d-4c3c5589a7e6",
   "metadata": {},
   "source": [
    "### 3. Retrieve the trained model from the Director"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad915ab3-0032-4a06-b2c0-00710585e24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_model = fl_experiment.get_last_model()\n",
    "best_model = fl_experiment.get_best_model()\n",
    "print(best_model.weights)\n",
    "print(last_model.weights)\n",
    "print(f\"last model MSE: {last_model.mse(x,y)}\")\n",
    "print(f\"best model MSE: {best_model.mse(x,y)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1930789e-b7b5-415e-844d-14ccc3844482",
   "metadata": {},
   "source": [
    "## Lets see what does the unified dataset look like\n",
    "And see how the trained model performs.\n",
    "Note: dots of the same colour belong to the same Envoy's dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51e8a56-d2f1-4758-a5a1-6d6652e4355e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_cols = n_cols\n",
    "n_samples = n_samples_per_col\n",
    "interval = 240\n",
    "x_start = 60\n",
    "noise = noise\n",
    "\n",
    "X = None\n",
    "\n",
    "for rank in range(n_cols):\n",
    "    np.random.seed(rank)  # Setting seed for reproducibility\n",
    "    x = np.random.rand(n_samples, 1) * interval + x_start\n",
    "    x *= np.pi / 180\n",
    "    X = x if X is None else np.vstack((X,x))\n",
    "    y = np.sin(x) + np.random.normal(0, noise, size=(n_samples, 1))\n",
    "    plt.plot(x,y,'+')\n",
    "    \n",
    "X.sort()    \n",
    "Y_hat = last_model.predict(X)\n",
    "plt.plot(X,Y_hat,'--')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e365766-4ea6-40bc-96ae-a183274e8b8c",
   "metadata": {},
   "source": [
    "## Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d793be-6c20-4a22-bad7-c082c1ee76ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To stop all services\n",
    "!pkill fx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809b8eb3-4775-43d9-8f96-de84a089a54e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "remove_configs(config_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b28b29-48d3-4f21-bc69-40259b83f93b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

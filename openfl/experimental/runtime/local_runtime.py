# Copyright (C) 2020-2023 Intel Corporation
# SPDX-License-Identifier: Apache-2.0
""" openfl.experimental.runtime package LocalRuntime class."""

from __future__ import annotations

import gc
import importlib
import math
import os
from copy import deepcopy
from typing import TYPE_CHECKING, Optional

import ray

from openfl.experimental.runtime import Runtime

if TYPE_CHECKING:
    from openfl.experimental.interface import Aggregator, Collaborator, FLSpec

from typing import Any, Callable, Dict, List, Type

from openfl.experimental.utilities import (
    ResourcesNotAvailableError,
    aggregator_to_collaborator,
    check_resource_allocation,
    checkpoint,
    filter_attributes,
    generate_artifacts,
    get_number_of_gpus,
)


class RayExecutor:

    def __init__(self):
        """Create RayExecutor object"""
        self.__remote_contexts = []

    def ray_call_put(
        self,
        participant: Any,
        ctx: Any,
        f_name: str,
        callback: Callable,
        clones: Optional[Any] = None,
    ) -> None:
        """
        Execute f_name from inside participant (Aggregator or Collaborator) class with the context
        of clone (ctx)
        """
        if clones is not None:
            self.__remote_contexts.append(
                participant.execute_func.remote(ctx, f_name, callback, clones)
            )
        else:
            self.__remote_contexts.append(
                participant.execute_func.remote(ctx, f_name, callback)
            )

    def ray_call_get(self) -> List[Any]:
        """
        Get remote clones and delete ray references of clone (ctx) and,
        reclaim memory
        """
        clones = ray.get(self.__remote_contexts)
        del self.__remote_contexts
        self.__remote_contexts = []

        return clones


def ray_group_assign(collaborators, num_actors=1):
    """
    Assigns collaborators to resource groups which share a CUDA context.

    Args:
        collaborators (list): The list of collaborators.
        num_actors (int, optional): Number of actors to distribute collaborators to.
        Defaults to 3.

    Returns:
        list: A list of GroupMember instances.
    """

    class GroupMember:
        """
        A utility class that manages the collaborator and its group.

        This class maintains compatibility with runtime execution by assigning attributes for each
        function in the Collaborator interface in conjunction with RemoteHelper.
        """

        def __init__(self, collaborator_actor, collaborator):
            """
            Initializes a new instance of the GroupMember class.

            Args:
                collaborator_actor: The collaborator actor.
                collaborator: The collaborator.
            """
            from openfl.experimental.interface import Collaborator

            all_methods = [
                method
                for method in dir(Collaborator)
                if callable(getattr(Collaborator, method))
            ]
            external_methods = [
                method for method in all_methods if (method[0] != "_")
            ]
            self.collaborator_actor = collaborator_actor
            self.collaborator = collaborator
            for method in external_methods:
                setattr(
                    self,
                    method,
                    RemoteHelper(
                        self.collaborator_actor, self.collaborator, method
                    ),
                )

    class RemoteHelper:
        """
        A utility class to maintain compatibility with RayExecutor.

        This class returns a lambda function that uses collaborator_actor.execute_from_col to run
        a given function from the given collaborator.
        """

        # once ray_grouped replaces the current ray runtime this class can be replaced with a
        # funtion that returns the lambda funtion, using a funtion is necesary because this is used
        # in setting multiple funtions in a loop and lambda takes the reference to self.f_name and
        # not the value so we need to change scope to avoid self.f_name from changing as the loop
        # progresses
        def __init__(self, collaborator_actor, collaborator, f_name) -> None:
            """
            Initializes a new instance of the RemoteHelper class.

            Args:
                collaborator_actor: The collaborator actor.
                collaborator: The collaborator.
                f_name (str): The name of the function.
            """
            self.f_name = f_name
            self.collaborator_actor = collaborator_actor
            self.collaborator = collaborator
            self.f = lambda *args, **kwargs: self.collaborator_actor.execute_from_col.remote(
                self.collaborator, self.f_name, *args, **kwargs
            )

        def remote(self, *args, **kwargs):
            """
            Executes the function with the given arguments and keyword arguments.

            Args:
                *args: The arguments to pass to the function.
                **kwargs: The keyword arguments to pass to the function.

            Returns:
                The result of the function execution.
            """
            return self.f(*args, *kwargs)

    collaborator_ray_refs = []
    collaborators_per_group = math.ceil(len(collaborators) / num_actors)
    times_called = 0
    # logic to sort collaborators by gpus, if collaborators have the same number of gpu then they
    # are sorted by cpu
    cpu_magnitude = len(str(abs(max([i.num_cpus for i in collaborators]))))
    min_gpu = min([i.num_gpus for i in collaborators])
    min_gpu = max(min_gpu, 0.0001)
    collaborators_sorted_by_gpucpu = sorted(
        collaborators,
        key=lambda x: x.num_gpus / min_gpu * 10**cpu_magnitude + x.num_cpus,
    )
    initializations = []

    for collaborator in collaborators_sorted_by_gpucpu:
        # initialize actor group
        if times_called % collaborators_per_group == 0:
            max_num_cpus = max(
                [
                    i.num_cpus
                    for i in collaborators_sorted_by_gpucpu[
                        times_called : times_called + collaborators_per_group
                    ]
                ]
            )
            max_num_gpus = max(
                [
                    i.num_gpus
                    for i in collaborators_sorted_by_gpucpu[
                        times_called : times_called + collaborators_per_group
                    ]
                ]
            )
            print(f"creating actor with {max_num_cpus}, {max_num_gpus}")
            collaborator_actor = (
                ray.remote(RayGroup)
                .options(
                    num_cpus=max_num_cpus, num_gpus=max_num_gpus
                )  # max_concurrency=max_concurrency)
                .remote()
            )
        # add collaborator to actor group
        initializations.append(
            collaborator_actor.append.remote(
                collaborator.get_name(),
                private_attributes_callable=collaborator.private_attributes_callable,
                **collaborator.kwargs,
            )
        )

        times_called += 1

        # append GroupMember to output list
        collaborator_ray_refs.append(
            GroupMember(collaborator_actor, collaborator.get_name())
        )
    # Wait for all collaborators to be created on actors
    ray.get(initializations)

    return collaborator_ray_refs


class RayGroup:
    """
    A Ray actor that manages a group of collaborators.

    This class allows for the execution of functions from a specified collaborator
    using the execute_from_col method. The collaborators are stored in a dictionary
    where the key is the collaborator's name.
    """

    def __init__(self):
        """
        Initializes a new instance of the RayGroup class.
        """
        self.collaborators = {}

    def append(
        self,
        name: str = "",
        private_attributes_callable: Callable = None,
        **kwargs,
    ):
        """
        Appends a new collaborator to the group.

        Args:
            name (str): The name of the collaborator.
            private_attributes_callable (Callable): A callable that sets the private attributes of
            the collaborator.
            **kwargs: Additional keyword arguments.
        """
        from openfl.experimental.interface import Collaborator

        self.collaborators[name] = Collaborator(
            name=name,
            private_attributes_callable=private_attributes_callable,
            **kwargs,
        )

    def execute_from_col(self, name, internal_f_name, *args, **kwargs):
        """
        Executes a function from a specified collaborator.

        Args:
            name (str): The name of the collaborator.
            internal_f_name (str): The name of the function to execute.
            *args: Additional arguments to pass to the function.
            **kwargs: Additional keyword arguments to pass to the function.

        Returns:
            The result of the function execution.
        """
        f = getattr(self.collaborators[name], internal_f_name)
        return f(*args, **kwargs)

    def get_collaborator(self, name):
        """
        Retrieves a collaborator from the group by name.

        Args:
            name (str): The name of the collaborator.

        Returns:
            The collaborator instance.
        """
        return self.collaborators[name]


class LocalRuntime(Runtime):

    def __init__(
        self,
        aggregator: Dict = None,
        collaborators: Dict = None,
        backend: str = "single_process",
        **kwargs,
    ) -> None:
        """
        Use single node to run the flow

        Args:
            aggregator:    The aggregator instance that holds private attributes
            collaborators: A list of collaborators; each with their own private attributes
            backend:       The backend that will execute the tasks. Available options are:

                           'single_process': (default) Executes every task within the same process

                           'ray':            Executes tasks using the Ray library. We use ray
                                             actors called RayGroups to runs tasks in their own
                                             isolated process. Each participant is distributed
                                             into a ray group. The RayGroups run concurrently
                                             while participants in the group run serially.
                                             The default is 1 RayGroup and can be changed by using
                                             the num_actors=1 kwarg. By using more RayGroups more
                                             concurency is allowed with the trade off being that
                                             each RayGroup has extra memory overhead in the form
                                             of extra CUDA CONTEXTS.

                                             Also the ray runtime supports GPU isolation using
                                             Ray's 'num_gpus' argument, which can be passed in
                                             through the collaborator placement decorator.

                                             Example:
                                             @collaborator(num_gpus=1)
                                             def some_collaborator_task(self):
                                                 ...


                                             By selecting num_gpus=1, the task is guaranteed
                                             exclusive GPU access. If the system has one GPU,
                                             collaborator tasks will run sequentially.
        """
        super().__init__()
        if backend not in ["ray", "single_process"]:
            raise ValueError(
                f"Invalid 'backend' value '{backend}', accepted values are "
                + "'ray', or 'single_process'"
            )
        if backend == "ray":
            if not ray.is_initialized():
                dh = kwargs.get("dashboard_host", "127.0.0.1")
                dp = kwargs.get("dashboard_port", 5252)
                ray.init(dashboard_host=dh, dashboard_port=dp)

            self.num_actors = kwargs.get("num_actors", 1)
        self.backend = backend
        if aggregator is not None:
            self.aggregator = self.__get_aggregator_object(aggregator)

        if collaborators is not None:
            self.collaborators = self.__get_collaborator_object(collaborators)

    def __get_aggregator_object(self, aggregator: Type[Aggregator]) -> Any:
        """Get aggregator object based on localruntime backend"""

        if self.backend == "single_process":
            return aggregator

        total_available_cpus = os.cpu_count()
        total_available_gpus = get_number_of_gpus()

        agg_cpus = aggregator.num_cpus
        agg_gpus = aggregator.num_gpus

        if agg_gpus > 0:
            check_resource_allocation(
                total_available_gpus,
                {aggregator.get_name(): agg_gpus},
            )

        if total_available_gpus < agg_gpus:
            raise ResourcesNotAvailableError(
                f"cannot assign more than available GPUs \
                    ({agg_gpus} < {total_available_gpus})."
            )
        if total_available_cpus < agg_cpus:
            raise ResourcesNotAvailableError(
                f"cannot assign more than available CPUs \
                    ({agg_cpus} < {total_available_cpus})."
            )

        interface_module = importlib.import_module(
            "openfl.experimental.interface"
        )
        aggregator_class = getattr(interface_module, "Aggregator")

        aggregator_actor = ray.remote(aggregator_class).options(
            num_cpus=agg_cpus, num_gpus=agg_gpus
        )
        aggregator_actor_ref = aggregator_actor.remote(
            name=aggregator.get_name(),
            private_attributes_callable=aggregator.private_attributes_callable,
            **aggregator.kwargs,
        )

        return aggregator_actor_ref

    def __get_collaborator_object(self, collaborators: List) -> Any:
        """Get collaborator object based on localruntime backend"""

        if self.backend == "single_process":
            return collaborators

        total_available_cpus = os.cpu_count()
        total_required_cpus = sum(
            [collaborator.num_cpus for collaborator in collaborators]
        )
        if total_available_cpus < total_required_cpus:
            raise ResourcesNotAvailableError(
                f"cannot assign more than available CPUs \
                    ({total_required_cpus} < {total_available_cpus})."
            )

        if self.backend == "ray":
            collaborator_ray_refs = ray_group_assign(
                collaborators, num_actors=self.num_actors
            )
            return collaborator_ray_refs

    @property
    def aggregator(self) -> str:
        """Returns name of _aggregator"""
        return self._aggregator.name

    @aggregator.setter
    def aggregator(self, aggregator: Type[Aggregator]):
        """Set LocalRuntime _aggregator"""
        self._aggregator = aggregator

    @property
    def collaborators(self) -> List[str]:
        """
        Return names of collaborators. Don't give direct access to private attributes
        """
        return list(self.__collaborators.keys())

    @collaborators.setter
    def collaborators(self, collaborators: List[Type[Collaborator]]):
        """Set LocalRuntime collaborators"""
        if self.backend == "single_process":

            def get_collab_name(collab):
                return collab.get_name()

        else:

            def get_collab_name(collab):
                return ray.get(collab.get_name.remote())

        self.__collaborators = {
            get_collab_name(collaborator): collaborator
            for collaborator in collaborators
        }

    def get_collaborator_kwargs(self, collaborator_name: str):
        """
        Returns kwargs of collaborator

        Args:
            collaborator_name: Collaborator name for which kwargs is to be returned

        Returns:
            kwargs: Collaborator private_attributes_callable function name, and
             arguments required to call it.
        """
        collab = self.__collaborators[collaborator_name]
        kwargs = {}
        if hasattr(collab, "private_attributes_callable"):
            if collab.private_attributes_callable is not None:
                kwargs.update(collab.kwargs)
                kwargs["private_attributes_callable"] = (
                    collab.private_attributes_callable.__name__
                )

        return kwargs

    def initialize_aggregator(self):
        """initialize aggregator private attributes"""
        if self.backend == "single_process":
            self._aggregator.initialize_private_attributes()
        else:
            ray.get(self._aggregator.initialize_private_attributes.remote())

    def initialize_collaborators(self):
        """initialize collaborator private attributes"""
        if self.backend == "single_process":

            def init_private_attrs(collab):
                return collab.initialize_private_attributes()

        else:

            def init_private_attrs(collab):
                return ray.get(collab.initialize_private_attributes.remote())

        for collaborator in self.__collaborators.values():
            init_private_attrs(collaborator)

    def restore_instance_snapshot(
        self, ctx: Type[FLSpec], instance_snapshot: List[Type[FLSpec]]
    ):
        """Restores attributes from backup (in instance snapshot) to ctx"""
        for backup in instance_snapshot:
            artifacts_iter, _ = generate_artifacts(ctx=backup)
            for name, attr in artifacts_iter():
                if not hasattr(ctx, name):
                    setattr(ctx, name, attr)

    def execute_agg_steps(
        self, ctx: Any, f_name: str, clones: Optional[Any] = None
    ):
        """
        Execute aggregator steps until at transition point
        """
        if clones is not None:
            f = getattr(ctx, f_name)
            f(clones)
        else:
            not_at_transition_point = True
            while not_at_transition_point:
                f = getattr(ctx, f_name)
                f()

                f, parent_func = ctx.execute_task_args[:2]
                if (
                    aggregator_to_collaborator(f, parent_func)
                    or f.__name__ == "end"
                ):
                    not_at_transition_point = False

                f_name = f.__name__

    def execute_collab_steps(self, ctx: Any, f_name: str):
        """
        Execute collaborator steps until at transition point
        """
        not_at_transition_point = True
        while not_at_transition_point:
            f = getattr(ctx, f_name)
            f()

            f, parent_func = ctx.execute_task_args[:2]
            if ctx._is_at_transition_point(f, parent_func):
                not_at_transition_point = False

            f_name = f.__name__

    def execute_task(self, flspec_obj: Type[FLSpec], f: Callable, **kwargs):
        """
        Defines which function to be executed based on name and kwargs
        Updates the arguments and executes until end is not reached

        Args:
            flspec_obj:        Reference to the FLSpec (flow) object. Contains information
                               about task sequence, flow attributes.
            f:                 The next task to be executed within the flow

        Returns:
            artifacts_iter: Iterator with updated sequence of values
        """
        parent_func = None
        instance_snapshot = None
        self.join_step = False

        while f.__name__ != "end":
            if "foreach" in kwargs:
                flspec_obj = self.execute_collab_task(
                    flspec_obj, f, parent_func, instance_snapshot, **kwargs
                )
            else:
                flspec_obj = self.execute_agg_task(flspec_obj, f)
            f, parent_func, instance_snapshot, kwargs = (
                flspec_obj.execute_task_args
            )
        else:
            flspec_obj = self.execute_agg_task(flspec_obj, f)
            f = flspec_obj.execute_task_args[0]

            checkpoint(flspec_obj, f)
            artifacts_iter, _ = generate_artifacts(ctx=flspec_obj)
            return artifacts_iter()

    def execute_agg_task(self, flspec_obj, f):
        """
        Performs execution of aggregator task
        Args:
            flspec_obj : Reference to the FLSpec (flow) object
            f          :  The task to be executed within the flow

        Returns:
            flspec_obj: updated FLSpec (flow) object
        """
        from openfl.experimental.interface import FLSpec

        aggregator = self._aggregator
        clones = None

        if self.join_step:
            clones = [
                FLSpec._clones[col] for col in self.selected_collaborators
            ]
            self.join_step = False

        if self.backend == "ray":
            ray_executor = RayExecutor()
            ray_executor.ray_call_put(
                aggregator,
                flspec_obj,
                f.__name__,
                self.execute_agg_steps,
                clones,
            )
            flspec_obj = ray_executor.ray_call_get()[0]
            del ray_executor
        else:
            aggregator.execute_func(
                flspec_obj, f.__name__, self.execute_agg_steps, clones
            )

        gc.collect()
        return flspec_obj

    def execute_collab_task(
        self, flspec_obj, f, parent_func, instance_snapshot, **kwargs
    ):
        """
        Performs
            1. Filter include/exclude
            2. Set runtime, collab private attributes , metaflow_interface
            3. Execution of all collaborator for each task
            4. Remove collaborator private attributes
            5. Execute the next function after transition

        Args:
            flspec_obj  :  Reference to the FLSpec (flow) object
            f           :  The task to be executed within the flow
            parent_func : The prior task executed in the flow
            instance_snapshot : A prior FLSpec state that needs to be restored

        Returns:
            flspec_obj: updated FLSpec (flow) object
        """

        from openfl.experimental.interface import FLSpec

        flspec_obj._foreach_methods.append(f.__name__)
        selected_collaborators = getattr(flspec_obj, kwargs["foreach"])
        self.selected_collaborators = selected_collaborators

        # filter exclude/include attributes for clone
        self.filter_exclude_include(
            flspec_obj, f, selected_collaborators, **kwargs
        )

        if self.backend == "ray":
            ray_executor = RayExecutor()
        # set runtime,collab private attributes and metaflowinterface
        for col in selected_collaborators:
            clone = FLSpec._clones[col]
            # Set new LocalRuntime for clone as it is required
            # new runtime object will not contain private attributes of
            # aggregator or other collaborators
            clone.runtime = LocalRuntime(backend="single_process")

            # write the clone to the object store
            # ensure clone is getting latest _metaflow_interface
            clone._metaflow_interface = flspec_obj._metaflow_interface

        for collab_name in selected_collaborators:
            clone = FLSpec._clones[collab_name]
            collaborator = self.__collaborators[collab_name]

            if self.backend == "ray":
                ray_executor.ray_call_put(
                    collaborator, clone, f.__name__, self.execute_collab_steps
                )
            else:
                collaborator.execute_func(
                    clone, f.__name__, self.execute_collab_steps
                )

        if self.backend == "ray":
            clones = ray_executor.ray_call_get()
            FLSpec._clones.update(zip(selected_collaborators, clones))
            clone = clones[0]
            del clones

        flspec_obj.execute_task_args = clone.execute_task_args

        # Restore the flspec_obj state if back-up is taken
        self.restore_instance_snapshot(flspec_obj, instance_snapshot)
        del instance_snapshot

        gc.collect()
        # Setting the join_step to indicate to aggregator to collect clones
        self.join_step = True
        return flspec_obj

    def filter_exclude_include(
        self, flspec_obj, f, selected_collaborators, **kwargs
    ):
        """
        This function filters exclude/include attributes
        Args:
            flspec_obj  :  Reference to the FLSpec (flow) object
            f           :  The task to be executed within the flow
            selected_collaborators : all collaborators
        """

        from openfl.experimental.interface import FLSpec

        for col in selected_collaborators:
            clone = FLSpec._clones[col]
            clone.input = col
            if (
                "exclude" in kwargs and hasattr(clone, kwargs["exclude"][0])
            ) or ("include" in kwargs and hasattr(clone, kwargs["include"][0])):
                filter_attributes(clone, f, **kwargs)
            artifacts_iter, _ = generate_artifacts(ctx=flspec_obj)
            for name, attr in artifacts_iter():
                setattr(clone, name, deepcopy(attr))
            clone._foreach_methods = flspec_obj._foreach_methods

    def __repr__(self):
        return "LocalRuntime"
